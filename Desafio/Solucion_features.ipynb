{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Solucion.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPWRnEx2oTvM"
      },
      "source": [
        "```\n",
        "ME72: Maestría en Métodos Cuantitativos para la Gestión y Análisis de Datos\n",
        "M72109: Analisis de datos no estructurados\n",
        "Universidad de Buenos Aires - Facultad de Ciencias Economicas (UBA-FCE)\n",
        "Año: 2021\n",
        "Profesor: Facundo Santiago\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWBLdBSioTvO"
      },
      "source": [
        "# Solución: ¿Qué tan memorable es un video?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbe7972dpDfx"
      },
      "source": [
        "Este notebook les permitirá tener a disposición todos los recursos que se vieron en durante la materia. Todos los fragmentos de código se descargaran utilizando la sección preparación del ambiente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXdA6Yg761jz"
      },
      "source": [
        "## Preparación del ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZrG1xI-61j0"
      },
      "source": [
        "### Sets de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xb7yWkB61j1"
      },
      "source": [
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/ground_truth.csv --directory-prefix ./Data/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/Features/audio_vectors.csv --directory-prefix ./Data/Features/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/Features/c3d_vectors.csv --directory-prefix ./Data/Features/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/Features/caption_features.csv --directory-prefix ./Data/Features/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/Features/colors_features.csv --directory-prefix ./Data/Features/ --quiet"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ9KM2hm61j7"
      },
      "source": [
        "### Librerías de codigo que se utilizan durante el curso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngMbrDtOAUeO"
      },
      "source": [
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/solucion_base.txt --quiet\n",
        "!pip install -r solucion_base.txt --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAPdJg4j61j8"
      },
      "source": [
        "#### Audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgEPMkE861j9"
      },
      "source": [
        "!wget -N https://storage.googleapis.com/audioset/yamnet.h5 --directory-prefix ./Models/yamnet/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Audio/Models/yamnet/yamnet_class_map.csv --directory-prefix ./Models/yamnet/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Audio/Utils/audio_plotter.py --directory-prefix ./Utils/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Audio/yamnet/yamnet.py --directory-prefix ./yamnet/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Audio/yamnet/params.py --directory-prefix ./yamnet/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Audio/yamnet/features_lib.py --directory-prefix ./yamnet/ --quiet"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mIgYB7261kS"
      },
      "source": [
        "#### NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNeu_Nue61kT"
      },
      "source": [
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Utils/TextDataset.py --directory-prefix ./Utils/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Utils/TextNormalizer.py --directory-prefix ./Utils/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Utils/PadSequenceTransformer.py --directory-prefix ./Utils/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Utils/Word2VecVectorizer.py --directory-prefix ./Utils/ --quiet\n",
        "!wget https://santiagxf.blob.core.windows.net/public/Word2Vec/model-en.bin --directory-prefix ./Models/Word2Vec --quiet"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7n2pmiw61kc"
      },
      "source": [
        "#### Vision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7COK8kZ61kd"
      },
      "source": [
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Vision/Utils/Cognitive.py --directory-prefix ./Utils/ --quiet\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Vision/Utils/Plotting.py --directory-prefix ./Utils/ --quiet"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utQ0fxnu61ko"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLjNwmAJ61kp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, SpatialDropout1D\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from yamnet.yamnet import yamnet_frames_model\n",
        "import yamnet.yamnet as yamnet_model\n",
        "from yamnet.params import Params\n",
        "\n",
        "from Utils.audio_plotter import plot_audio_embeddings\n",
        "from Utils.TextDataset import ClassificationDataset\n",
        "from Utils.TextNormalizer import TweetTextNormalizer\n",
        "from Utils.Word2VecVectorizer import Word2VecVectorizer\n",
        "from Utils.PadSequenceTransformer import PadSequenceTransformer\n",
        "\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ucs_gunq61ku"
      },
      "source": [
        "## Solución"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBDymaXtoTvp"
      },
      "source": [
        "Cuentan con 2 tipos de anotaciones para cada uno de los fragmentos de video disponibles:\n",
        " - **memorability_score:** Representa el puntaje de memorabilidad de la secuencia en particular, desde 0 a 1. Valores más grandes son mejores.\n",
        " - **memorable:** Variable categórica que representa si un video es memorable o no. Un video con `memorability_score` superior a `0.5` es marcado como memorable (`1`), sino es marcado como no memorable (`0`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69lG6CJyoTvq"
      },
      "source": [
        "labels = pd.read_csv('Data/ground_truth.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXS_1KRBoTvt",
        "outputId": "570584c2-f3a5-464e-dd8d-7392a5981d46"
      },
      "source": [
        "labels.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_name</th>\n",
              "      <th>start(sec)</th>\n",
              "      <th>end(sec)</th>\n",
              "      <th>sequence_name</th>\n",
              "      <th>Neutral (1)_Typical (0)</th>\n",
              "      <th>nb_annotations</th>\n",
              "      <th>memorability_score</th>\n",
              "      <th>memorabable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127 hours</td>\n",
              "      <td>2000</td>\n",
              "      <td>2010</td>\n",
              "      <td>127_hours_2000_2010_1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>127 hours</td>\n",
              "      <td>2182</td>\n",
              "      <td>2192</td>\n",
              "      <td>127_hours_2182_2192_5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  movie_name  start(sec)  end(sec)          sequence_name  \\\n",
              "0  127 hours        2000      2010  127_hours_2000_2010_1   \n",
              "1  127 hours        2182      2192  127_hours_2182_2192_5   \n",
              "\n",
              "   Neutral (1)_Typical (0)  nb_annotations  memorability_score  memorabable  \n",
              "0                        0               5                 1.0            1  \n",
              "1                        1               8                 0.0            0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVZ1ZGv-61k7"
      },
      "source": [
        "Las siguientes variables contienen la información preprocesada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr5ngP_z61k8"
      },
      "source": [
        "captions = pd.read_csv('Data/Features/caption_features.csv')\n",
        "colors = pd.read_csv('Data/Features/colors_features.csv')\n",
        "audio_embeddings = pd.read_csv('Data/Features/audio_vectors.csv').to_numpy()[:,2:].reshape((-1,20,1024))\n",
        "video_embeddings = pd.read_csv('Data/Features/c3d_vectors.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4CQH6fg-FQW"
      },
      "source": [
        "> **Importante:** Note que `audio_embeddings` es un tensor y no un `pd.DataFrame`. Esto se debe a que las dimensiones de este tipo de dato son multidimensionales y los dataframes en `pandas` no permiten este tipo de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teUH1dVe61nz"
      },
      "source": [
        "# completar solución"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}