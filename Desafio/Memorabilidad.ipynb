{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ME72: Maestría en Métodos Cuantitativos para la Gestión y Análisis de Datos\n",
    "M72109: Analisis de datos no estructurados\n",
    "Universidad de Buenos Aires - Facultad de Ciencias Economicas (UBA-FCE)\n",
    "Año: 2020\n",
    "Profesor: Facundo Santiago\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio: ¿Qué tan memorable es un video?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sT_t9OxYwKIc"
   },
   "source": [
    "## ¿De que se trata el desafío?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta tarea se centra en el problema de predecir qué tan memorable es un video para los espectadores. Requiere que los participantes predigan automáticamente las puntuaciones de memorabilidad de los videos que reflejan la probabilidad de que se recuerde un video. Recibiran un extenso conjunto de datos de videos que van acompañados de anotaciones memorables, así como características extraidas previamente para facilitarles el procesamiento. Las etiquetas (labels) se ha recopilado a través de pruebas de reconocimiento y, por lo tanto, es el resultado de una medición objetiva del rendimiento de la memoria.\n",
    "\n",
    "<img src='Docs/memorability.png' width=600 />\n",
    "\n",
    "Creditos del desafio original:\n",
    "http://www.multimediaeval.org/mediaeval2019/memorability/\n",
    "\n",
    "Mihai Gabriel Constantin, University Politehnica of Bucharest, Romania\n",
    "Bogdan Ionescu, University Politehnica of Bucharest, Romania\n",
    "Claire-Hélène Demarty, Technicolor, France\n",
    "Quang-Khanh-Ngoc Duong, Technicolor, France\n",
    "Xavier Alameda-Pineda, INRIA, France\n",
    "Mats Sjöberg, CSC, Finland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direcciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberán entrenar modelos computacionales capaces de inferir la memorabilidad de video a partir del contenido visual. Opcionalmente, se pueden utilizar títulos descriptivos adjuntos a los videos. Los modelos se evaluarán a través de métricas de evaluación estándar utilizadas en las tareas de clasificación (correlación de Spearman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TghjzJl0wKId"
   },
   "source": [
    "## Preparación del ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mdazYRTHwKIg"
   },
   "source": [
    "Descarguemos los fragmentos de codigo que se utilizan en este caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZwX_5SFwKIh"
   },
   "outputs": [],
   "source": [
    "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desadio/Utils/audio_extractor.py --directory-prefix ./Utils/\n",
    "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desadio/Utils/audio_featurizer.py --directory-prefix ./Utils/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos el set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-20 17:01:27--  https://santiagxf.blob.core.windows.net/public/2018_MovieMemorabilityPackage.tgz\n",
      "Resolving santiagxf.blob.core.windows.net (santiagxf.blob.core.windows.net)... 52.239.220.32\n",
      "Connecting to santiagxf.blob.core.windows.net (santiagxf.blob.core.windows.net)|52.239.220.32|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1461601236 (1.4G) [application/x-compressed]\n",
      "Saving to: ‘Data/2018_MovieMemorabilityPackage.tgz’\n",
      "\n",
      "2018_MovieMemorabil 100%[===================>]   1.36G   103MB/s    in 14s     \n",
      "\n",
      "2020-09-20 17:01:58 (96.8 MB/s) - ‘Data/2018_MovieMemorabilityPackage.tgz’ saved [1461601236/1461601236]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -N https://santiagxf.blob.core.windows.net/public/2018_MovieMemorabilityPackage.tgz --directory-prefix Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descompromiremos el archivo para obtener el set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar zxvf ./Data/2018_MovieMemorabilityPackage.tgz --directory Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anotaciones para el problema de memorabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuentan con la anotaciones para el problema de memorabilidad. Dependiendo de su elección pueden optar por resolver un problema de clasificación o un problema de regresión. Esto lo veran refrejado en:\n",
    " - **memorability_score:** Representa el puntaje de memorabilidad de la secuencia en particular. Valores altos son mejors.\n",
    " - **memorable:** Variable categórica que representa si un video es memorable o no. Un video con Score superior a 0.5 es marcado como memorable (1), sino es marcado como no memorable (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('Data/ground_truth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>start(sec)</th>\n",
       "      <th>end(sec)</th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>Neutral (1)_Typical (0)</th>\n",
       "      <th>nb_annotations</th>\n",
       "      <th>memorability_score</th>\n",
       "      <th>memorabable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127 hours</td>\n",
       "      <td>2000</td>\n",
       "      <td>2010</td>\n",
       "      <td>127_hours_2000_2010_1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127 hours</td>\n",
       "      <td>2182</td>\n",
       "      <td>2192</td>\n",
       "      <td>127_hours_2182_2192_5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_name  start(sec)  end(sec)          sequence_name  \\\n",
       "0  127 hours        2000      2010  127_hours_2000_2010_1   \n",
       "1  127 hours        2182      2192  127_hours_2182_2192_5   \n",
       "\n",
       "   Neutral (1)_Typical (0)  nb_annotations  memorability_score  memorabable  \n",
       "0                        0               5                 1.0            1  \n",
       "1                        1               8                 0.0            0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elije tu propia aventura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este desadio, les propongo elegir la dificultad con la que quieren trabajar para solucionar el problema en cuestión. Dependiendo de la elección, son las herramientas que tendrán a su disosición para resolver el problema. Pueden utilizar algunas de las sugerencias, todas las sugerencias, o si conocen alguna técnica en particular que les gustaría revisar si aplica... probarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolver el desafio utilizando los datos de origen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta configuración del desafio más similar a la vida real, y solo contaran como datos de entrada un conjunto de videos en formato MP4 juntos con sus anotaciones en formato CSV. Cualquier procesamiento de datos deberá realizarse utilizando esta información solamente. Como algunos procesamientos pueden ser bastante complejos, contarán además con:\n",
    " - Imágenes extraidas cada 2 segundos por cada secuencia a analizar\n",
    " - Tracks de audio disponibles en formato WAV listos para utilizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el directorio */Data/Raw/videos* encontraran todas las secuencias utilizadas en este desafio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el directorio */Data/Raw/audios* encontraran todos los audios correspondientes a cada una de las secuencias de los videos. Los audios están en formato wav, que si bien ocupan mayor espacio, son más sencillos de procesar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el directorio */Data/Raw/frames* encontraran todos los frames extraidos de cada una de las secuencias. Los frames están disponibles cada 2 segundos por lo cual disponen de 5 frames por cada secuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolver el desafío utilizando features generadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta configuración del desafio, y hay bastante trabajo realizado y se les entrega en formatos CSV para que no tengan que trabajar con grandes volumenes de datos no estructurados. En particular tendran:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descripciónes de las imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuentan con las descripciones de cuadros (frames) de cada una de las secuencias. Estos frames están extraidos cada 1 segundo y las descripciones se generaron utilizando la API de Computer Vision de Azure Cognitive Services. Cada una de las descripciones forma una oración, y por lo tanto, por cada secuencia tendrán disponible un parrafo con 10 oraciones describiendo cada una de las escenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = pd.read_csv('Data/Features/caption_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127_hours_2000_2010_1</td>\n",
       "      <td>a man in a suit and tie standing in front of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127_hours_2182_2192_5</td>\n",
       "      <td>a man holding a toothbrush in his mouth. a wom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sequence_name                                                 cc\n",
       "0  127_hours_2000_2010_1  a man in a suit and tie standing in front of a...\n",
       "1  127_hours_2182_2192_5  a man holding a toothbrush in his mouth. a wom..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectores de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se corresponden a las representaciones (embeddings) utilizados por la red YAMNet que vimos en el curso. YAMNet es un modelo que explota esta caracteristica al construir imagenes a partir de audio (llamados parches o patchs). Cada uno de estos patchs es el resultado de calcular espectrogramas log-mel, creando así parches de imágenes 2D para utilizar en nuestro modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embeddings = pd.read_csv('Data/Features/audio_vectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>127_hours_2000_2010_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.796399</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>127_hours_2000_2010_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>0.010787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          sequence_name    1         2         3         4  \\\n",
       "0           0  127_hours_2000_2010_1  0.0  0.796399  0.009879  0.000000   \n",
       "1           1  127_hours_2000_2010_1  0.0  0.000000  0.000000  0.003163   \n",
       "\n",
       "          5    6    7    8  ...  1015  1016  1017      1018  1019  1020  1021  \\\n",
       "0  0.000000  0.0  0.0  0.0  ...   0.0   0.0   0.0  0.492673   0.0   0.0   0.0   \n",
       "1  0.010787  0.0  0.0  0.0  ...   0.0   0.0   0.0  0.173500   0.0   0.0   0.0   \n",
       "\n",
       "       1022  1023  1024  \n",
       "0  0.391332   0.0   0.0  \n",
       "1  0.177809   0.0   0.0  \n",
       "\n",
       "[2 rows x 1026 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_embeddings.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectores de la red C3D (convoluciones en 3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se corresponden a las representaciones aprendidas al aplicar un modelo de convolución 3D sobre el input del video. Estas convoluciones no solo tienen en cuenta localidad a nivel de pixeles en las imagenes sino que también localidad a nivel espacio-temporal en el transcurso del video.\n",
    "\n",
    "<img src='Docs/3D-timedistributed.PNG' width=500 />\n",
    "\n",
    "Referencias sobre este modelo: https://arxiv.org/pdf/1711.11248.pdf<br />\n",
    "Implementación por el equipo de Facebook AI: https://github.com/facebookresearch/VMZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_embeddings = pd.read_csv('Data/Features/c3d_vectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>Unnamed: 4097</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127_hours_2000_2010_1</td>\n",
       "      <td>0.82588</td>\n",
       "      <td>6.3702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34248</td>\n",
       "      <td>0.75896</td>\n",
       "      <td>1.7976</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6224</td>\n",
       "      <td>1.7332</td>\n",
       "      <td>2.4912</td>\n",
       "      <td>3.27780</td>\n",
       "      <td>1.7001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.9559</td>\n",
       "      <td>6.1765</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127_hours_2182_2192_5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.2294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.53370</td>\n",
       "      <td>1.2082</td>\n",
       "      <td>2.6512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8342</td>\n",
       "      <td>1.7536</td>\n",
       "      <td>1.8910</td>\n",
       "      <td>0.91983</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0523</td>\n",
       "      <td>1.0713</td>\n",
       "      <td>1.4447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 4098 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sequence_name        0       1    2        3        4       5  \\\n",
       "0  127_hours_2000_2010_1  0.82588  6.3702  0.0  0.34248  0.75896  1.7976   \n",
       "1  127_hours_2182_2192_5  0.00000  2.2294  0.0  0.00000  1.53370  1.2082   \n",
       "\n",
       "        6    7       8  ...  4087    4088    4089    4090     4091    4092  \\\n",
       "0  0.1524  0.0  2.1005  ...   0.0  5.6224  1.7332  2.4912  3.27780  1.7001   \n",
       "1  2.6512  0.0  4.1553  ...   0.0  3.8342  1.7536  1.8910  0.91983  0.0000   \n",
       "\n",
       "     4093    4094    4095  Unnamed: 4097  \n",
       "0  0.0000  1.9559  6.1765            NaN  \n",
       "1  2.0523  1.0713  1.4447            NaN  \n",
       "\n",
       "[2 rows x 4098 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_embeddings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.1 (tf21-py37)",
   "language": "python",
   "name": "tf21-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
