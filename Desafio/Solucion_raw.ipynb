{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Solucion.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPWRnEx2oTvM"
      },
      "source": [
        "```\n",
        "ME72: Maestría en Métodos Cuantitativos para la Gestión y Análisis de Datos\n",
        "M72109: Analisis de datos no estructurados\n",
        "Universidad de Buenos Aires - Facultad de Ciencias Economicas (UBA-FCE)\n",
        "Año: 2021\n",
        "Profesor: Facundo Santiago, Javier Ignacio Garcia Fronti\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWBLdBSioTvO"
      },
      "source": [
        "# ¿Qué tan memorable es un video?: Solución base utilizando videos, images y audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbe7972dpDfx"
      },
      "source": [
        "Este notebook les permitirá tener a disposición todos los recursos que se vieron en durante la materia. Todos los fragmentos de código se descargaran utilizando la sección preparación del ambiente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXdA6Yg761jz"
      },
      "source": [
        "## Preparación del ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZrG1xI-61j0"
      },
      "source": [
        "### Sets de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xb7yWkB61j1"
      },
      "source": [
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/ground_truth.csv --directory-prefix ./Data/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/Features/audio_vectors.csv --directory-prefix ./Data/Features/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/Features/c3d_vectors.csv --directory-prefix ./Data/Features/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/Features/caption_features.csv --directory-prefix ./Data/Features/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/Features/colors_features.csv --directory-prefix ./Data/Features/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ9KM2hm61j7"
      },
      "source": [
        "### Librerías de codigo que se utilizan durante el curso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAPdJg4j61j8"
      },
      "source": [
        "#### Audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgEPMkE861j9"
      },
      "source": [
        "!wget -N https://storage.googleapis.com/audioset/yamnet.h5 --directory-prefix ./Models/yamnet/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Audio/Models/yamnet/yamnet_class_map.csv --directory-prefix ./Models/yamnet/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Audio/Utils/audio_plotter.py --directory-prefix ./Utils/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Audio/yamnet/yamnet.py --directory-prefix ./yamnet/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Audio/yamnet/params.py --directory-prefix ./yamnet/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Audio/yamnet/features_lib.py --directory-prefix ./yamnet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jWAZV8H61kI"
      },
      "source": [
        "!pip install librosa\n",
        "!pip install moviepy\n",
        "!pip install soundfile\n",
        "!pip install azure-cognitiveservices-speech"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mIgYB7261kS"
      },
      "source": [
        "#### NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNeu_Nue61kT"
      },
      "source": [
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Utils/TextDataset.py --directory-prefix ./Utils/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Utils/TextNormalizer.py --directory-prefix ./Utils/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Utils/PadSequenceTransformer.py --directory-prefix ./Utils/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Utils/Word2VecVectorizer.py --directory-prefix ./Utils/\n",
        "!wget https://santiagxf.blob.core.windows.net/public/Word2Vec/model.bin --directory-prefix ./Models/Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYch8GOa61kY"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install unidecode\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7n2pmiw61kc"
      },
      "source": [
        "#### Vision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7COK8kZ61kd"
      },
      "source": [
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Vision/Utils/Cognitive.py --directory-prefix ./Utils/\n",
        "!wget -N https://raw.githubusercontent.com/santiagxf/M72109/master/Vision/Utils/Plotting.py --directory-prefix ./Utils/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsJun4BI61kl"
      },
      "source": [
        "!pip install tensorflow-datasets\n",
        "!pip install azure-cognitiveservices-vision-computervision\n",
        "!pip install matplotlib\n",
        "!pip install skimage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utQ0fxnu61ko"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLjNwmAJ61kp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, SpatialDropout1D\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from yamnet.yamnet import yamnet_frames_model\n",
        "import yamnet.yamnet as yamnet_model\n",
        "from yamnet.params import Params\n",
        "\n",
        "from Utils.audio_plotter import plot_audio_embeddings\n",
        "from Utils.TextDataset import ClassificationDataset\n",
        "from Utils.TextNormalizer import TweetTextNormalizer\n",
        "from Utils.Word2VecVectorizer import Word2VecVectorizer\n",
        "from Utils.PadSequenceTransformer import PadSequenceTransformer\n",
        "\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ucs_gunq61ku"
      },
      "source": [
        "## Solución"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBDymaXtoTvp"
      },
      "source": [
        "Cuentan con 2 tipos de anotaciones para cada uno de los fragmentos de video disponibles:\n",
        " - **memorability_score:** Representa el puntaje de memorabilidad de la secuencia en particular, desde 0 a 1. Valores más grandes son mejores.\n",
        " - **memorable:** Variable categórica que representa si un video es memorable o no. Un video con `memorability_score` superior a `0.5` es marcado como memorable (`1`), sino es marcado como no memorable (`0`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69lG6CJyoTvq"
      },
      "source": [
        "labels = pd.read_csv('Data/ground_truth.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXS_1KRBoTvt",
        "outputId": "570584c2-f3a5-464e-dd8d-7392a5981d46"
      },
      "source": [
        "labels.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_name</th>\n",
              "      <th>start(sec)</th>\n",
              "      <th>end(sec)</th>\n",
              "      <th>sequence_name</th>\n",
              "      <th>Neutral (1)_Typical (0)</th>\n",
              "      <th>nb_annotations</th>\n",
              "      <th>memorability_score</th>\n",
              "      <th>memorabable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127 hours</td>\n",
              "      <td>2000</td>\n",
              "      <td>2010</td>\n",
              "      <td>127_hours_2000_2010_1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>127 hours</td>\n",
              "      <td>2182</td>\n",
              "      <td>2192</td>\n",
              "      <td>127_hours_2182_2192_5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  movie_name  start(sec)  end(sec)          sequence_name  \\\n",
              "0  127 hours        2000      2010  127_hours_2000_2010_1   \n",
              "1  127 hours        2182      2192  127_hours_2182_2192_5   \n",
              "\n",
              "   Neutral (1)_Typical (0)  nb_annotations  memorability_score  memorabable  \n",
              "0                        0               5                 1.0            1  \n",
              "1                        1               8                 0.0            0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Xi8axtPx7b"
      },
      "source": [
        "> Note que aquí nuestras muestras son \"secuencias\" de determinadas películas. En total dispone de 609 secuencias con el nombre `sequence_name`. El mismo nombre se generó automáticamente concatenando el nombre de la pelicula a la que pertenece la secuencia (movie_name), seguido del segundo en el que comienza la secuencia, seguido del segundo en el que termina, seguido de un numero que indica el número de secuencia. Por ejemplo, la secuencia `127_hours_2000_2010_1` es un fragmento de la pelicula \"127 hours\", que va desde el segundo 2000 (00:33:20 hrs.) al segundo 2010 (00:33:30 hrs.) y es el fragmento número 1. Esta información es totalmente irrelevante para el problema de memorabilidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-phMVhQA61mQ"
      },
      "source": [
        "### Datos no estructurados\n",
        "\n",
        "Dado que los conjuntos de datos pueden ser de gran tamaño, descargue solo los datos que necesita:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt2Xp4oe61mR"
      },
      "source": [
        "#### Para utilizar los cuadros (frames)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn1Cn72C61mS"
      },
      "source": [
        "!wget -N https://santiagxf.blob.core.windows.net/public/Memorability/frames.tar.gz --directory-prefix ./Data/Raw/\n",
        "!tar zxvf ./Data/Raw/frames.tar.gz --directory ./Data/Raw/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOQCDTj5PT5U"
      },
      "source": [
        "> En el directorio `Data/Raw/frames` encontraran todos los cuadros extraidos de cada una de las secuencias. Los cuadros están disponibles cada 2 segundos por lo cual disponen de 5 cuadros por cada secuencia. Todos los cuadros pertenecientes a una secuencia están almacenados en una carpeta con el mismo nombre de la secuencia a la que pertenece, por lo que la carpeta `127_hours_2000_2010_1` contiene todos los cuadros pertenecientes a la secuencia `127_hours_2000_2010_1` en el conjunto de datos de anotaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkwfP4sC61mw"
      },
      "source": [
        "# completar solución"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL1Q0cmy61nK"
      },
      "source": [
        "#### Para utilizar los audios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttFN_wja61nO"
      },
      "source": [
        "!wget -N https://santiagxf.blob.core.windows.net/public/Memorability/audios.tar.gz --directory-prefix ./Data/Raw/\n",
        "!tar zxvf ./Data/Raw/audios.tar.gz --directory ./Data/Raw/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_pWzWaxOuoC"
      },
      "source": [
        "> En el directorio `Data/Raw/audios` encontraran todos los audios correspondientes a cada una de las secuencias de los videos. Cada audio tiene el mismo nombre de la secuencia a la que pertenece, por lo que el archivo `127_hours_2000_2010_1.wav` pertenece a la secuencia `127_hours_2000_2010_1` en el conjunto de datos de anotaciones. Los audios están en formato `wav`, que si bien ocupan mayor espacio, son más sencillos de procesar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U69bgtv861nd"
      },
      "source": [
        "# completar solución"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WCX-dri61nf"
      },
      "source": [
        "#### Para utilizar los videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Hx9fhN61ng"
      },
      "source": [
        "!wget -N https://santiagxf.blob.core.windows.net/public/Memorability/sources.tar.gz --directory-prefix ./Data/Raw/\n",
        "!tar zxvf ./Data/Raw/sources.tar.gz --directory ./Data/Raw/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTpqX3DGOnzJ"
      },
      "source": [
        "> En el directorio `Data/Raw/sources` encontraran todas las secuencias utilizadas en este desafío. El archivo `Data/ground_truth.csv` contine los nombres de las peliculas a las que corresponde cada fragmento en caso que quieran revisarlos. Cada video tiene el mismo nombre de la secuencia a la que pertenece, por lo que el archivo `127_hours_2000_2010_1.mp4` pertenece a la secuencia `127_hours_2000_2010_1` en el conjunto de datos de anotaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teUH1dVe61nz"
      },
      "source": [
        "# completar solución"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}