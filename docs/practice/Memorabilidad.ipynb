{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPWRnEx2oTvM"
      },
      "source": [
        "```\n",
        "ME72: Maestría en Métodos Cuantitativos para la Gestión y Análisis de Datos\n",
        "M72109: Analisis de datos no estructurados\n",
        "Universidad de Buenos Aires - Facultad de Ciencias Economicas (UBA-FCE)\n",
        "Año: 2024\n",
        "Profesor: Facundo Santiago, Javier Ignacio Garcia Fronti\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWBLdBSioTvO"
      },
      "source": [
        "# Desafio: ¿Qué tan memorable es un video?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbe7972dpDfx"
      },
      "source": [
        "Como trabajo final para la materia, les proponemos resolver un desafio de memorabilidad de un video, el cual requerirá de utilizar todos los conceptos que revisamos en la materia **al mismo tiempo**: imagenes, audio y texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT_t9OxYwKIc"
      },
      "source": [
        "## ¿De que se trata el desafío?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1_-eKx3oTvT"
      },
      "source": [
        "Esta tarea se centra en el problema de predecir qué tan memorable es un video para un espectador. Definiremos a un video como memorable como la probabilidad de que se recuerde tal video luego de un lapso de tiempo determinado.\n",
        "\n",
        "Recibirán un extenso conjunto de datos de videos que van acompañados de anotaciones memorables, así como predictores (features) extraídos previamente que reflejan distintos preprocesamientos de los videos para que la tarea le resulte más sencilla. Las etiquetas (labels) se ha recopilado a través de pruebas de reconocimiento y, por lo tanto, es el resultado de una medición objetiva del rendimiento de la memoria.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Docs/memorability.PNG' width=600 />\n",
        "\n",
        "*Creditos del desafio original:*\n",
        "\n",
        "http://www.multimediaeval.org/mediaeval2019/memorability/\n",
        "\n",
        "Mihai Gabriel Constantin, University Politehnica of Bucharest, Romania\n",
        "Bogdan Ionescu, University Politehnica of Bucharest, Romania\n",
        "Claire-Hélène Demarty, Technicolor, France\n",
        "Quang-Khanh-Ngoc Duong, Technicolor, France\n",
        "Xavier Alameda-Pineda, INRIA, France\n",
        "Mats Sjöberg, CSC, Finland\n",
        "\n",
        "Para mas información sobre esta tarea, puede revisar [Overview of The MediaEval 2021 Predicting Media Memorability Task](https://arxiv.org/abs/2112.05982)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K6p37ncoTvU"
      },
      "source": [
        "## Direcciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr_jJ5wAoTvV"
      },
      "source": [
        "Deberán entrenar modelos de aprendizaje automático capaces de inferir la memorabilidad de video a partir del contenido audiovisual. Para hacerlo, podrán optar por utilizar los videos directamente o utilizar características (features) que fueron extraídas desde los mismos utilizando algunas de las técnicas que vimos en este curso.\n",
        "Utilizando estos datos, deberán evaluar la performance del modelo utilizando un set de datos de evaluación. Los modelos se evaluarán a través de métricas de evaluación estándar utilizadas en las tareas de clasificación y regresión (dependiendo del tipo de desafío que elijan).\n",
        "\n",
        "> **IMPORTANTE AÑO 2023**: Para reducir el alcance del trabajo final, solamente se solicita que resuelvan este trabajo práctico utilizando los predictores que corresponden a texto. **Entrene al menos 2 modelos correspondientes a la sección de NLP**. Puede utilizar la siguiente plantilla para escribir su solución:\n",
        "\n",
        "- [Solución base utilizando predictores basados en texto (NLP) - ¿Qué tan memorable es un video? ](https://colab.research.google.com/github/santiagxf/M72109/blob/master/Desafio/Solucion_features_nlp.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdX8oMEkoTvp"
      },
      "source": [
        "## Anotaciones para el problema de memorabilidad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBDymaXtoTvp"
      },
      "source": [
        "Cuentan con 2 tipos de anotaciones para cada uno de los fragmentos de video disponibles:\n",
        " - **memorability_score:** Representa el puntaje de memorabilidad de la secuencia en particular, desde 0 a 1. Valores más grandes son mejores.\n",
        " - **memorable:** Variable categórica que representa si un video es memorable o no. Un video con `memorability_score` superior a `0.5` es marcado como memorable (`1`), sino es marcado como no memorable (`0`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMtIaR4PFkRu"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/ground_truth.csv \\\n",
        "  --directory-prefix ./Data/ --no-clobber --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69lG6CJyoTvq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "labels = pd.read_csv('Data/ground_truth.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "kXS_1KRBoTvt",
        "outputId": "3dab050d-ca64-4a70-86fb-67b2b7451b53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_name</th>\n",
              "      <th>start(sec)</th>\n",
              "      <th>end(sec)</th>\n",
              "      <th>sequence_name</th>\n",
              "      <th>Neutral (1)_Typical (0)</th>\n",
              "      <th>nb_annotations</th>\n",
              "      <th>memorability_score</th>\n",
              "      <th>memorabable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127 hours</td>\n",
              "      <td>2000</td>\n",
              "      <td>2010</td>\n",
              "      <td>127_hours_2000_2010_1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>127 hours</td>\n",
              "      <td>2182</td>\n",
              "      <td>2192</td>\n",
              "      <td>127_hours_2182_2192_5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>127 hours</td>\n",
              "      <td>271</td>\n",
              "      <td>281</td>\n",
              "      <td>127_hours_271_281_1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>127 hours</td>\n",
              "      <td>285</td>\n",
              "      <td>295</td>\n",
              "      <td>127_hours_285_295_2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>127 hours</td>\n",
              "      <td>328</td>\n",
              "      <td>338</td>\n",
              "      <td>127_hours_328_338_3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  movie_name  start(sec)  end(sec)          sequence_name  \\\n",
              "0  127 hours        2000      2010  127_hours_2000_2010_1   \n",
              "1  127 hours        2182      2192  127_hours_2182_2192_5   \n",
              "2  127 hours         271       281    127_hours_271_281_1   \n",
              "3  127 hours         285       295    127_hours_285_295_2   \n",
              "4  127 hours         328       338    127_hours_328_338_3   \n",
              "\n",
              "   Neutral (1)_Typical (0)  nb_annotations  memorability_score  memorabable  \n",
              "0                        0               5            1.000000            1  \n",
              "1                        1               8            0.000000            0  \n",
              "2                        1               4            0.750000            1  \n",
              "3                        1               5            0.800000            1  \n",
              "4                        0               7            0.714286            1  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5037jMtRbHH"
      },
      "source": [
        "> Note que aquí nuestras muestras son \"secuencias\" de determinadas películas. En total dispone de 609 secuencias con el nombre `sequence_name`. El mismo nombre se generó automáticamente concatenando el nombre de la pelicula a la que pertenece la secuencia (movie_name), seguido del segundo en el que comienza la secuencia, seguido del segundo en el que termina, seguido de un numero que indica el número de secuencia. Por ejemplo, la secuencia `127_hours_2000_2010_1` es un fragmento de la pelicula \"127 hours\", que va desde el segundo 2000 (00:33:20 hrs.) al segundo 2010 (00:33:30 hrs.) y es el fragmento número 1. Esta información es totalmente irrelevante para el problema de memorabilidad pero **el nombre de la secuencia (`sequence_name`) será su clave primeria para vincular los diferentes conjuntos de datos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlJ1JocvGMrn"
      },
      "source": [
        "### Entrega"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKfBU99VFrFP"
      },
      "source": [
        "Para entregar la solución, podrán utilizar la plataforma que más les resulta conveniente. En caso de optar por entregar un notebook de Google Colaboratory, pueden utilizar la siguiente plantilla de entrega donde contarán con todas las herramientas que vimos en el curso ya instaladas y listas para utilizar. Todos los fragmentos de código, librerias y sets de datos se descargarán automaticamente cuando ejecuten las celdas \"preparación del ambiente\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtKSuPT1GH0S"
      },
      "source": [
        "- [Solución base utilizando predictores basados en texto (NLP) - ¿Qué tan memorable es un video? ](https://colab.research.google.com/github/santiagxf/M72109/blob/master/Desafio/Solucion_features_nlp.ipynb)\n",
        "- [Solución base utilizando predictores pre-procesados - ¿Qué tan memorable es un video? ](https://colab.research.google.com/github/santiagxf/M72109/blob/master/Desafio/Solucion_features.ipynb)\n",
        "- [Solución base utilizando videos, images y audio - ¿Qué tan memorable es un video? ](https://colab.research.google.com/github/santiagxf/M72109/blob/master/Desafio/Solucion_raw.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54ih544DoTvw"
      },
      "source": [
        "## Elije tu propia aventura"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlw8T_TJoTvx"
      },
      "source": [
        "En este desafío, se les propone elegir la dificultad con la que quieren trabajar para solucionar el problema en cuestión. Dependiendo de la elección, son las herramientas que tendrán a su disosición para resolver el problema. Pueden utilizar algunas de las sugerencias, todas las sugerencias, o probar alguna técnica que conozcan y que les parezca interesante de probar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtSQSwfloTv4"
      },
      "source": [
        "### Resolver el desafío utilizando predictores preprocesados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU7gx-HOoTv5"
      },
      "source": [
        "En esta configuración del desafio, ya hay bastante trabajo realizado. Los videos han sido preprocesados para generar un conjunto de predictores que pueden ayudar a resolver el problema. Estos predictores se entregan como un conjunto de archivos en formato CSV.\n",
        "\n",
        "A pesar de que esta opción pueda parecer sencilla, ofrece sus propios desafíos ya que tienen a disposición muchos predictores pero en dominios distintos: audio, texto, embeddings, etc. Deberán desarrollar una técnica que pueda hacer sentido de esto en su conjunto.\n",
        "\n",
        "A continuación detallamos los predictores con los que contarán:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEWtmWBCHBwt"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/Features/audio_vectors.csv \\\n",
        "  --directory-prefix ./Data/Features/ --quiet\n",
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/Features/caption_features.csv \\\n",
        "  --directory-prefix ./Data/Features/ --quiet\n",
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/Desafio/Data/Features/colors_features.csv \\\n",
        "  --directory-prefix ./Data/Features/ --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqqS8evHoTv5"
      },
      "source": [
        "#### Descripciónes de las imagenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU6rU8EkoTv6"
      },
      "source": [
        "Cuentan con las descripciones de cuadros (frames) de cada una de las secuencias. Estos frames están extraidos cada 1 segundo y las descripciones se generaron utilizando la API de Computer Vision de Azure Cognitive Services. Cada una de las descripciones forma una oración, y por lo tanto, por cada secuencia tendrán disponible un parrafo con 10 oraciones describiendo cada una de las escenas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_8cKMFxoTv7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "captions = pd.read_csv('Data/Features/caption_features.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "CfXroshYoTv-",
        "outputId": "47c99c8a-f478-49d2-ec68-cd39987acaaf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence_name</th>\n",
              "      <th>cc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127_hours_2000_2010_1</td>\n",
              "      <td>a man in a suit and tie standing in front of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>127_hours_2182_2192_5</td>\n",
              "      <td>a man holding a toothbrush in his mouth. a wom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>127_hours_271_281_1</td>\n",
              "      <td>a view of a mountain range from a plane. a fir...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           sequence_name                                                 cc\n",
              "0  127_hours_2000_2010_1  a man in a suit and tie standing in front of a...\n",
              "1  127_hours_2182_2192_5  a man holding a toothbrush in his mouth. a wom...\n",
              "2    127_hours_271_281_1  a view of a mountain range from a plane. a fir..."
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "captions.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG5cfz538iqC",
        "outputId": "b7c5d746-740b-4a01-eb96-542935f040a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(660, 2)"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "captions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNcrFKGYFkSQ"
      },
      "source": [
        "#### Colores de las imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u7KCGjZFkSQ"
      },
      "source": [
        "Los colores en una imágen pueden ser representativos de lo que uno está viendo. Por ejemplo, en una secuencia de terror, las imagenes con fondos oscuros quizás prevalezcan. Para capturar esto, cuentan con anotaciones para cada secuencia, para cada cuadro (frame de la secuencia) con los valores correspondientes al color más dominante en el fondo y el color más dominante en primer plano. Los posibles colores son: `black`, `blue`, `brown`, `gray`, `green`, `orange`, `pink`, `purple`, `red`, `teal`, `white` y `yellow`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYYO91tlFkSR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "colors = pd.read_csv('Data/Features/colors_features.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Gbzux4GoFkST",
        "outputId": "fff1a267-96e0-4763-9865-380081c2bb41"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence_name</th>\n",
              "      <th>dominant_background</th>\n",
              "      <th>dominant_foreground</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127_hours_2000_2010_1</td>\n",
              "      <td>Black</td>\n",
              "      <td>Black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>127_hours_2000_2010_1</td>\n",
              "      <td>Grey</td>\n",
              "      <td>Black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>127_hours_2000_2010_1</td>\n",
              "      <td>Black</td>\n",
              "      <td>Black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>127_hours_2000_2010_1</td>\n",
              "      <td>Black</td>\n",
              "      <td>Black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>127_hours_2000_2010_1</td>\n",
              "      <td>Black</td>\n",
              "      <td>Black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>127_hours_2182_2192_5</td>\n",
              "      <td>Black</td>\n",
              "      <td>Black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>127_hours_2182_2192_5</td>\n",
              "      <td>Black</td>\n",
              "      <td>Yellow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>127_hours_2182_2192_5</td>\n",
              "      <td>Black</td>\n",
              "      <td>Yellow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>127_hours_2182_2192_5</td>\n",
              "      <td>Brown</td>\n",
              "      <td>Yellow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>127_hours_2182_2192_5</td>\n",
              "      <td>Brown</td>\n",
              "      <td>Yellow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           sequence_name dominant_background dominant_foreground\n",
              "0  127_hours_2000_2010_1               Black               Black\n",
              "1  127_hours_2000_2010_1                Grey               Black\n",
              "2  127_hours_2000_2010_1               Black               Black\n",
              "3  127_hours_2000_2010_1               Black               Black\n",
              "4  127_hours_2000_2010_1               Black               Black\n",
              "5  127_hours_2182_2192_5               Black               Black\n",
              "6  127_hours_2182_2192_5               Black              Yellow\n",
              "7  127_hours_2182_2192_5               Black              Yellow\n",
              "8  127_hours_2182_2192_5               Brown              Yellow\n",
              "9  127_hours_2182_2192_5               Brown              Yellow"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "colors.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R47xkne7ILU",
        "outputId": "8d50be93-ab20-44e3-d93c-44122b47b71a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3300, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "colors.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq1vftfSKd5H"
      },
      "source": [
        "> Noten que en este caso, disponen de esta información por cada uno de los cuadros (es decir, 5 anotaciones por cada secuencia y por lo tanto deberán elejir una estrategia para quedarse con 1 solo valor por secuencia. Por ejemplo: el color más frecuente, o el color más raro. También pueden optar por utilizar variables categoricas en el sentido \"contine_fondo_oscuro\" significando una secuencia en que el fondo en algún cuadro es oscuro/negro.\n",
        "\n",
        "El siguiente ejemplo muestra como tomar por ejemplo el valor más frecuente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdCgKr-u7Sor"
      },
      "outputs": [],
      "source": [
        "grouped_colors = colors.groupby('sequence_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K9Pj9Sk7b1n",
        "outputId": "fe73b9c1-2bf7-4d13-8900-b5beef27be17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sequence_name\n",
              "127_hours_2000_2010_1     Black\n",
              "127_hours_2182_2192_5     Black\n",
              "127_hours_271_281_1       Brown\n",
              "127_hours_285_295_2       Brown\n",
              "127_hours_328_338_3      Yellow\n",
              "                          ...  \n",
              "Youth_1996_2006_26        Brown\n",
              "Youth_2023_2033_23        Black\n",
              "Youth_2155_2165_28        Black\n",
              "Youth_2400_2410_24        Black\n",
              "Youth_2483_2493_25        Brown\n",
              "Name: dominant_background, Length: 660, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mode = lambda x: x.mode() if len(x) > 2 else np.array(x)\n",
        "grouped_colors['dominant_background'].agg(mode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPylGpWaoTwA"
      },
      "source": [
        "#### Vectores de audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GBcZOtjoTwB"
      },
      "source": [
        "Se corresponden a las representaciones (embeddings) utilizados por la red `YAMNet` que vimos en el curso. `YAMNet` es un modelo que utiliza la misma ténica que las redes CNN pero construyendo imágenes a partir de audio (llamados parches o patchs). Cada uno de estos patchs es el resultado de calcular espectrogramas de audio, creando así parches de imágenes 2D para utilizar en nuestro modelo.\n",
        "\n",
        "Los vectores generados por `YAMNet` son vectores en un espacio de 1024-D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDAKlAJ1oTwB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "audio_embeddings = pd.read_csv('Data/Features/audio_vectors.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "VVYDOID8oTwE",
        "outputId": "35d9257a-8c1a-4da3-9eab-f43174aff0cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence_name</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>1022</th>\n",
              "      <th>1023</th>\n",
              "      <th>1024</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127_hours_2000_2010_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.796399</td>\n",
              "      <td>0.009879</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.492673</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.391333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>127_hours_2000_2010_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003163</td>\n",
              "      <td>0.010787</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.173500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.177809</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 1025 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           sequence_name    1         2         3         4         5    6  \\\n",
              "0  127_hours_2000_2010_1  0.0  0.796399  0.009879  0.000000  0.000000  0.0   \n",
              "1  127_hours_2000_2010_1  0.0  0.000000  0.000000  0.003163  0.010787  0.0   \n",
              "\n",
              "     7    8    9  ...  1015  1016  1017      1018  1019  1020  1021      1022  \\\n",
              "0  0.0  0.0  0.0  ...   0.0   0.0   0.0  0.492673   0.0   0.0   0.0  0.391333   \n",
              "1  0.0  0.0  0.0  ...   0.0   0.0   0.0  0.173500   0.0   0.0   0.0  0.177809   \n",
              "\n",
              "   1023  1024  \n",
              "0   0.0   0.0  \n",
              "1   0.0   0.0  \n",
              "\n",
              "[2 rows x 1025 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "audio_embeddings.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lone-U26MLUs",
        "outputId": "b7c88c2e-f31f-458d-d05e-4eeb81b4e3eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13200, 1025)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "audio_embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZvr8h2-LcnN"
      },
      "source": [
        "Para cada secuencia dispone de 20 filas, las cuales representan el tiempo. Recuerde que todas las secuencias tienen la misma longitud. Dado que la estructura de datos `csv` no permite almacenar datos multidimensionales, deberemos correjir esto de forma manual y trasformar las muestras a tensores de `(20, 1024)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDZV8z5C-Z_H"
      },
      "outputs": [],
      "source": [
        "audio_embeddings_vectors = audio_embeddings.to_numpy()[:,1:].reshape((-1,20,1024))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9NsRxta843X",
        "outputId": "e1173719-ca58-4d78-84a8-053802a0792e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(660, 20, 1024)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "audio_embeddings_vectors.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhIQ8dJ3oTvx"
      },
      "source": [
        "### Resolver el desafío utilizando los datos de origen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_vGLIxToTv0"
      },
      "source": [
        "Esta configuración del desafío es la más similar a la vida real, y solo contaran con un conjunto de videos en formato MP4 como datos de entrada junto con sus anotaciones de memorabilidad en formato CSV. Cualquier procesamiento de datos deberá realizarse utilizando esta información únicamente. Dado que algunos procesamientos de datos sobre videos pueden ser complejos, adicionalmente contarán además con:\n",
        " - Imágenes extraidas cada 2 segundos por cada secuencia a analizar\n",
        " - Tracks de audio disponibles en formato WAV listos para utilizar\n",
        "\n",
        "A pesar de que el video a sido separado en imagenes y audio, resolver el desafío en utilizando estos datos será una tarea compleja. Sin embargo, en el contexto de sus organizaciones, normalmente se encontrarán con esta dificultad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slqhMQfooTv3"
      },
      "source": [
        "#### Cuadros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB67LMgioTv4"
      },
      "source": [
        "En el directorio `Data/Raw/frames` encontraran todos los cuadros de cada una de los videos disponibles. Los cuadros correspondientes cada video están en un directorio con su mismo nombre. Los cuadros están muestreados cada 2 segundos por lo cual disponen de 5 cuadros por cada secuencia.\n",
        "\n",
        "Algunas ideas:\n",
        "\n",
        " - Aplicar modelos de convolución directamente sobre las imagenes y sobre las secuencias de cuadros.\n",
        " - Aplicar técnicas de descripción de imagenes utilizando Servicios Cognitivos\n",
        " - Reconocimiento de lugares claves.\n",
        " - Los fragmentos tienen personas famosas, ya que son actores de cine y televisión. ¿Será importante?\n",
        " - Colores de la escena."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6A9oK-uoTv2"
      },
      "source": [
        "#### Audios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LACmI1EUoTv3"
      },
      "source": [
        "En el directorio `Data/Raw/audios` encontraran todos los audios correspondientes a cada una de las secuencias de los videos. Los audios están en formato `wav`, que si bien ocupan mayor espacio, son más sencillos de procesar.\n",
        "\n",
        "Algunas ideas:\n",
        "\n",
        " - Aplicar técnicas de speech-to-text.\n",
        " - Aplicar técnicas de embeddings de audio.\n",
        " - Clasificar primero el audio (en por ejemplo 'instrumento musical', 'personas charlando', 'exterior', 'aire libre') y luego utilizarlos para resolver el problema."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Memorabilidad.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}