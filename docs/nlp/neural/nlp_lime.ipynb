{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "allennlp_interpret.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernel_info": {
      "name": "nlp-py38"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - PyTorch",
      "language": "python",
      "name": "azureml_py38_pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKENeWEEwKIb"
      },
      "source": [
        "Explicando predicciones utilizando LIME\n",
        "======================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JctlpI10jJ15"
      },
      "source": [
        "Introducción\n",
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT_t9OxYwKIc"
      },
      "source": [
        "AllenNLP es un framework general de aprendizaje profundo para NLP, establecido por el mundialmente famoso Allen Institute for AI Lab. Contiene modelos de referencia de última generación que se ejecutan sobre el `PyTorch`. AllenNLP es una librería que ademas busca implementar abstracciones que permitan el rápido desarrollo de modelos y reutilización de componentes al despegarse de detalles de implementación de cada modelo.\n",
        "\n",
        "En este ejemplo, veremos como utilizar esta librería para generar salency maps que nos permitan interpretar las predicciones de nuestros modelos basados en `transformers`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcyc_TQ6dis7"
      },
      "source": [
        "### Para ejecutar este notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJFcNrbmjJ17"
      },
      "source": [
        "Para ejecutar este notebook, instale las siguientes librerias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgK8b6e_jJ17",
        "outputId": "23a2d941-3f8e-40ac-e88a-1ae7da3588a4"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Datasets/mascorpus/tweets_marketing.csv \\\n",
        "    --quiet --no-clobber --directory-prefix ./Datasets/mascorpus/\n",
        "\n",
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Utils/TextDataset.py \\\n",
        "    --quiet --no-clobber --directory-prefix ./Utils/\n",
        "    \n",
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/docs/nlp/neural/allennlp_interpret.txt \\\n",
        "    --quiet --no-clobber\n",
        "!pip install -r allennlp_interpret.txt --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 738 kB 43.4 MB/s \n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement allennlp-interpret (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for allennlp-interpret\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuUoW80kwffw"
      },
      "source": [
        "Si ejecuta en Google Colab, adicionalmente deberá:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPJ-xKmrwffx",
        "outputId": "8ae718ea-5aab-45a9-a1c8-66d1952ddea5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install eli5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.1-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 58.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 63.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 25.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.3\n",
            "Collecting eli5\n",
            "  Downloading eli5-0.11.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (21.2.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5) (2.11.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5) (2.0.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr7vZC0cwff0"
      },
      "source": [
        "Descargaremos un modelo previamente entrenando el el problema de clasificación de Tweets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgXwXTX2wff1"
      },
      "source": [
        "!wget https://santiagxf.blob.core.windows.net/public/models/tweet_classification_bert.zip --no-clobber --quiet\n",
        "!unzip -qq tweet_classification_bert.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntcs1AlpfckX"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gBXNzwYwKIu"
      },
      "source": [
        "Cargamos el set de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuUI_dXFxh6u"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"tweet_classification_bert\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU9ZxTd9yNrf"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "def predict_proba(text: str) -> List[float]:\n",
        "  inputs = tokenizer(text, padding=True, truncation=True, max_length=20, return_tensors='pt')\n",
        "  predictions = model(**inputs)\n",
        "  smx = torch.nn.Softmax(dim = 1)(predictions.logits)\n",
        "  #odds = predictions.logits.exp()\n",
        "  #probs = odds/(odds.sum(axis=1))\n",
        "\n",
        "  \n",
        "  #smx = probs.detach().numpy()\n",
        "  #return np.sum(smx, )\n",
        "  #smx[smx.argmax(axis=1)]+=1-smx.sum(axis=1)\n",
        "  #return smx\n",
        "  return smx.detach().numpy()"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwDtTdXr7J0N"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bswgkwan7Kn7",
        "outputId": "cf6b252d-80a1-4910-815f-4c33339937c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_proba([\"la casa estaba si vacia claro oppp\", \"la casa se salio de control\"])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.10890099, 0.02119908, 0.04010604, 0.04518595, 0.02475744,\n",
              "        0.74086446, 0.01898602],\n",
              "       [0.17640594, 0.02150902, 0.08571446, 0.10166235, 0.03061507,\n",
              "        0.54807955, 0.03601361]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xW2YUvn9J-B"
      },
      "source": [
        ""
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMBEop__zFAI"
      },
      "source": [
        "target_names = ['ALIMENTACION', 'AUTOMOCION', 'BANCA', 'BEBIDAS', 'DEPORTES', 'RETAIL', 'TELCO']"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GpTjik0zrV_"
      },
      "source": [
        "import eli5\n",
        "from eli5.lime import TextExplainer\n",
        "\n",
        "te = TextExplainer(random_state=42, n_samples=500).fit(\"Nos estafaron en mercadona. No vuelvo a comprar alli jamas\", predict_proba)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9abSfxwd1M7B",
        "outputId": "826d5461-3dfb-48d9-e26c-5d05226f3efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "te.show_prediction(target_names=target_names)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=ALIMENTACION\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.020</b>, score <b>-3.907</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 98.26%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.156\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 83.88%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -3.751\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 90.43%); opacity: 0.83\" title=\"-0.209\">nos</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.11%); opacity: 0.84\" title=\"0.284\">estafaron</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.13%); opacity: 0.86\" title=\"-0.509\">en</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 62.65%); opacity: 0.98\" title=\"-1.458\">mercadona</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 86.07%); opacity: 0.84\" title=\"-0.356\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.73%); opacity: 0.82\" title=\"-0.169\">vuelvo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.11%); opacity: 0.82\" title=\"-0.158\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.21%); opacity: 0.95\" title=\"-1.211\">comprar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.061\">alli</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.56%); opacity: 0.83\" title=\"0.269\">jamas</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=AUTOMOCION\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.018</b>, score <b>-4.041</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 95.71%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.565\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.71%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -3.475\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 87.48%); opacity: 0.84\" title=\"0.306\">nos</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.31%); opacity: 0.87\" title=\"0.542\">estafaron</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.33%); opacity: 0.82\" title=\"0.181\">en</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.77%); opacity: 0.84\" title=\"-0.296\">mercadona</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 94.13%); opacity: 0.81\" title=\"-0.104\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.65%); opacity: 0.87\" title=\"0.528\">vuelvo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.33%); opacity: 0.83\" title=\"0.277\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.92%); opacity: 0.85\" title=\"-0.437\">comprar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.52%); opacity: 0.81\" title=\"-0.120\">alli</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.77%); opacity: 0.82\" title=\"-0.140\">jamas</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=BANCA\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.045</b>, score <b>-3.086</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 95.25%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.654\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 88.10%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.432\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 78.44%); opacity: 0.88\" title=\"0.665\">nos</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.86%); opacity: 0.90\" title=\"0.828\">estafaron</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.73%); opacity: 0.82\" title=\"0.169\">en</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.60%); opacity: 0.90\" title=\"-0.841\">mercadona</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 89.42%); opacity: 0.83\" title=\"-0.241\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.03%); opacity: 0.84\" title=\"-0.287\">vuelvo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.10%); opacity: 0.82\" title=\"0.188\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.12%); opacity: 0.81\" title=\"0.080\">comprar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.59%); opacity: 0.89\" title=\"-0.748\">alli</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.30%); opacity: 0.82\" title=\"-0.125\">jamas</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=BEBIDAS\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.007</b>, score <b>-5.005</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 96.06%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.501\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 81.67%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -4.503\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 90.56%); opacity: 0.83\" title=\"0.204\">nos</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.37%); opacity: 0.83\" title=\"0.210\">estafaron</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.33%); opacity: 0.85\" title=\"-0.384\">en</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 62.84%); opacity: 0.98\" title=\"-1.447\">mercadona</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 83.89%); opacity: 0.85\" title=\"-0.439\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.15%); opacity: 0.90\" title=\"0.815\">vuelvo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.82%); opacity: 0.82\" title=\"-0.166\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 69.28%); opacity: 0.94\" title=\"-1.103\">comprar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.22%); opacity: 0.90\" title=\"-0.812\">alli</span><span style=\"opacity: 0.80\"> jamas</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=DEPORTES\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.011</b>, score <b>-4.492</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 95.51%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.605\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 83.47%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -3.887\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 95.55%); opacity: 0.81\" title=\"-0.070\">nos</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.83%); opacity: 0.84\" title=\"0.294\">estafaron</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.41%); opacity: 0.82\" title=\"-0.122\">en</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.82%); opacity: 0.82\" title=\"-0.196\">mercadona</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 88.56%); opacity: 0.83\" title=\"-0.269\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.22%); opacity: 0.81\" title=\"0.101\">vuelvo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.85%); opacity: 0.80\" title=\"0.010\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.57%); opacity: 0.84\" title=\"-0.303\">comprar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.58%); opacity: 0.81\" title=\"-0.048\">alli</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.97%); opacity: 0.82\" title=\"0.162\">jamas</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=RETAIL\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.896</b>, score <b>1.956</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.36%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.356\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 96.63%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.400\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 87.54%); opacity: 0.84\" title=\"-0.304\">nos</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.58%); opacity: 0.86\" title=\"-0.491\">estafaron</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.78%); opacity: 0.85\" title=\"0.404\">en</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.608\">mercadona</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 81.45%); opacity: 0.87\" title=\"0.537\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.78%); opacity: 0.83\" title=\"0.262\">vuelvo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.86%); opacity: 0.84\" title=\"0.328\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.02%); opacity: 0.91\" title=\"0.868\">comprar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.78%); opacity: 0.88\" title=\"0.650\">alli</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.61%); opacity: 0.84\" title=\"-0.337\">jamas</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=TELCO\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.003</b>, score <b>-5.696</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 95.56%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.594\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -5.102\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 83.87%); opacity: 0.85\" title=\"-0.439\">nos</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.52%); opacity: 0.80\" title=\"0.030\">estafaron</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.70%); opacity: 0.82\" title=\"-0.142\">en</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.91%); opacity: 0.90\" title=\"-0.826\">mercadona</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 89.63%); opacity: 0.83\" title=\"-0.234\">no</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.09%); opacity: 0.82\" title=\"0.131\">vuelvo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.76%); opacity: 0.86\" title=\"-0.483\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.92%); opacity: 0.90\" title=\"-0.825\">comprar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.76%); opacity: 0.81\" title=\"-0.065\">alli</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.37%); opacity: 0.84\" title=\"0.345\">jamas</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8vqJD9JwKIv"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "tweets = pd.read_csv('Datasets/mascorpus/tweets_marketing.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-9nkTp9wKIy"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tweets['TEXTO'], tweets['SECTOR'], \n",
        "                                                    test_size=0.33, \n",
        "                                                    stratify=tweets['SECTOR'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExV73PU4Ak1I"
      },
      "source": [
        "### Verificando el hardware disponible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1604083146665
        },
        "id": "ULqO3R6_Am2I",
        "outputId": "9f9f2677-f209-43b9-980d-264a3957f4d9"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "print(\"Este notebook se está ejecutando en\", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Este notebook se está ejecutando en cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g27A6eGswKI2"
      },
      "source": [
        "Sobre los salency maps\n",
        "----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTeXlnTxwKI2"
      },
      "source": [
        "TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQrgdxJMwff5"
      },
      "source": [
        "Cargamos nuestro modelo en allennlp\n",
        "-----------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXgQvCX2wKJi"
      },
      "source": [
        "Verifiquemos la performance de nuestro modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQUjg5QGwff5"
      },
      "source": [
        "model_name = \"tweet_classification\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYfP1hlawff5"
      },
      "source": [
        "### Creando un objeto Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wreKr4MLwff6"
      },
      "source": [
        "Importamos algunos elementos que necesitaremos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZQPaNL2s23z"
      },
      "source": [
        "from typing import Dict, Iterable, List\n",
        "\n",
        "from allennlp.common import Params\n",
        "from allennlp.data import DatasetReader, Instance, Batch\n",
        "from allennlp.data.fields import Field, LabelField, TextField\n",
        "from allennlp.data.token_indexers import TokenIndexer\n",
        "from allennlp.data.tokenizers import Tokenizer\n",
        "from allennlp.data.vocabulary import PreTrainedTokenizer, Vocabulary\n",
        "from allennlp.models import BasicClassifier, Model\n",
        "from allennlp.modules.token_embedders import PretrainedTransformerEmbedder\n",
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.data.tokenizers.pretrained_transformer_tokenizer import PretrainedTransformerTokenizer\n",
        "from allennlp.data.token_indexers.pretrained_transformer_indexer import PretrainedTransformerIndexer\n",
        "from allennlp.modules.seq2vec_encoders.bert_pooler import BertPooler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNQ6adFH0w9-"
      },
      "source": [
        "transformer_vocab = Vocabulary.from_pretrained_transformer(model_name)\n",
        "transformer_tokenizer = PretrainedTransformerTokenizer(model_name)\n",
        "transformer_encoder = BertPooler(model_name)\n",
        "\n",
        "token_indexer = PretrainedTransformerIndexer(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGhEyez5wff6"
      },
      "source": [
        "params = Params(\n",
        "    {\n",
        "     \"token_embedders\": {\n",
        "        \"tokens\": {\n",
        "          \"type\": \"pretrained_transformer\",\n",
        "          \"model_name\": model_name,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        ")\n",
        "\n",
        "token_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJS_5MUHT6ae"
      },
      "source": [
        "transformer_model = BasicClassifier(vocab=transformer_vocab, text_field_embedder=token_embedder, seq2vec_encoder=transformer_encoder, dropout=0.1, num_labels=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3kz-ySJwff7"
      },
      "source": [
        "### Creamos un DatasetReader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soe8I3wuxY4o"
      },
      "source": [
        "from allennlp.data import DatasetReader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ2EaLOTs4o2"
      },
      "source": [
        "class ClassificationTransformerReader(DatasetReader):\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer: Tokenizer,\n",
        "        token_indexer: TokenIndexer,\n",
        "        max_tokens: int,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.token_indexers: Dict[str, TokenIndexer] = { \"tokens\": token_indexer }\n",
        "        self.max_tokens = max_tokens\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def text_to_instance(self, text: str, label: str = None) -> Instance:\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        if self.max_tokens:\n",
        "            tokens = tokens[: self.max_tokens]\n",
        "        \n",
        "        inputs = TextField(tokens, self.token_indexers)\n",
        "        fields: Dict[str, Field] = { \"tokens\": inputs }\n",
        "            \n",
        "        if label:\n",
        "            fields[\"label\"] = LabelField(label)\n",
        "            \n",
        "        return Instance(fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTbut2YFwff8"
      },
      "source": [
        "Instanciamos el `DatasetReader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USOdKLOLxcsL"
      },
      "source": [
        "dataset_reader = ClassificationTransformerReader(tokenizer=tokenizer, token_indexer=indexer, max_tokens=400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHZZee0qwff8"
      },
      "source": [
        "### Provemos que nuestro modelo funciona"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11t8d8z3BWjH"
      },
      "source": [
        "instance = dataset_reader.text_to_instance(sample_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Id7l50BbWL"
      },
      "source": [
        "dataset = Batch([instance])\n",
        "dataset.index_instances(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-GYJtprBqXu"
      },
      "source": [
        "from allennlp.nn import util\n",
        "model_input = util.move_to_device(dataset.as_tensor_dict(), model._get_prediction_device())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVQSvtlOB0qU"
      },
      "source": [
        "outputs = model.make_output_human_readable(model(**model_input))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzY0hxoNwff9",
        "outputId": "dea39fff-19ff-4801-de50-021bc4de78ec"
      },
      "source": [
        "outputs['probs'].argmax()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "execution_count": 319,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl7H403ywff-"
      },
      "source": [
        "Interpretando nuestras predicciones\n",
        "-----------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B28J8jCpmkQq"
      },
      "source": [
        "from allennlp.interpret.saliency_interpreters import SimpleGradient\n",
        "from allennlp.predictors import Predictor, TextClassifierPredictor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTX6HgF6sXrs"
      },
      "source": [
        "predictor = TextClassifierPredictor(transformer_model, dataset_reader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djiGHlzpqeun"
      },
      "source": [
        "interpreter = SimpleGradient(predictor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyvaEQrZwff-"
      },
      "source": [
        "Busquemos un tweet para interpretar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLcJ-eP4wff-",
        "outputId": "879a5e81-212b-4bf7-8a52-b0f90d231a6e"
      },
      "source": [
        "sample_text_idx = 2071\n",
        "sample_text = tweets['TEXTO'][sample_text_idx]\n",
        "sample_label = tweets['SECTOR'][sample_text_idx]\n",
        "\n",
        "print(\"Texto:\", sample_text, \"\\Sector:\", sample_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Samples: BBVA remolca el crecimiento de la banca española pese a los obstáculos https://t.co/wF9tOqxB5D \n",
            "Label: BANCA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsfJuaqmwff-",
        "outputId": "707678b6-8620-4f80-c2c0-c18c6ec30a87"
      },
      "source": [
        "train_dataset.label_map"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ALIMENTACION': 0,\n",
              " 'AUTOMOCION': 1,\n",
              " 'BANCA': 2,\n",
              " 'BEBIDAS': 3,\n",
              " 'DEPORTES': 4,\n",
              " 'RETAIL': 5,\n",
              " 'TELCO': 6}"
            ]
          },
          "execution_count": 281,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYSpFzFBwff_"
      },
      "source": [
        "Calculemos los gradientes para cada token:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_i_OjI_edIS"
      },
      "source": [
        "inputs = {\"sentence\": sample_text }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_00Ya8ZelBk"
      },
      "source": [
        "interpretation = interpreter.saliency_interpret_from_json(inputs)\n",
        "grads = interpretation['instance_1']['grad_input_1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjvkGAipwff_"
      },
      "source": [
        "Podemos graficar los resultados utilizando un mapa de calor marcando con colores más intensos aquellos tokens que tienen mayor impacto en las predicciones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKnUFEzYwff_",
        "outputId": "98862b1e-8707-4e51-ec3d-b859d06ffb82"
      },
      "source": [
        "import math\n",
        "from IPython.display import HTML\n",
        "\n",
        "html = \"\"\n",
        "for idx, token in enumerate(tokenizer.tokenize(inputs['sentence'])):\n",
        "    html += \"<span style='background-color:rgba(255,0,0,{})'>{} </span>\".format(grads[idx],token)\n",
        "    \n",
        "HTML(html)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span style='background-color:rgba(255,0,0,0.023973679291077122)'>[CLS] </span><span style='background-color:rgba(255,0,0,0.04897258439852681)'>@ </span><span style='background-color:rgba(255,0,0,0.003461454720505409)'>afectados </span><span style='background-color:rgba(255,0,0,0.02091576096284071)'>##bb </span><span style='background-color:rgba(255,0,0,0.018777627214177528)'>##s </span><span style='background-color:rgba(255,0,0,0.031570827555892855)'>gracias </span><span style='background-color:rgba(255,0,0,0.0016718006309883002)'>por </span><span style='background-color:rgba(255,0,0,0.0034003259600348073)'>vuestro </span><span style='background-color:rgba(255,0,0,0.06144485286567216)'>apoyo </span><span style='background-color:rgba(255,0,0,0.005402004359105598)'>. </span><span style='background-color:rgba(255,0,0,0.01802461645015915)'>@ </span><span style='background-color:rgba(255,0,0,0.061875498507208804)'>movi </span><span style='background-color:rgba(255,0,0,0.024941960716525262)'>##sta </span><span style='background-color:rgba(255,0,0,0.13591464547869064)'>##r </span><span style='background-color:rgba(255,0,0,0.11568165706100288)'>@ </span><span style='background-color:rgba(255,0,0,0.026843567739396487)'>telefónica </span><span style='background-color:rgba(255,0,0,0.04155317701714767)'>me </span><span style='background-color:rgba(255,0,0,0.020817662853791805)'>han </span><span style='background-color:rgba(255,0,0,0.005203374227524732)'>proporcionado </span><span style='background-color:rgba(255,0,0,0.0007301853839047058)'>un </span><span style='background-color:rgba(255,0,0,0.015294630686846507)'>sam </span><span style='background-color:rgba(255,0,0,0.026412237223066567)'>##su </span><span style='background-color:rgba(255,0,0,0.06879373175012778)'>##ng </span><span style='background-color:rgba(255,0,0,0.060360859349322865)'>galax </span><span style='background-color:rgba(255,0,0,0.009029374533876937)'>##y </span><span style='background-color:rgba(255,0,0,0.024829015338365158)'>s </span><span style='background-color:rgba(255,0,0,0.011436398744010385)'>##5 </span><span style='background-color:rgba(255,0,0,0.011620545021001981)'>, </span><span style='background-color:rgba(255,0,0,0.0033746346510469495)'>que </span><span style='background-color:rgba(255,0,0,0.0024233566030202997)'>ya </span><span style='background-color:rgba(255,0,0,0.013814822628132545)'>tengo </span><span style='background-color:rgba(255,0,0,0.0029324966630722986)'>en </span><span style='background-color:rgba(255,0,0,0.013570686308404035)'>mi </span><span style='background-color:rgba(255,0,0,0.005596539415660109)'>poder </span><span style='background-color:rgba(255,0,0,0.01920838170998595)'>. </span><span style='background-color:rgba(255,0,0,0.040125054327352805)'>[SEP] </span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 289,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}