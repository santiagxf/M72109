{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKENeWEEwKIb"
      },
      "source": [
        "Explicaciones para NLP utilizando SHAP\n",
        "======================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JctlpI10jJ15"
      },
      "source": [
        "Introducción\n",
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT_t9OxYwKIc"
      },
      "source": [
        "TODO\n",
        "\n",
        "Para una introducción más detallada puede ver la entrada del blog: [Model interpretability — Making your model confesses: SHAP](https://santiagof.medium.com/model-interpretability-making-your-model-confess-shapley-values-5fb95a10a624)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t67TU7HLY1Hg"
      },
      "source": [
        "¿Como funciona?\n",
        "---------------\n",
        "\n",
        "TODO\n",
        "\n",
        "Para mas información sobre esta librería visite: https://shap.readthedocs.io/en/latest/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcyc_TQ6dis7"
      },
      "source": [
        "### Para ejecutar este notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJFcNrbmjJ17"
      },
      "source": [
        "Para ejecutar este notebook, instale las siguientes librerias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgK8b6e_jJ17"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Datasets/mascorpus/tweets_marketing.csv \\\n",
        "    --quiet --no-clobber --directory-prefix ./Datasets/mascorpus/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sxwUvomeZ9hd"
      },
      "outputs": [],
      "source": [
        "!pip install transformers --quiet\n",
        "!pip install shap --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr7vZC0cwff0"
      },
      "source": [
        "Descargaremos un modelo previamente entrenando el el problema de clasificación de Tweets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgXwXTX2wff1"
      },
      "outputs": [],
      "source": [
        "!wget https://santiagxf.blob.core.windows.net/public/models/tweet_classification_bert.zip --no-clobber --quiet\n",
        "!unzip -qq tweet_classification_bert.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ntcs1AlpfckX"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Sih7EhY1H0"
      },
      "source": [
        "Cargamos el conjunto de datos con el que se entrenó el modelo en caso de necesitarlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8vqJD9JwKIv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "tweets = pd.read_csv('Datasets/mascorpus/tweets_marketing.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcO4lC5qY1H3"
      },
      "source": [
        "Cargando un modelo de NLP\n",
        "-------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gBXNzwYwKIu"
      },
      "source": [
        "Cargaremos el modelo que fue descargado anteriornmente utilizando la librería de `transformers`. Note que cargamos tanto el `tokenizer` como el modelo propiamente dicho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuUI_dXFxh6u"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"tweet_classification_bert\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juB0uVfFY1H_"
      },
      "source": [
        "Recordemos que nuestro modelo predice los sectores a los que pertenecería el tweet, siendo ellos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMBEop__zFAI"
      },
      "outputs": [],
      "source": [
        "target_names = ['ALIMENTACION', 'AUTOMOCION', 'BANCA', 'BEBIDAS', 'DEPORTES', 'RETAIL', 'TELCO']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dArhsrI6Y1H5"
      },
      "source": [
        "Generando explicaciones con SHAP\n",
        "--------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = [\"Nos estafaron en carrefour. No vuelvo a comprar alli jamas\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "explainer = shap.Explainer(model, tokenizer)\n",
        "shap_values = explainer(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizando las explicaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.text(shap_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos analizar el impacto de una sola clase:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.text(shap_values[:, :, \"ALIMENTACION\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizando las palabras que tienen el mayor impacto en una clase determinada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.bar(shap_values[:,:,\"ALIMENTACION\"].mean(0), order=shap.Explanation.argsort)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En los ejemplos anteriores, explicamos la salida directa del objeto pipline, que son las probabilidades de clase. A veces tiene más sentido trabajar en un espacio de probabilidades logarítmicas donde es natural sumar y restar efectos (la suma y la resta corresponden a la suma o resta de bits de información de evidencia)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logit_explainer = shap.Explainer(shap.models.TransformersPipeline(pred, rescale_to_logits=True))\n",
        "\n",
        "logit_shap_values = logit_explainer(sample)\n",
        "shap.plots.text(logit_shap_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analizando las predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = [\n",
        "    \"Nos estafaron en carrefour\",\n",
        "    \"Nos estafaron en el super\",\n",
        "    \"Nos estafaron en la gondola\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = [\n",
        "    0,\n",
        "    0,\n",
        "    0\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utilizando un Teacher Forcing y creamos un Text masker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "teacher_forcing_model = shap.models.TeacherForcing(model, tokenizer)\n",
        "masker = shap.maskers.Text(tokenizer, mask_token = \"...\", collapse_mask_token=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos el explicador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "explainer = shap.Explainer(teacher_forcing_model, masker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generamos las explicaciones:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "shap_values = explainer(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora que hemos generado los valores SHAP, podemos echar un vistazo a la contribución de los tokens en la entrada que impulsa a generar una predicción en la clase alimentación. Nota: El color rojo indica una contribución positiva mientras que el color azul indica una contribución negativa y la intensidad del color muestra su fuerza en la dirección respectiva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shap.plots.text(shap_values)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "allennlp_interpret.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernel_info": {
      "name": "nlp-py38"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - PyTorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
