Interpretación de modelos 
=========================

A pesar de su amplia adopción, los modelos de aprendizaje automático - y especialmente aquellos basados en aprendizaje profundo - siguen siendo cajas negras a la hoja de entender como toman las decisiones que toman [1]_ . Sin embargo, comprender las razones detrás de las predicciones es importante para evaluar la confianza, que es fundamental si uno planea tomar acciones basadas en una predicción o al elegir si implementar un nuevo modelo en el contexto de una organización o proceso de negocio. Esta comprensión también proporciona información sobre el modelo, que se puede utilizar para transformar un modelo o una predicción que no son confiables en uno confiable.


**Referencias:**

.. [1] `Why Should I Trust You?": Explaining the Predictions of Any Classifier <https://arxiv.org/abs/1602.04938>`_

.. toctree::
   :maxdepth: 1
   :caption: Ejemplos

   Explicaciones para NLP utilizando LIME <nlp_lime.ipynb>
   Explicaciones para NLP utilizando salency maps con AllenNLP <allennlp_interpret.ipynb>
