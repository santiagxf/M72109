{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "T√©cnicas de reducci√≥n de dimensionalidad\n",
    "==================================="
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introducci√≥n\n",
    "\n",
    "Topic modeling es una t√©cnica de aprendizaje autom√°tico no supervisado donde intentados descubrir t√≥picos que son abstractos al texto pero que pueden describir una colecci√≥n de documentos. Es importante marcar que estos \"t√≥picos\" no son necesariamente equivalentes a la interpretaci√≥n coloquial de t√≥picos, sino que responden a un patr√≥n que emerge de las palabras que est√°n en los documentos.\n",
    "\n",
    "La suposici√≥n b√°sica para Topic Modeling es que cada documento est√° representado por una mescla de t√≥picos, y cada t√≥pico consiste en una colecci√≥n de palabras."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "u8Irja1O_J9X"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Para ejecutar este notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para ejecutar este notebook, instale las siguientes librerias:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Datasets/mascorpus/tweets_marketing.csv \\\n",
    "    --quiet --no-clobber --directory-prefix ./Datasets/mascorpus/\n",
    "    \n",
    "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/docs/nlp/modeling/topic-modeling.txt \\\n",
    "    --quiet --no-clobber\n",
    "!pip install -r topic-modeling.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!python -m spacy download es_core_news_sm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Primero importaremos algunas librerias necesarias"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "WPpqVNrwSdhL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPfF_O0U_J9a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sobre el set de datos con el que vamos a trabajar"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "lE_O7bEjLebd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizaremos como ejemplo un set de datos en espa√±ol que contiene tweets que diferentes usuarios han publicado en relaci√≥n a diferentes marcas de productos u empresas en el rubro de alimentaci√≥n, construcci√≥n, automoviles, etc. Estos tweets, a su vez, est√°n asociados a una de las diferentes fases en el proceso de ventas (tambi√©n conocido como Marketing Funel) y por eso est√°n tagueados con las fases de:\n",
    " - Awareness ‚Äì el cliente es conciente de la existencia de un producto o servicio\n",
    " - Interest ‚Äì activamente expresa el interes de un producto o servicio\n",
    " - Evaluation ‚Äì aspira una marca o producto en particular\n",
    " - Purchase ‚Äì toma el siguiente paso necesario para comprar el producto o servicio\n",
    " - Postpurchase - realizaci√≥n del proceso de compra. El cliente compara la diferencia entre lo que deseaba y lo que obtuvo\n",
    "\n",
    "Referencia: [Spanish Corpus of Tweets for Marketing](http://ceur-ws.org/Vol-2111/paper1.pdf\n",
    "\n",
    "> Nota: La version de este conjunto de datos que utilizaremos aqui es una versi√≥n preprocesada del original."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "H8lcRTa_Li4e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "tweets = pd.read_csv('Datasets/mascorpus/tweets_marketing.csv')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gc44Q7do_J9h"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspeccionamos el set de datos"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "INJwReUXSs4K"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "tweets.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               TEXTO  SECTOR      MARCA  \\\n",
       "0  #tablondeanuncios Funda nordica ikea #madrid h...  RETAIL       IKEA   \n",
       "1  #tr Me ofrezco para montar muebles de Ikea - H...  RETAIL       IKEA   \n",
       "2  #VozP√≥puli Vozp√≥puli @voz_populi - #LoM√°sLeido...  RETAIL    ALCAMPO   \n",
       "3  #ZonaTecno Destacado: Todo lo que hay que sabe...  RETAIL  CARREFOUR   \n",
       "4  $Carrefour retira pez #Panga. OCU y grupos x #...  RETAIL  CARREFOUR   \n",
       "\n",
       "       CANAL  AWARENESS  EVALUATION  PURCHASE  POSTPURCHASE  NC2  \n",
       "0  Microblog          0           0       0.0             0  1.0  \n",
       "1  Microblog          0           0       0.0             0  1.0  \n",
       "2  Microblog          0           0       0.0             0  1.0  \n",
       "3  Microblog          0           0       0.0             0  1.0  \n",
       "4  Microblog          0           0       0.0             0  1.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXTO</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>MARCA</th>\n",
       "      <th>CANAL</th>\n",
       "      <th>AWARENESS</th>\n",
       "      <th>EVALUATION</th>\n",
       "      <th>PURCHASE</th>\n",
       "      <th>POSTPURCHASE</th>\n",
       "      <th>NC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#tablondeanuncios Funda nordica ikea #madrid h...</td>\n",
       "      <td>RETAIL</td>\n",
       "      <td>IKEA</td>\n",
       "      <td>Microblog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#tr Me ofrezco para montar muebles de Ikea - H...</td>\n",
       "      <td>RETAIL</td>\n",
       "      <td>IKEA</td>\n",
       "      <td>Microblog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#VozP√≥puli Vozp√≥puli @voz_populi - #LoM√°sLeido...</td>\n",
       "      <td>RETAIL</td>\n",
       "      <td>ALCAMPO</td>\n",
       "      <td>Microblog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#ZonaTecno Destacado: Todo lo que hay que sabe...</td>\n",
       "      <td>RETAIL</td>\n",
       "      <td>CARREFOUR</td>\n",
       "      <td>Microblog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$Carrefour retira pez #Panga. OCU y grupos x #...</td>\n",
       "      <td>RETAIL</td>\n",
       "      <td>CARREFOUR</td>\n",
       "      <td>Microblog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Gd6EocPdG5A0",
    "outputId": "6d1df056-08d1-4e7d-89b8-342c80082c2d"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "tweets.groupby('SECTOR').head(1)[['TEXTO', 'SECTOR']]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  TEXTO        SECTOR\n",
       "0     #tablondeanuncios Funda nordica ikea #madrid h...        RETAIL\n",
       "725   \"Ilcinsisti lis MB dispiniblis\" te odeeeeeo Mo...         TELCO\n",
       "964   #CarlosSlim y Bimbo lanzar√°n un veh√≠culo el√©ct...  ALIMENTACION\n",
       "1298  ‚ÄºüèéToyota #Day, 4ruedas ,1/4 milla, 1 #pasi√≥n, ...    AUTOMOCION\n",
       "1748  \"- T√∫ qu√©.\\n- Yo na.\"\\nConversaciones banco sa...         BANCA\n",
       "2348  - Cari√±o, te juro que s√≥lo ten√≠an Cruzcampo en...       BEBIDAS\n",
       "3023  #adidas #hockey Amenabar 2080 CABA https://t.c...      DEPORTES"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXTO</th>\n",
       "      <th>SECTOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#tablondeanuncios Funda nordica ikea #madrid h...</td>\n",
       "      <td>RETAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>\"Ilcinsisti lis MB dispiniblis\" te odeeeeeo Mo...</td>\n",
       "      <td>TELCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>#CarlosSlim y Bimbo lanzar√°n un veh√≠culo el√©ct...</td>\n",
       "      <td>ALIMENTACION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>‚ÄºüèéToyota #Day, 4ruedas ,1/4 milla, 1 #pasi√≥n, ...</td>\n",
       "      <td>AUTOMOCION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>\"- T√∫ qu√©.\\n- Yo na.\"\\nConversaciones banco sa...</td>\n",
       "      <td>BANCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>- Cari√±o, te juro que s√≥lo ten√≠an Cruzcampo en...</td>\n",
       "      <td>BEBIDAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>#adidas #hockey Amenabar 2080 CABA https://t.c...</td>\n",
       "      <td>DEPORTES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "uXwJS2Og_J9l",
    "outputId": "7b354598-bf6f-41a6-dd63-afe7897e3d68"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprosesamiento"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "r9FcIehJ_J9q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como en toda tarea de NLP, y m√°s generalmente, en Machine Learning, ocuparemos una porci√≥n de nuestro tiempo en preprocesar los datos para generar representaciones √∫tiles y deshacernos de problemas especificos que podr√≠a exhibir nuestro set de datos. "
   ],
   "metadata": {
    "colab_type": "text",
    "id": "gfUnlH25HEeM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creando una rutina de preprosesamiento de texto\n",
    "\n",
    "Realizaremos las tareas cotidianas de preprocesamiento. Adicionalmente nuestra rutina va a: \n",
    "\n",
    " - Eliminar caracteres especiales: Acentos y caracteres especiales podr√≠an complejizar el la representaci√≥n de palabras, por lo que los eliminaremos.\n",
    " - Eliminaremos URLs y handles que son t√≠picos en tweeter. Esto es especifico en este set de datos ya que una URL no representa informaci√≥n en este contexto."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "UZISG0Cs_J-g"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import unidecode\n",
    "import spacy\n",
    "import es_core_news_sm as spa\n",
    "import re\n",
    "from nltk import stem\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "parser = spa.load() # Cargamos el parser en espa√±ol\n",
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True) # Creamos un tokenizer\n",
    "stemmer = stem.SnowballStemmer(language='spanish') # Creamos un steammer\n",
    "lemmatizer = lambda word : \" \".join([token.lemma_ for token in parser(word)]) # Creamos un lemmatizer\n",
    "stopwords = set(stopwords.words('spanish')) # Instanciamos las stopwords en espa√±ol\n",
    "urls_regex = re.compile('http\\S+') # Usamos una expresion regular para encontrar las URLs\n",
    "\n",
    "def process_text(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token for token in tokens if not re.match(urls_regex, token)]\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    tokens = [unidecode.unidecode(token) for token in tokens] # Quitamos acentos\n",
    "    tokens = [lemmatizer(token) for token in tokens]\n",
    "    return tokens"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eJxv1LA_J-g"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "doc_list = []\n",
    "\n",
    "for doc in tqdm(tweets['TEXTO']):\n",
    "    tokens = process_text(doc)\n",
    "    doc_list.append(' '.join(tokens))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3763/3763 [01:54<00:00, 32.98it/s]\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U4uXheye_J-j",
    "outputId": "a79ef5e4-2048-41c6-e95b-bd8143567c28"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Revisemos algunos resultados:"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "LtykSqbA_J-l"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tweets['TEXTO'][2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'#VozP√≥puli Vozp√≥puli @voz_populi - #LoM√°sLeidoHoy Mercadona, DIA o Alcampo guardan silencio ante la ola europea... https://t.co/aJTuA4J9UV'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 120
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QQgWOejW_J-l",
    "outputId": "d9bf3e73-d7fd-45df-83f4-06d74e9d4af2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "doc_list[2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'# VozPopuli Vozpopuli # LoMasLeidoHoy Mercadona Alcampo guardar silenciar europeo'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 121
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "huZ2Cu2Q_J-n",
    "outputId": "2735e7f4-9625-4ab8-d826-360912b5ca19"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(doc_list)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3763"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 122
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6WSbMjTnRYXT",
    "outputId": "cdd43d26-0161-46eb-eafe-3a3ad9c9211e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectorizaci√≥n"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "-PXVzn24_J-p"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una vez que nuesto texto fue preprocesado para mantener solo aquellas palabras que nos son relevantes, pasamos al proceso de generar vectores a partir de las palabras que componen nuestro vocabulario. Nuestros modelos no pueden operar sobre palabras, y por lo tanto necesitamos una representaci√≥n n√∫merica de las mismas."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "TLwWu__sX4Rq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True, sublinear_tf=True, norm='l2')\n",
    "vectors = vectorizer.fit_transform(doc_list).todense()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUldeeN6_J-7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vectors.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reducci√≥n de dimensionalidad: Featurization\n",
    "Una vez que tenemos nuestros palabras representadas como vectores, nos aparece el problema de que ¬°a√∫n son demasiado grandes! En el ejemplo anterior, estamos trabajando con vectores en un espacio de 6K+. Necesitamos reducir esta dimensionalidad. Para esto, utilizaremos m√©todos de reducci√≥n de dimensionalidad con el objetivo de generar features que nos sean m√°s utiles. Estas features las generaremos de forma \"no supervisada\""
   ],
   "metadata": {
    "colab_type": "text",
    "id": "j5YtJxjQXgxH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### M√©todos b√°sados en SVD"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "cI4HLD1tkTBT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los modelos basados en factorizaci√≥n de matrices intentan reducir la dimensionalidad de la matriz al aproximarla usando dos matrices que representan embeddings de palabras y embeddings de documentos (m√°s una matriz singular que los vincula los unos con los otros). Este m√©todo es bastante popular no solo en NLP sino que tambi√©n en sistemas de recomendaci√≥n, m√©todo que fu√© ganador del Netflix Prize (Funk SVD).\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/700/1*Z0EUVs7QElEqRqXtqut_FQ.png\" />\n",
    "\n",
    "\n",
    "U y V(trapuesta) son ortogonales. Esto es de esperar porque si determinadas propiedades determinan un determinado factor latente, entonces esas propiedades ser√°n poco relevantes en los restantes factores (pues sino, no har√≠a sentido que conformen un factor distinto en un primer lugar).\n",
    "\n",
    "SVC es un metodo de decomposici√≥n exacto, lo que singnifica que las matrices U y V son lo suficientemente grandes para mapear exactamente la matriz A. "
   ],
   "metadata": {
    "colab_type": "text",
    "id": "-8tC0kyK_J-6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSI - Latent Semantic Indexing"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "Kh1u5cZzkKbO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LSI es un caso particular de factorizaci√≥n de matrices. Cuando SVD es utilizado para procesar t√≥picos en texto y en donde los valores de la matriz A corresponden a frecuencias de palabras, este m√©todo se lo denomina Latent Semantic Analysis (sin embargo, en NLP no se lo suele nombrar como LSI).\n",
    "\n",
    "Dado que SVC es un m√©todo de decomposici√≥n exacto, tiende a producir matrices de poca densidad (sparse). Para evitar este problema, se utiliza una versi√≥n modificada de SVC conocida como Truncated SVD que solamente computa los k componentes mas grandes en la descomposici√≥n. Esto ayuda a que LSI combata efectivamente el problema de matrices sparse que tienden a generarse cuando se tienen cuerpos de texto con sin√≥nimos y palabras que significan varias cosas dependiendo del contexto. Truncated SVD ev√≠ta ser un m√©todo de decomposici√≥n exacto al aproximar la matriz A utilizando los k t√≥picos m√°s relevantes.\n",
    "\n",
    "<img src='https://github.com/fastai/course-nlp/raw/aabfeddf61fea29b18c72f841d057b56a216b7eb/images/svd_fb.png' />\n",
    "\n",
    "Facebook Research: Fast Randomized SVD [https://research.fb.com/fast-randomized-svd/])\n",
    "\n",
    "En esta configuraci√≥n entonces:\n",
    " - Un documento es nada mas que la distribuci√≥n de palabras que ocurren en el (Bag of words)\n",
    " - A es una matriz de m x n donde m es la cantidad de documentos √∫ observaciones, y n es la cantidad de palabras en el vocabulario.\n",
    " - Los valores de A corresponden a la frecuencia de la cada palabra del vocabulario en cada observaci√≥n √∫ documento.\n",
    " - A es una matriz sujeta a ruido con distribuci√≥n Gausiana.\n",
    "\n",
    "\n",
    "Referencia: Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions [https://arxiv.org/abs/0909.4061]"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "U1pbwdPv_J-7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El principal parametro en LSI es el numero de factores que queremos generar (el parametro K). No existe una regla para especificar este parametro ya que depende del escenario. Valores muy peque√±os pueden forzar a los documentos a ser colisionar en los t√≥picos que son asignados, mientras que valores muy grandes pueden hacer que palabras poco frecuentes y raras terminen determinando su propio \"topico\". Este valor lo especificaremos en n_components. El parametro algorithm hace referencia al m√©todo que utilizaremos para generar la descomposici√≥n:"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "c1iGWgQZca0C"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=7, algorithm='randomized')\n",
    "USigma = svd.fit_transform(vectors)\n",
    "Sigma = svd.singular_values_\n",
    "VT = svd.components_"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZ2uzF82_J--"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si bien en el codigo anterior estamos viendo las 3 matrices, solo nos interesa la matriz VT. ¬øPorque? Recuerden que nuestro \"input\" es un conjunto de palabras que luego vectorizamos utilizando TF-IDF. Cada documento est√° representado por este conjunto de palabras. Nuestro objetivo es disponer una forma donde podamos convertir este set de palabras a \"t√≥picos\" que sean m√°s informativos que las palabras propiamente dichas. **En consecuencia, lo √∫nico que nos interesa aqui es la matriz VT**"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "3bFhXZc6eHQL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "VT.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7, 6729)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 134
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Xvvt3kpu_J_A",
    "outputId": "f6005751-c4c8-476f-9df0-1c0697732a3a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Internamente, TrucatedSVC es un wrapper de la clase randomized_svd donde la matr√≠z Q que vimos anteriormente se genera a trav√©s de un m√©todo de sampling aleatorio. Las siguientes lineas son equivalentes a lo que vimos anteriormente:"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "uwu_KCg__J_C"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "U, Sigma, VT = randomized_svd(vectors, \n",
    "                              n_components=7,\n",
    "                              n_iter=5)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_kigl-Xl_J_D"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos validar que U es una matriz ortogonal"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "HV9fOGLB_J_F"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.allclose(U.T @ U, np.eye(U.shape[1]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 136
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uLYEo9Gm_J_F",
    "outputId": "d538b528-1067-4e18-a3f7-4c7b362e67cc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lo siguiente es solo a titulo informativo, pero si vemos los valores de la matriz Sigma, veremos la importancia relativa de los documentos con respecto a los t√≥picos que encontramos. Si los gr√°ficamos vemos que sus valores comienzan a decrecer relativamente r√°pido, sosteniendo la supoci√≥n de que Truncated SVD genera los K m√°s relevantes t√≥picos."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "xSv1wUgK_J_I"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(Sigma)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f349d3837b8>]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 137
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     }
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "HVI80HRw_J_I",
    "outputId": "95681231-913f-4db9-b04c-f5936cae8e15"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Interpretando los t√≥picos\n"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "IR8CpAYe_J_K"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La siguiente funci√≥n solo toma la matriz de VT y obtiene las 8 palabras m√°s importantes en este topico. Si quieren pueden variar este parametro para ver m√°s palabras e inspeccionar los t√≥picos. Esto es importante porque LSI es un m√©todo no supervisado, por lo tanto no sabemos a priori cuando un t√≥pico es bueno o malo. El sentido debemos darselo nosotros:"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "ra5f0S7FfKjG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def show_topics(a):\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[-8:-1]]\n",
    "    topic_words = ([top_words(t) for t in a])\n",
    "    return [' '.join(t) for t in topic_words]"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBNIN0xE_J_K"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "show_topics(VT)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['medalla querer ganar gustar comprar cerveza cruzcampo',\n",
       " 'olimpia nikes siempre nuevo zapatilla camiseta adidas',\n",
       " 'comprar nuevo conocer gustar aldub81stweeksary superstar cruzcampo',\n",
       " 'bueno querer invitar beber arruinaunacitacon4palabras cerveza gustar',\n",
       " '10 terminar carrera milka ritmar correr acabo',\n",
       " 'alfajor querer ganar carrefour comprar mercadona chocolate',\n",
       " 'panga vender movistar mejor comprar bimbo carrefour']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 139
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "IDhDFVY9_J_M",
    "outputId": "9069708a-658f-4509-86f4-9116ecf25e4f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Limitaciones en LSI:\n",
    " - LSI sufre de un problema llamado \"Indeterminaci√≥n del signo\", que b√°sicamente significa que el signo en la matr√≠z VT y USigma dependen del algorimo que se utiliz√≥ para generarlos y de las condiciones iniciales (initial random state). En este contexto, que significa que un t√≥pico est√© relacionado con una palabra en un valor negativo?"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "WKCo8UOd_J_Q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NMF: Non-negative Matrix Factorization\n",
    "\n",
    "Motivaci√≥n: En lugar de construir nuestros factores imponiendo la restricci√≥n de que sean ortogonales, la idea es de construirlos de tal forma que sean no-negativos."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "no6V6rtO_J_Q"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=7, random_state = 1234)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQwyjnN8_J_R"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "W1 = nmf.fit_transform(vectors)\n",
    "H1 = nmf.components_"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdTfBg2n_J_U"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En este caso, la matriz que nos interesa es H1"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "lIYwacxIfxqQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "H1.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7, 6729)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 142
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S39Zrr06_J_a",
    "outputId": "10dddfe5-2fab-4c6b-e0b1-f73beee22622"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Interpretando los t√≥picos"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "qkEBkOc-fqtT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "show_topics(H1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['novio comprar querer corona medalla cerveza ganar',\n",
       " 'olimpia color nikes siempre nuevo zapatilla camiseta',\n",
       " 'tenis napaacc cliente nuevo conocer aldub81stweeksary superstar',\n",
       " 'mahou invitar querer beber arruinaunacitacon4palabras cerveza gustar',\n",
       " '50 10 terminar carrera ritmar correr acabo',\n",
       " 'mcflurry necesito quiero querer alfajor ganar chocolate',\n",
       " 'panga vender movistar mejor comprar bimbo carrefour']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 143
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "X8qfO_Dx_J_d",
    "outputId": "9394872e-1c2a-4f5f-8ab9-7ef8c7cb7a77"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LDA: Latent Dirichlet Allocation\n",
    "\n",
    "LDA es un m√©todo Bayesiano basado en la distribuci√≥n de Dirichlet, la cual es una distribuci√≥n sobre probabilidades en K categorias. LDA supone que los documentos que tenemos pertenecen a K categorias distintas cuya distribuci√≥n es desconocida, sin embargo, asume que todos los fragmentos que componen el texto fueron generados a trav√©s de un mismo proceso generativo. "
   ],
   "metadata": {
    "colab_type": "text",
    "id": "cbMNkPv7_J_i"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La distribuci√≥n Dirichlet es una generalizaci√≥n de la distribuci√≥n Beta en un espacio multidimensional. As√≠ como la distribuci√≥n beta es la distribuci√≥n previa de la binomial, la distribuci√≥n de Dirichlet es la distribuci√≥n previa de la multinomial. \n",
    "\n",
    "$$ P(w\\mid d) = P(d)\\sum_c P(k\\mid d)P(w\\mid k) $$\n",
    "\n",
    "*¬øNotan alguna similitud con SVD?*\n",
    "\n",
    "David Blei, Andrew Ng, Michael Jordan:  Latent Dirichlet Allocation [https://jmlr.org/papers/volume3/blei03a/blei03a.pdf]"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "0bct-Ck5f6fs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=7)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cN1vPUB3_J_j"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lda.fit(vectors)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=7, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=None,\n",
       "                          topic_word_prior=None, total_samples=1000000.0,\n",
       "                          verbose=0)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 145
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "d1dC1tN6_J_k",
    "outputId": "77bbfe70-3ae7-4c2e-f829-d93282057b45"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for idx, topic in enumerate(lda.components_):\n",
    "    print (\"Topic \", idx, \" \".join(vocab[i] for i in topic.argsort()[:-10 - 1:-1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Topic  0 cruzcampo milka heineken toyota gustar bimbo carrefour cerveza llevar arruinaunacitacon4palabras\n",
      "Topic  1 adir adidas mercadona bimbo comprar heineken alcampo milka barato supermercado\n",
      "Topic  2 querer heineken adidas mercadona ir movistar banco poder hacendar vez\n",
      "Topic  3 galicia carrefour estrella movistar banco mercadona heineken soler sabadell bueno\n",
      "Topic  4 movistar toyota heineken mercadona adidas favor suzuki hacer vender adir\n",
      "Topic  5 heineken nikeplus acabo correr ritmar santander mejor bimbo mercadona cerveza\n",
      "Topic  6 heineken mueble bankia adir montar encontrar vestir quien medalla carrefour\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "cF-MpBfDgk2O",
    "outputId": "62f4a800-b397-4893-b7ca-f101ece7334f"
   }
  }
 ],
 "metadata": {
  "colab": {
   "name": "Topic Modeling.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}