{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizado con métodos clásicos\n",
        "================================\n",
        "\n",
        "## Introducción"
      ],
      "metadata": {
        "id": "64VtYMpfSyf-"
      },
      "id": "64VtYMpfSyf-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un modelos de aprendizaje automático es, a groso modo, una función parametrizada `f(x)` que toma como entrada\n",
        "un vector `x`, `n-dimensional`, y produce un vector de salida `m-dimensional`. Tal función puede ser simple (para un modelo lineal por ejemplo) o más compleja (como una red neuronal).\n",
        "\n",
        "Cuando trabajamos con lenguaje natural, la mayoría de nuestros datos de entrada representarán características discretas y categóricas, ya sean palabras, letras o incluso utterancias (partes del discurso). La pregunta que nos haremos entonces es ¿Cómo codificamos esos datos categóricos de una manera que sea práctica para ser utilizada por un modelo de aprendizaje automático?\n",
        "\n",
        "Discutiremos las opciones disponibles.\n",
        "\n",
        " - [One-hot encoding](#One-hot-encoding)\n",
        " - [Index-based encoding](#Index-based-encoding)\n",
        " - [Basados en frecuencias](#Basados-en-frecuencias)\n",
        "\n",
        " Utilizaremos el siguiente corpus para nuestros ejemplos:\n"
      ],
      "metadata": {
        "id": "dLRE8wzSSygF"
      },
      "id": "dLRE8wzSSygF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "corpus = [\"El hielo es agua en estado sólido\",\n",
        "          \"El hielo es uno de los cuatro estados naturales del agua\",\n",
        "          \"El agua pura se congela a 0 grados\",\n",
        "          \"El hielo es el nombre común del agua en estado sólido\"]"
      ],
      "outputs": [],
      "metadata": {
        "id": "FFWRRU00SygG"
      },
      "id": "FFWRRU00SygG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Para ejecutar este notebook"
      ],
      "metadata": {
        "id": "zyuxR3UTSygJ"
      },
      "id": "zyuxR3UTSygJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para ejecutar este notebook, instale las siguientes librerias:"
      ],
      "metadata": {
        "id": "U0BdtmHGSygK"
      },
      "id": "U0BdtmHGSygK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/docs/nlp/vectorization/vectorization.txt --quiet --no-clobber\n",
        "!pip install -r vectorization.txt"
      ],
      "outputs": [],
      "metadata": {
        "id": "Z_KMq7GnSygL"
      },
      "id": "Z_KMq7GnSygL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-hot encoding"
      ],
      "metadata": {
        "id": "uuc_1Ex6SygN"
      },
      "id": "uuc_1Ex6SygN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que el texto representará características discretas y categóricas, hace sentido pensar en utilizar métodos clásicos para este tipo de dato. **One-hot encoding** es una técnica sensilla que cosiste en representar las palabras con vectores de longitud igual al tamaño del vocabulario donde todas las posiciones son zero salvo la posición que corresponde al indice de la palabra en cuestión. Eso significa que las dimensiones de los vectores de entrada dependerá del tamaño del vocabulario y no del tamaño del cuerpo de texto. Este tipo de representación tiene la propiedad de que todas las palabras son igualmente relevantes para el modelo."
      ],
      "metadata": {
        "id": "2zskVUwgSygN"
      },
      "id": "2zskVUwgSygN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si bien este método es sencillo de implementar, genera representaciones dispersas, que genera dificultades a la hora de procesarlos. Sin embargo esto no significa que esta forma de codificación no sea práctica. Veremos más adelante que esta técnica se puede utilizar para aprender representaciones más complejas como [embeddings](https://m72109.readthedocs.io/es/latest/nlp/vectorization/embeddings.html). En estas configuraciones, la entrada de la red neuronal está especificada como una colección de vectores one-hot."
      ],
      "metadata": {
        "id": "11FT9sOoS_V9"
      },
      "id": "11FT9sOoS_V9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index-based encoding"
      ],
      "metadata": {
        "id": "fKhZpjEWSygO"
      },
      "id": "fKhZpjEWSygO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es una técnica similar a `one-hot encoding` salvo que aqui los vectores están representados utilizando los valores numéricos correspondientes a los índices que ocupan cada palabra dentro del vocabulario. Es decir que cada palabra está codificada como un número entero. Esto hace que el tamaño del vector no dependa del tamaño del vocabulario.\n",
        "\n",
        "En general, esta técnica no ofrece ninguna ventaja, pero se utiliza como una representación intermedia para implementar otras formas de vectorización. Por este motivo no se la suele referenciar como una técnica de **vectorización** sino que como un **diccionario de palabras** (ya que mapea *palabras* con *IDs únicos*) Veamos como utilizarla:"
      ],
      "metadata": {
        "id": "vb5pweKcSygP"
      },
      "id": "vb5pweKcSygP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero crearemos nuestro vocabulario:"
      ],
      "metadata": {
        "id": "-HylllRJSygP"
      },
      "id": "-HylllRJSygP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vocab = { i:w for w,i in enumerate(set(' '.join(corpus).split())) }"
      ],
      "outputs": [],
      "metadata": {
        "id": "cZTdZQzeSygP"
      },
      "id": "cZTdZQzeSygP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando el vocabulario, transformamos nuestros documentos en vectores:"
      ],
      "metadata": {
        "id": "v1cr590mSygQ"
      },
      "id": "v1cr590mSygQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vectors = [[vocab[w] for w in s.split(' ')] for s in corpus]"
      ],
      "outputs": [],
      "metadata": {
        "id": "qx-DdW3MSygQ"
      },
      "id": "qx-DdW3MSygQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(vectors)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>21.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0   1   2   3   4   5   6     7     8     9     10\n",
              "0   8  15  18   6  16   3  19   NaN   NaN   NaN   NaN\n",
              "1   8  15  18  10   4   5  13  21.0  11.0  14.0   6.0\n",
              "2   8   6   2   9   0  22  17   1.0   NaN   NaN   NaN\n",
              "3   8  15  18  20  12   7  14   6.0  16.0   3.0  19.0"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "metadata": {
        "id": "seKDU01pSygQ",
        "outputId": "e1c3a5a5-aa4d-43f4-8cd0-9223e62e2996"
      },
      "id": "seKDU01pSygQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basados en frecuencias"
      ],
      "metadata": {
        "id": "Mk67wK4USygR"
      },
      "id": "Mk67wK4USygR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se trata de una familia de métodos de los más ampliamente utilizado durante mucho tiempo para convertir texto en representaciones numéricas. En general, estos métodos representan el texto utilizando una lista de frecuencia de palabras, es decir, basandose de alguna forma en la frecuencia en la que aparecen."
      ],
      "metadata": {
        "id": "VhIZIN0ySygR"
      },
      "id": "VhIZIN0ySygR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los métodos basados en bag-of-words tienen las siguientes limitaciones:\n",
        "\n",
        " - El orden de las palabras es ignorado\n",
        " - La frecuencia de la plabra no necesariamente encapsula la importancia\n",
        " - Las frecuencias marginales juegan un papel importante (relación entre files y columnas)"
      ],
      "metadata": {
        "id": "fyRnJpBiSygR"
      },
      "id": "fyRnJpBiSygR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Term frecuency"
      ],
      "metadata": {
        "id": "RQJEfZHSSygR"
      },
      "id": "RQJEfZHSSygR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza un vector de longitud igual al tamaño del vocabulario, pero donde los valores corresponden a la frecuencia de la palabra w en el documento D. Las palabras más frecuentes tienen más relevancia.\n",
        "\n",
        "$$TF = \\frac {freq(w_i)} {len(doc)} $$"
      ],
      "metadata": {
        "id": "O32ZdBqQSygR"
      },
      "id": "O32ZdBqQSygR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(min_df=0., max_df=1.)\n",
        "vectors = vectorizer.fit_transform(corpus)"
      ],
      "outputs": [],
      "metadata": {
        "id": "_yHWF2NySygS"
      },
      "id": "_yHWF2NySygS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vectors = vectors.todense()"
      ],
      "outputs": [],
      "metadata": {
        "id": "_CuP_PYSSygS"
      },
      "id": "_CuP_PYSSygS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vectors.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "metadata": {
        "id": "dZHgVaQPSygS",
        "outputId": "6cbafcba-d69d-48f0-b702-4dedcd7f9807"
      },
      "id": "dZHgVaQPSygS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ¿Que representa 20 en las dimensiones del vector?"
      ],
      "metadata": {
        "id": "EPNzHBq9SygS"
      },
      "id": "EPNzHBq9SygS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Obtenemos todas las palabras del vocabulario\n",
        "vocab = vectorizer.get_feature_names()\n",
        "# Vectores de cada uno de los documentos\n",
        "pd.DataFrame(vectors, columns=vocab)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>agua</th>\n",
              "      <th>común</th>\n",
              "      <th>congela</th>\n",
              "      <th>cuatro</th>\n",
              "      <th>de</th>\n",
              "      <th>del</th>\n",
              "      <th>el</th>\n",
              "      <th>en</th>\n",
              "      <th>es</th>\n",
              "      <th>estado</th>\n",
              "      <th>estados</th>\n",
              "      <th>grados</th>\n",
              "      <th>hielo</th>\n",
              "      <th>los</th>\n",
              "      <th>naturales</th>\n",
              "      <th>nombre</th>\n",
              "      <th>pura</th>\n",
              "      <th>se</th>\n",
              "      <th>sólido</th>\n",
              "      <th>uno</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   agua  común  congela  cuatro  de  del  el  en  es  estado  estados  grados  \\\n",
              "0     1      0        0       0   0    0   1   1   1       1        0       0   \n",
              "1     1      0        0       1   1    1   1   0   1       0        1       0   \n",
              "2     1      0        1       0   0    0   1   0   0       0        0       1   \n",
              "3     1      1        0       0   0    1   2   1   1       1        0       0   \n",
              "\n",
              "   hielo  los  naturales  nombre  pura  se  sólido  uno  \n",
              "0      1    0          0       0     0   0       1    0  \n",
              "1      1    1          1       0     0   0       0    1  \n",
              "2      0    0          0       0     1   1       0    0  \n",
              "3      1    0          0       1     0   0       1    0  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "metadata": {
        "id": "jeAe-jbxSygT",
        "outputId": "3bd150e8-913a-48f4-b88d-5ba8ed5f85f9"
      },
      "id": "jeAe-jbxSygT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF"
      ],
      "metadata": {
        "id": "tqDCQpTHSygT"
      },
      "id": "tqDCQpTHSygT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se trata de un método similar a Term Frecuency, pero cuyo objetivo es tratar de ajustar la frecuencia de la palabra en cada documento considerando que tan frecuente es dentro del corpus (dispersión). Dispersión justamente se refiere a que tan equitativamente las palabras están distribuidas entre los diferentes documentos del texto.\n",
        "\n",
        "Este método considera que:\n",
        "\n",
        " - Cuanto más frecuente es una palabra en el corpus (más dispersa), más general es su significado.\n",
        " - Cuanto más centralizada está el uso de una palabra dentro de todo el corpus (baja dispersión), más probable es que la palabra represente un tópico puntual.\n",
        "\n",
        "Para calcular el peso de cada palabra debemos obtener:\n",
        "\n",
        " - **TF:** La frecuencia del termino en el corpus.\n",
        "\n",
        " $$TF = \\frac {freq(w_i)} {len(doc)} $$\n",
        "\n",
        " - **IDF:** La frecuencia (inversa) del termino en el documento.\n",
        "\n",
        "$$IDF = 1 + log(\\frac {len(corpus)} {freq(w_i, corpus)}) $$"
      ],
      "metadata": {
        "id": "rMp0s9bqSygT"
      },
      "id": "rMp0s9bqSygT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, `tfidf` se computa como la multiplicación de los dos terminos. Adicionalmente, se normaliza usando `L2`, es decir, la norma euclidiana. `L2` reducirá el tamaño de todos los pesos pero los hará 0. Si bien es menos eficiente en terminos de memoria, puede ser útil si queremos/necesitamos retener todos los parámetros.\n",
        "\n",
        "$$\n",
        "    \\textit{TF-IDF}_{normalized} = \\frac{tf \\times idf}{\\sqrt{(tf\\times idf)^2}}\n",
        "$$"
      ],
      "metadata": {
        "id": "FKH5deeOSygT"
      },
      "id": "FKH5deeOSygT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos como aplicarlo:"
      ],
      "metadata": {
        "id": "srjr6hnKSygT"
      },
      "id": "srjr6hnKSygT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(corpus)"
      ],
      "outputs": [],
      "metadata": {
        "id": "m12pg5HiSygT"
      },
      "id": "m12pg5HiSygT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vectors = vectors.todense()\n",
        "vectors.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "metadata": {
        "id": "yrICiomwSygU",
        "outputId": "fa6fcff6-4dfb-4cc8-d62b-20f34eff37cf"
      },
      "id": "yrICiomwSygU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Notemos que cambiar la forma de vectorización en estos casos no cambia la longitud de nuestros vectores (que siempre está dada por la dimensionalidad del vocabulario, en este caso 20). Solo cambia los valores numericos que se asignan en los vectores."
      ],
      "metadata": {
        "id": "j54VtxB0SygU"
      },
      "id": "j54VtxB0SygU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vocab = vectorizer.get_feature_names()\n",
        "pd.DataFrame(np.round(vectors, 2), columns=vocab)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>agua</th>\n",
              "      <th>común</th>\n",
              "      <th>congela</th>\n",
              "      <th>cuatro</th>\n",
              "      <th>de</th>\n",
              "      <th>del</th>\n",
              "      <th>el</th>\n",
              "      <th>en</th>\n",
              "      <th>es</th>\n",
              "      <th>estado</th>\n",
              "      <th>estados</th>\n",
              "      <th>grados</th>\n",
              "      <th>hielo</th>\n",
              "      <th>los</th>\n",
              "      <th>naturales</th>\n",
              "      <th>nombre</th>\n",
              "      <th>pura</th>\n",
              "      <th>se</th>\n",
              "      <th>sólido</th>\n",
              "      <th>uno</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   agua  común  congela  cuatro    de   del    el    en    es  estado  \\\n",
              "0  0.29   0.00     0.00    0.00  0.00  0.00  0.29  0.44  0.36    0.44   \n",
              "1  0.18   0.00     0.00    0.35  0.35  0.28  0.18  0.00  0.23    0.00   \n",
              "2  0.24   0.00     0.47    0.00  0.00  0.00  0.24  0.00  0.00    0.00   \n",
              "3  0.20   0.39     0.00    0.00  0.00  0.31  0.40  0.31  0.25    0.31   \n",
              "\n",
              "   estados  grados  hielo   los  naturales  nombre  pura    se  sólido   uno  \n",
              "0     0.00    0.00   0.36  0.00       0.00    0.00  0.00  0.00    0.44  0.00  \n",
              "1     0.35    0.00   0.23  0.35       0.35    0.00  0.00  0.00    0.00  0.35  \n",
              "2     0.00    0.47   0.00  0.00       0.00    0.00  0.47  0.47    0.00  0.00  \n",
              "3     0.00    0.00   0.25  0.00       0.00    0.39  0.00  0.00    0.31  0.00  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "metadata": {
        "id": "N4dmJHarSygU",
        "outputId": "5e6b2d34-87ec-49a2-e5cb-b6bee36dcd7a"
      },
      "id": "N4dmJHarSygU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusión"
      ],
      "metadata": {
        "id": "Be_gwPEcSygV"
      },
      "id": "Be_gwPEcSygV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En estos métodos, cada caractéritica o palabra que forma parte de nuestra entrada está representada en su propia dimensión, y como resultado, tenemos representaciones que dependen del tamaño del vocabulario. Estas representaciones tienen la característica de que la representación de cada palabra es independiente de las restantes. Esto quiere decir que el vector que corresponde a la palabra *perro* es tan distinto al vector que corresponde a *gato* como lo es al que corresponde con *heladera*.\n",
        "\n",
        "En la siguiente sección veremos técnicas de vectorización de vectores de espacios continuos, donde estas características no se cumplen."
      ],
      "metadata": {
        "id": "Wty0OepXSygV"
      },
      "id": "Wty0OepXSygV"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}