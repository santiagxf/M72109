{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Vectorización de texto\n",
    "======================\n",
    "\n",
    "## Introducción"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Un modelos de aprendizaje automático es, a groso modo, una función parametrizada `f(x)` que toma como entrada\n",
    "un vector `x`, `n-dimensional`, y produce un vector de salida `m-dimensional`. Tal función puede ser simple (para un modelo lineal por ejemplo) o más compleja (como una red neuronal).\n",
    "\n",
    "Cuando trabajamos con lenguaje natural, la mayoría de nuestros datos de entrada representarán características discretas y categóricas, ya sean palabras, letras o incluso utterancias (partes del discurso). La pregunta que nos haremos entonces es ¿Cómo codificamos esos datos categóricos de una manera que sea práctica para ser utilizada por un modelo de aprendizaje automático? \n",
    "\n",
    "Discutiremos las opciones disponibles.\n",
    "\n",
    " - [One-hot encoding](#One-hot-encoding)\n",
    " - [Index-based encoding](#Index-based-encoding)\n",
    " - [Bag-of-words (BOW)](#Bag-of-words-(BOW))\n",
    " - [Dense encoding (embeddings)](#Dense-encoding-(embeddings))\n",
    " \n",
    " Utilizaremos el siguiente corpus para nuestros ejemplos:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "corpus = [\"El hielo es agua en estado sólido\",\n",
    "          \"El hielo es uno de los cuatro estados naturales del agua\",\n",
    "          \"El agua pura se congela a 0 grados\",\n",
    "          \"El hielo es el nombre común del agua en estado sólido\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Para ejecutar este notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para ejecutar este notebook, instale las siguientes librerias:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/docs/nlp/vectorization/Vectorization.txt --quiet --no-clobber\n",
    "!pip install -r Vectorization.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-hot encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dado que el texto representará características discretas y categóricas, hace sentido pensar en utilizar métodos clásicos para este tipo de dato. **One-hot encoding** es una técnica sensilla que cosiste en representar las palabras con vectores de longitud igual al tamaño del vocabulario donde todas las posiciones son zero salvo la posición que corresponde al indice de la palabra en cuestión. Eso significa que las dimensiones de los vectores de entrada dependerá del tamaño del vocabulario y no del tamaño del cuerpo de texto. Este tipo de representación tiene la propiedad de que todas las palabras son igualmente relevantes para el modelo.\n",
    "\n",
    "Si bien este método es sencillo de implementar, genera representaciones dispersas, con mucha cantidad de zeros, que genera dificultades a la hora de procesarlos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Index-based encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Es una técnica similar a `one-hot encoding` salvo que aqui los vectores están representados utilizando los valores numéricos correspondientes a los índices que ocupan cada palabra dentro del vocabulario. Es decir que cada palabra está codificada como un número entero. Esto hace que el tamaño del vector no dependa del tamaño del vocabulario.\n",
    "\n",
    "En general, esta técnica no ofrece ninguna ventaja, pero se utiliza como una representación intermedia para implementar otras formas de vectorización. Por este motivo no se la suele referenciar como una técnica de **vectorización** sino que como un **diccionario de palabras** (ya que mapea *palabras* con *IDs únicos*) Veamos como utilizarla:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Primero crearemos nuestro vocabulario:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "vocab = { i:w for w,i in enumerate(set(' '.join(corpus).split())) }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizando el vocabulario, transformamos nuestros documentos en vectores:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "vectors = [[vocab[w] for w in s.split(' ')] for s in corpus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(vectors)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6     7     8     9     10\n",
       "0   8  15  18   6  16   3  19   NaN   NaN   NaN   NaN\n",
       "1   8  15  18  10   4   5  13  21.0  11.0  14.0   6.0\n",
       "2   8   6   2   9   0  22  17   1.0   NaN   NaN   NaN\n",
       "3   8  15  18  20  12   7  14   6.0  16.0   3.0  19.0"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bag-of-words (BOW)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se trata de una familia de métodos de los más ampliamente utilizado durante mucho tiempo para convertir texto en representaciones numéricas. En general, estos métodos representan el texto utilizando una lista de frecuencia de palabras, es decir, basandose de alguna forma en la frecuencia en la que aparecen."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los métodos basados en bag-of-words tienen las siguientes limitaciones:\n",
    "\n",
    " - El orden de las palabras es ignorado\n",
    " - La frecuencia de la plabra no necesariamente encapsula la importancia\n",
    " - Las frecuencias marginales juegan un papel importante (relación entre files y columnas)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Term frecuency"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utiliza un vector de longitud igual al tamaño del vocabulario, pero donde los valores corresponden a la frecuencia de la palabra w en el documento D. Las palabras más frecuentes tienen más relevancia.\n",
    "\n",
    "$$TF = \\frac {freq(w_i)} {len(doc)} $$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0., max_df=1.)\n",
    "vectors = vectorizer.fit_transform(corpus)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "vectors = vectors.todense()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "vectors.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4, 20)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ¿Que representa 20 en las dimensiones del vector?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Obtenemos todas las palabras del vocabulario\n",
    "vocab = vectorizer.get_feature_names()\n",
    "# Vectores de cada uno de los documentos\n",
    "pd.DataFrame(vectors, columns=vocab)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agua</th>\n",
       "      <th>común</th>\n",
       "      <th>congela</th>\n",
       "      <th>cuatro</th>\n",
       "      <th>de</th>\n",
       "      <th>del</th>\n",
       "      <th>el</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>estado</th>\n",
       "      <th>estados</th>\n",
       "      <th>grados</th>\n",
       "      <th>hielo</th>\n",
       "      <th>los</th>\n",
       "      <th>naturales</th>\n",
       "      <th>nombre</th>\n",
       "      <th>pura</th>\n",
       "      <th>se</th>\n",
       "      <th>sólido</th>\n",
       "      <th>uno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agua  común  congela  cuatro  de  del  el  en  es  estado  estados  grados  \\\n",
       "0     1      0        0       0   0    0   1   1   1       1        0       0   \n",
       "1     1      0        0       1   1    1   1   0   1       0        1       0   \n",
       "2     1      0        1       0   0    0   1   0   0       0        0       1   \n",
       "3     1      1        0       0   0    1   2   1   1       1        0       0   \n",
       "\n",
       "   hielo  los  naturales  nombre  pura  se  sólido  uno  \n",
       "0      1    0          0       0     0   0       1    0  \n",
       "1      1    1          1       0     0   0       0    1  \n",
       "2      0    0          0       0     1   1       0    0  \n",
       "3      1    0          0       1     0   0       1    0  "
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF-IDF"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se trata de un método similar a Term Frecuency, pero cuyo objetivo es tratar de ajustar la frecuencia de la palabra en cada documento considerando que tan frecuente es dentro del corpus (dispersión). Dispersión justamente se refiere a que tan equitativamente las palabras están distribuidas entre los diferentes documentos del texto.\n",
    "\n",
    "Este método considera que:\n",
    "\n",
    " - Cuanto más frecuente es una palabra en el corpus (más dispersa), más general es su significado.\n",
    " - Cuanto más centralizada está el uso de una palabra dentro de todo el corpus (baja dispersión), más probable es que la palabra represente un tópico puntual.\n",
    "\n",
    "Para calcular el peso de cada palabra debemos obtener:\n",
    "\n",
    " - **TF:** La frecuencia del termino en el corpus.\n",
    " \n",
    " $$TF = \\frac {freq(w_i)} {len(doc)} $$\n",
    " \n",
    " - **IDF:** La frecuencia (inversa) del termino en el documento.\n",
    "\n",
    "$$IDF = 1 + log(\\frac {len(corpus)} {freq(w_i, corpus)}) $$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, `tfidf` se computa como la multiplicación de los dos terminos. Adicionalmente, se normaliza usando `L2`, es decir, la norma euclidiana. `L2` reducirá el tamaño de todos los pesos pero los hará 0. Si bien es menos eficiente en terminos de memoria, puede ser útil si queremos/necesitamos retener todos los parámetros.\n",
    "\n",
    "$$\n",
    "    \\textit{TF-IDF}_{normalized} = \\frac{tf \\times idf}{\\sqrt{(tf\\times idf)^2}}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos como aplicarlo:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(corpus)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "vectors = vectors.todense()\n",
    "vectors.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4, 20)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Notemos que cambiar la forma de vectorización en estos casos no cambia la longitud de nuestros vectores (que siempre está dada por la dimensionalidad del vocabulario, en este caso 20). Solo cambia los valores numericos que se asignan en los vectores."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "pd.DataFrame(np.round(vectors, 2), columns=vocab)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agua</th>\n",
       "      <th>común</th>\n",
       "      <th>congela</th>\n",
       "      <th>cuatro</th>\n",
       "      <th>de</th>\n",
       "      <th>del</th>\n",
       "      <th>el</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>estado</th>\n",
       "      <th>estados</th>\n",
       "      <th>grados</th>\n",
       "      <th>hielo</th>\n",
       "      <th>los</th>\n",
       "      <th>naturales</th>\n",
       "      <th>nombre</th>\n",
       "      <th>pura</th>\n",
       "      <th>se</th>\n",
       "      <th>sólido</th>\n",
       "      <th>uno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agua  común  congela  cuatro    de   del    el    en    es  estado  \\\n",
       "0  0.29   0.00     0.00    0.00  0.00  0.00  0.29  0.44  0.36    0.44   \n",
       "1  0.18   0.00     0.00    0.35  0.35  0.28  0.18  0.00  0.23    0.00   \n",
       "2  0.24   0.00     0.47    0.00  0.00  0.00  0.24  0.00  0.00    0.00   \n",
       "3  0.20   0.39     0.00    0.00  0.00  0.31  0.40  0.31  0.25    0.31   \n",
       "\n",
       "   estados  grados  hielo   los  naturales  nombre  pura    se  sólido   uno  \n",
       "0     0.00    0.00   0.36  0.00       0.00    0.00  0.00  0.00    0.44  0.00  \n",
       "1     0.35    0.00   0.23  0.35       0.35    0.00  0.00  0.00    0.00  0.35  \n",
       "2     0.00    0.47   0.00  0.00       0.00    0.00  0.47  0.47    0.00  0.00  \n",
       "3     0.00    0.00   0.25  0.00       0.00    0.39  0.00  0.00    0.31  0.00  "
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dense encoding (embeddings)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quizás el mayor salto conceptual al pasar de modelos lineales (que utilizan matrices dispersas) a modelos de aprendizaje profundo no lineales es dejar de representar cada característica (feature) como una única dimensión que depende del tamaño del vocabulario y representarlos como vectores densos. Es decir, cada característica está **embebida**\n",
    "en un espacio dimensional d, y se representa como un vector en ese espacio. La dimensión d es usualmente mucho más pequeña que el tamaño del vocabulario (codificado como vectores unidimensionales). En general, estos vectores adquieren dimensiones de 100-300 dimensiones. Estos *embeddings* (la representación vectorial de cada una de las palabras) se incorporan como parámetros de modelos neuronales (generalmente)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Abordaremos este tema en el próximo capítulo."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}