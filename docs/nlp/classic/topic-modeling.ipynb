{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RcCek8lsFze"
      },
      "source": [
        "T√©cnicas de reducci√≥n de dimensionalidad\n",
        "==================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Irja1O_J9X"
      },
      "source": [
        "## Introducci√≥n\n",
        "\n",
        "Topic modeling es una t√©cnica de aprendizaje autom√°tico no supervisado donde intentados descubrir t√≥picos que son abstractos al texto pero que pueden describir una colecci√≥n de documentos. Es importante marcar que estos \"t√≥picos\" no son necesariamente equivalentes a la interpretaci√≥n coloquial de t√≥picos, sino que responden a un patr√≥n que emerge de las palabras que est√°n en los documentos.\n",
        "\n",
        "La suposici√≥n b√°sica para Topic Modeling es que cada documento est√° representado por una mescla de t√≥picos, y cada t√≥pico consiste en una colecci√≥n de palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJKJtlkCsFzn"
      },
      "source": [
        "### Para ejecutar este notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjntkNZ5sFzn"
      },
      "source": [
        "Para ejecutar este notebook, instalaremos las siguientes librerias:\n",
        "\n",
        "```\n",
        "nltk\n",
        "pandas\n",
        "numpy\n",
        "matplotlib\n",
        "tqdm\n",
        "spacy==2.3.5\n",
        "unidecode\n",
        "scikit-learn\n",
        "importlib-metadata==4.13.0\n",
        "pyLDAvis\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9zClL8PJsFzo"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Datasets/mascorpus/tweets_marketing.csv \\\n",
        "    --quiet --no-clobber --directory-prefix ./Datasets/mascorpus/\n",
        "    \n",
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/docs/nlp/classic/topic-modeling.txt \\\n",
        "    --quiet --no-clobber\n",
        "!pip install -r topic-modeling.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KgoST-ebsFzq"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download es_core_news_sm 1> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deshabilitamos algunos mensajes de advertencias:"
      ],
      "metadata": {
        "id": "uVCSKx1cu6Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "ltgAo3Y2u9md"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPpqVNrwSdhL"
      },
      "source": [
        "Primero importaremos algunas librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zPfF_O0U_J9a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE_O7bEjLebd"
      },
      "source": [
        "## Sobre el set de datos con el que vamos a trabajar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8lcRTa_Li4e"
      },
      "source": [
        "Utilizaremos como ejemplo un set de datos en espa√±ol que contiene tweets que diferentes usuarios han publicado en relaci√≥n a diferentes marcas de productos u empresas en el rubro de alimentaci√≥n, construcci√≥n, automoviles, etc. Estos tweets, a su vez, est√°n asociados a una de las diferentes fases en el proceso de ventas (tambi√©n conocido como Marketing Funel) y por eso est√°n tagueados con las fases de:\n",
        " - Awareness ‚Äì el cliente es conciente de la existencia de un producto o servicio\n",
        " - Interest ‚Äì activamente expresa el interes de un producto o servicio\n",
        " - Evaluation ‚Äì aspira una marca o producto en particular\n",
        " - Purchase ‚Äì toma el siguiente paso necesario para comprar el producto o servicio\n",
        " - Postpurchase - realizaci√≥n del proceso de compra. El cliente compara la diferencia entre lo que deseaba y lo que obtuvo\n",
        "\n",
        "Referencia: [Spanish Corpus of Tweets for Marketing](http://ceur-ws.org/Vol-2111/paper1.pdf\n",
        "\n",
        "> Nota: La version de este conjunto de datos que utilizaremos aqui es una versi√≥n preprocesada del original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gc44Q7do_J9h"
      },
      "outputs": [],
      "source": [
        "tweets = pd.read_csv('Datasets/mascorpus/tweets_marketing.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INJwReUXSs4K"
      },
      "source": [
        "Inspeccionamos el set de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Gd6EocPdG5A0",
        "outputId": "3b03557b-ffd3-4135-aa3b-354c71bcb4e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               TEXTO  SECTOR      MARCA  \\\n",
              "0  #tablondeanuncios Funda nordica ikea #madrid h...  RETAIL       IKEA   \n",
              "1  #tr Me ofrezco para montar muebles de Ikea - H...  RETAIL       IKEA   \n",
              "2  #VozP√≥puli Vozp√≥puli @voz_populi - #LoM√°sLeido...  RETAIL    ALCAMPO   \n",
              "3  #ZonaTecno Destacado: Todo lo que hay que sabe...  RETAIL  CARREFOUR   \n",
              "4  $Carrefour retira pez #Panga. OCU y grupos x #...  RETAIL  CARREFOUR   \n",
              "\n",
              "       CANAL  AWARENESS  EVALUATION  PURCHASE  POSTPURCHASE  NC2  \n",
              "0  Microblog          0           0       0.0             0  1.0  \n",
              "1  Microblog          0           0       0.0             0  1.0  \n",
              "2  Microblog          0           0       0.0             0  1.0  \n",
              "3  Microblog          0           0       0.0             0  1.0  \n",
              "4  Microblog          0           0       0.0             0  1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-429bb74f-97ce-4923-bbfa-3d30516ea753\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXTO</th>\n",
              "      <th>SECTOR</th>\n",
              "      <th>MARCA</th>\n",
              "      <th>CANAL</th>\n",
              "      <th>AWARENESS</th>\n",
              "      <th>EVALUATION</th>\n",
              "      <th>PURCHASE</th>\n",
              "      <th>POSTPURCHASE</th>\n",
              "      <th>NC2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#tablondeanuncios Funda nordica ikea #madrid h...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>IKEA</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#tr Me ofrezco para montar muebles de Ikea - H...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>IKEA</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#VozP√≥puli Vozp√≥puli @voz_populi - #LoM√°sLeido...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>ALCAMPO</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#ZonaTecno Destacado: Todo lo que hay que sabe...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>CARREFOUR</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>$Carrefour retira pez #Panga. OCU y grupos x #...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>CARREFOUR</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-429bb74f-97ce-4923-bbfa-3d30516ea753')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-429bb74f-97ce-4923-bbfa-3d30516ea753 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-429bb74f-97ce-4923-bbfa-3d30516ea753');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tweets.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "uXwJS2Og_J9l",
        "outputId": "c61d78a3-82e8-4ab2-d32e-2575366de134"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  TEXTO        SECTOR\n",
              "0     #tablondeanuncios Funda nordica ikea #madrid h...        RETAIL\n",
              "725   \"Ilcinsisti lis MB dispiniblis\" te odeeeeeo Mo...         TELCO\n",
              "964   #CarlosSlim y Bimbo lanzar√°n un veh√≠culo el√©ct...  ALIMENTACION\n",
              "1298  ‚ÄºüèéToyota #Day, 4ruedas ,1/4 milla, 1 #pasi√≥n, ...    AUTOMOCION\n",
              "1748  \"- T√∫ qu√©.\\n- Yo na.\"\\nConversaciones banco sa...         BANCA\n",
              "2348  - Cari√±o, te juro que s√≥lo ten√≠an Cruzcampo en...       BEBIDAS\n",
              "3023  #adidas #hockey Amenabar 2080 CABA https://t.c...      DEPORTES"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cdcafa0-3c38-492c-9fa0-01437c6af8bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXTO</th>\n",
              "      <th>SECTOR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#tablondeanuncios Funda nordica ikea #madrid h...</td>\n",
              "      <td>RETAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>\"Ilcinsisti lis MB dispiniblis\" te odeeeeeo Mo...</td>\n",
              "      <td>TELCO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>#CarlosSlim y Bimbo lanzar√°n un veh√≠culo el√©ct...</td>\n",
              "      <td>ALIMENTACION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>‚ÄºüèéToyota #Day, 4ruedas ,1/4 milla, 1 #pasi√≥n, ...</td>\n",
              "      <td>AUTOMOCION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1748</th>\n",
              "      <td>\"- T√∫ qu√©.\\n- Yo na.\"\\nConversaciones banco sa...</td>\n",
              "      <td>BANCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2348</th>\n",
              "      <td>- Cari√±o, te juro que s√≥lo ten√≠an Cruzcampo en...</td>\n",
              "      <td>BEBIDAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3023</th>\n",
              "      <td>#adidas #hockey Amenabar 2080 CABA https://t.c...</td>\n",
              "      <td>DEPORTES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cdcafa0-3c38-492c-9fa0-01437c6af8bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6cdcafa0-3c38-492c-9fa0-01437c6af8bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6cdcafa0-3c38-492c-9fa0-01437c6af8bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "tweets.groupby('SECTOR').head(1)[['TEXTO', 'SECTOR']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9FcIehJ_J9q"
      },
      "source": [
        "## Preprosesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfUnlH25HEeM"
      },
      "source": [
        "Como en toda tarea de NLP, y m√°s generalmente, en Machine Learning, ocuparemos una porci√≥n de nuestro tiempo en preprocesar los datos para generar representaciones √∫tiles y deshacernos de problemas especificos que podr√≠a exhibir nuestro set de datos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZISG0Cs_J-g"
      },
      "source": [
        "### Creando una rutina de preprosesamiento de texto\n",
        "\n",
        "Realizaremos las tareas cotidianas de preprocesamiento. Adicionalmente nuestra rutina va a: \n",
        "\n",
        " - Eliminar caracteres especiales: Acentos y caracteres especiales podr√≠an complejizar el la representaci√≥n de palabras, por lo que los eliminaremos.\n",
        " - Eliminaremos URLs y handles que son t√≠picos en tweeter. Esto es especifico en este set de datos ya que una URL no representa informaci√≥n en este contexto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0eJxv1LA_J-g"
      },
      "outputs": [],
      "source": [
        "import unidecode\n",
        "import spacy\n",
        "import es_core_news_sm as spa\n",
        "import re\n",
        "import nltk\n",
        "from nltk import stem\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize.casual import TweetTokenizer\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "parser = spa.load() # Cargamos el parser en espa√±ol\n",
        "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True) # Creamos un tokenizer\n",
        "stemmer = stem.SnowballStemmer(language='spanish') # Creamos un steammer\n",
        "lemmatizer = lambda word : \" \".join([token.lemma_ for token in parser(word)]) # Creamos un lemmatizer\n",
        "stopwords = set(stopwords.words('spanish')) # Instanciamos las stopwords en espa√±ol\n",
        "urls_regex = re.compile('http\\S+') # Usamos una expresion regular para encontrar las URLs\n",
        "\n",
        "def process_text(text):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token for token in tokens if not re.match(urls_regex, token)]\n",
        "    tokens = [token for token in tokens if len(token) > 4]\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    tokens = [unidecode.unidecode(token) for token in tokens] # Quitamos acentos\n",
        "    tokens = [lemmatizer(token) for token in tokens]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4uXheye_J-j",
        "outputId": "92baf020-1119-45a9-e01e-910ca1cf173d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3763/3763 [01:35<00:00, 39.51it/s]\n"
          ]
        }
      ],
      "source": [
        "doc_list = []\n",
        "\n",
        "for doc in tqdm(tweets['TEXTO']):\n",
        "    tokens = process_text(doc)\n",
        "    doc_list.append(' '.join(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtykSqbA_J-l"
      },
      "source": [
        "Revisemos algunos resultados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QQgWOejW_J-l",
        "outputId": "c465d9c3-9405-4448-ecd8-a44b567df7cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#VozP√≥puli Vozp√≥puli @voz_populi - #LoM√°sLeidoHoy Mercadona, DIA o Alcampo guardan silencio ante la ola europea... https://t.co/aJTuA4J9UV'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tweets['TEXTO'][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "huZ2Cu2Q_J-n",
        "outputId": "211d694b-e234-4a1b-f4fb-8b479c15885c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# VozPopuli Vozpopuli # LoMasLeidoHoy Mercadona Alcampo guardar silenciar europeo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "doc_list[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WSbMjTnRYXT",
        "outputId": "137eb172-2181-44e3-a6aa-e39fb2dd13ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3763"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(doc_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PXVzn24_J-p"
      },
      "source": [
        "## Vectorizaci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLwWu__sX4Rq"
      },
      "source": [
        "Una vez que nuesto texto fue preprocesado para mantener solo aquellas palabras que nos son relevantes, pasamos al proceso de generar vectores a partir de las palabras que componen nuestro vocabulario. Nuestros modelos no pueden operar sobre palabras, y por lo tanto necesitamos una representaci√≥n n√∫merica de las mismas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JUldeeN6_J-7"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=True, sublinear_tf=True, norm='l2')\n",
        "vectors = vectorizer.fit_transform(doc_list).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pTQYz9ABsFz7",
        "outputId": "435fbdcc-1f3d-40f9-80d8-8ceb7973ca9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3763, 6733)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "vectors.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5YtJxjQXgxH"
      },
      "source": [
        "## Reducci√≥n de dimensionalidad: Featurization\n",
        "Una vez que tenemos nuestros palabras representadas como vectores, nos aparece el problema de que ¬°a√∫n son demasiado grandes! En el ejemplo anterior, estamos trabajando con vectores en un espacio de 6K+. Necesitamos reducir esta dimensionalidad. Para esto, utilizaremos m√©todos de reducci√≥n de dimensionalidad con el objetivo de generar features que nos sean m√°s utiles. Estas features las generaremos de forma \"no supervisada\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI4HLD1tkTBT"
      },
      "source": [
        "### M√©todos b√°sados en descomposici√≥n de matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8tC0kyK_J-6"
      },
      "source": [
        "Los modelos basados en factorizaci√≥n de matrices intentan reducir la dimensionalidad de la matriz al aproximarla usando dos matrices que representan embeddings de palabras y embeddings de documentos (m√°s una matriz singular que los vincula los unos con los otros). Este m√©todo es bastante popular no solo en NLP sino que tambi√©n en sistemas de recomendaci√≥n, m√©todo que fu√© ganador del Netflix Prize (Funk SVD).\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/700/1*Z0EUVs7QElEqRqXtqut_FQ.png\" />\n",
        "\n",
        "\n",
        "U y V(trapuesta) son ortogonales. Esto es de esperar porque si determinadas propiedades determinan un determinado factor latente, entonces esas propiedades ser√°n poco relevantes en los restantes factores (pues sino, no har√≠a sentido que conformen un factor distinto en un primer lugar).\n",
        "\n",
        "SVC es un metodo de decomposici√≥n exacto, lo que singnifica que las matrices U y V son lo suficientemente grandes para mapear exactamente la matriz A. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh1u5cZzkKbO"
      },
      "source": [
        "### LSI - Latent Semantic Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1pbwdPv_J-7"
      },
      "source": [
        "LSI es un caso particular de factorizaci√≥n de matrices. Cuando SVD es utilizado para procesar t√≥picos en texto y en donde los valores de la matriz A corresponden a frecuencias de palabras, este m√©todo se lo denomina Latent Semantic Analysis (sin embargo, en NLP no se lo suele nombrar como LSI).\n",
        "\n",
        "Dado que SVC es un m√©todo de decomposici√≥n exacto, tiende a producir matrices de poca densidad (sparse). Para evitar este problema, se utiliza una versi√≥n modificada de SVC conocida como Truncated SVD que solamente computa los k componentes mas grandes en la descomposici√≥n. Esto ayuda a que LSI combata efectivamente el problema de matrices sparse que tienden a generarse cuando se tienen cuerpos de texto con sin√≥nimos y palabras que significan varias cosas dependiendo del contexto. Truncated SVD ev√≠ta ser un m√©todo de decomposici√≥n exacto al aproximar la matriz A utilizando los k t√≥picos m√°s relevantes.\n",
        "\n",
        "<img src='https://github.com/fastai/course-nlp/raw/aabfeddf61fea29b18c72f841d057b56a216b7eb/images/svd_fb.png' />\n",
        "\n",
        "Facebook Research: Fast Randomized SVD [https://research.fb.com/fast-randomized-svd/])\n",
        "\n",
        "En esta configuraci√≥n entonces:\n",
        " - Un documento es nada mas que la distribuci√≥n de palabras que ocurren en el (Bag of words)\n",
        " - A es una matriz de m x n donde m es la cantidad de documentos √∫ observaciones, y n es la cantidad de palabras en el vocabulario.\n",
        " - Los valores de A corresponden a la frecuencia de la cada palabra del vocabulario en cada observaci√≥n √∫ documento.\n",
        " - A es una matriz sujeta a ruido con distribuci√≥n Gausiana.\n",
        "\n",
        "\n",
        "Referencia: Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions [https://arxiv.org/abs/0909.4061]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1iGWgQZca0C"
      },
      "source": [
        "El principal parametro en LSI es el numero de factores que queremos generar (el parametro K). No existe una regla para especificar este parametro ya que depende del escenario. Valores muy peque√±os pueden forzar a los documentos a ser colisionar en los t√≥picos que son asignados, mientras que valores muy grandes pueden hacer que palabras poco frecuentes y raras terminen determinando su propio \"topico\". \n",
        "\n",
        "> Valores t√≠picos de este par√°metro est√°n en 50 < k < 300\n",
        "\n",
        "En la librer√≠a `scikit-learn`, este valor lo especificaremos en `n_components`. El parametro `algorithm` hace referencia al m√©todo que utilizaremos para generar la descomposici√≥n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ2uzF82_J--",
        "outputId": "ae935012-881c-428b-86ab-ae45333707ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=7, algorithm='randomized')\n",
        "USigma = svd.fit_transform(vectors)\n",
        "Sigma = svd.singular_values_\n",
        "VT = svd.components_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bFhXZc6eHQL"
      },
      "source": [
        "Si bien en el codigo anterior estamos viendo las 3 matrices, solo nos interesa la matriz VT. ¬øPorque? Recuerden que nuestro \"input\" es un conjunto de palabras que luego vectorizamos utilizando TF-IDF. Cada documento est√° representado por este conjunto de palabras. Nuestro objetivo es disponer una forma donde podamos convertir este set de palabras a \"t√≥picos\" que sean m√°s informativos que las palabras propiamente dichas. **En consecuencia, lo √∫nico que nos interesa aqui es la matriz VT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvvt3kpu_J_A",
        "outputId": "06618569-3f8d-474b-9424-f9d3fb6281ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 6733)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "VT.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwu_KCg__J_C"
      },
      "source": [
        "Internamente, TrucatedSVC es un wrapper de la clase randomized_svd donde la matr√≠z Q que vimos anteriormente se genera a trav√©s de un m√©todo de sampling aleatorio. Las siguientes lineas son equivalentes a lo que vimos anteriormente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kigl-Xl_J_D",
        "outputId": "4edce893-6ac1-4125-95c7-b016a41b27ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:376: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.extmath import randomized_svd\n",
        "\n",
        "U, Sigma, VT = randomized_svd(vectors, \n",
        "                              n_components=7,\n",
        "                              n_iter=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV9fOGLB_J_F"
      },
      "source": [
        "Podemos validar que U es una matriz ortogonal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLYEo9Gm_J_F",
        "outputId": "f96afd3d-242b-4ba7-d5a6-976a2fe35a82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "np.allclose(U.T @ U, np.eye(U.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSv1wUgK_J_I"
      },
      "source": [
        "Lo siguiente es solo a titulo informativo, pero si vemos los valores de la matriz Sigma, veremos la importancia relativa de los documentos con respecto a los t√≥picos que encontramos. Si los gr√°ficamos vemos que sus valores comienzan a decrecer relativamente r√°pido, sosteniendo la supoci√≥n de que Truncated SVD genera los K m√°s relevantes t√≥picos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "HVI80HRw_J_I",
        "outputId": "ad69eb56-6bf5-4fcd-dcdb-6973964c3bcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6e204a7d90>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(Sigma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR8CpAYe_J_K"
      },
      "source": [
        "#### Interpretando los t√≥picos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra5f0S7FfKjG"
      },
      "source": [
        "La siguiente funci√≥n solo toma la matriz de VT y obtiene las 8 palabras m√°s importantes en este topico. Si quieren pueden variar este parametro para ver m√°s palabras e inspeccionar los t√≥picos. Esto es importante porque LSI es un m√©todo no supervisado, por lo tanto no sabemos a priori cuando un t√≥pico es bueno o malo. El sentido debemos darselo nosotros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fBNIN0xE_J_K"
      },
      "outputs": [],
      "source": [
        "vocab = {value:key for (key, value) in vectorizer.vocabulary_.items()}\n",
        "\n",
        "def show_topics(a):\n",
        "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[-8:-1]]\n",
        "    topic_words = ([top_words(t) for t in a])\n",
        "    return [' '.join(t) for t in topic_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDhDFVY9_J_M",
        "outputId": "4e926128-fda6-4fd2-af70-a914e61d5730"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['medalla querer ganar gustar comprar cerveza cruzcampo',\n",
              " 'olimpia nikes siempre nuevo zapatilla camiseta adidas',\n",
              " 'comprar nuevo conocer gustar aldub81stweeksary superstar cruzcampo',\n",
              " 'bueno querer invitar beber arruinaunacitacon4palabras cerveza gustar',\n",
              " '10 terminar carrera milka ritmar correr acabo',\n",
              " 'alfajor querer ganar carrefour comprar mercadona chocolate',\n",
              " 'panga vender movistar mejor comprar bimbo carrefour']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "show_topics(VT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKCo8UOd_J_Q"
      },
      "source": [
        "Limitaciones en LSI:\n",
        " - LSI sufre de un problema llamado \"Indeterminaci√≥n del signo\", que b√°sicamente significa que el signo en la matr√≠z VT y USigma dependen del algorimo que se utiliz√≥ para generarlos y de las condiciones iniciales (initial random state). En este contexto, que significa que un t√≥pico est√© relacionado con una palabra en un valor negativo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no6V6rtO_J_Q"
      },
      "source": [
        "### NMF: Non-negative Matrix Factorization\n",
        "\n",
        "Motivaci√≥n: En lugar de construir nuestros factores imponiendo la restricci√≥n de que sean ortogonales, la idea es de construirlos de tal forma que sean no-negativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NQwyjnN8_J_R"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nmf = NMF(n_components=7, random_state = 1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdTfBg2n_J_U",
        "outputId": "556cd182-72e3-4bea-a407-955beba36c23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:294: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "W1 = nmf.fit_transform(vectors)\n",
        "H1 = nmf.components_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIYwacxIfxqQ"
      },
      "source": [
        "En este caso, la matriz que nos interesa es H1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S39Zrr06_J_a",
        "outputId": "64cebfe0-fe61-4bd9-e047-a4e9d71659ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 6733)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "H1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkEBkOc-fqtT"
      },
      "source": [
        "#### Interpretando los t√≥picos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8qfO_Dx_J_d",
        "outputId": "93817fe2-e6ce-4b7a-c9dd-8dafbab86c1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['novio comprar querer corona medalla cerveza ganar',\n",
              " 'olimpia color nikes siempre nuevo zapatilla camiseta',\n",
              " 'tenis napaacc cliente nuevo conocer aldub81stweeksary superstar',\n",
              " 'mahou invitar querer beber arruinaunacitacon4palabras cerveza gustar',\n",
              " '50 10 terminar carrera ritmar correr acabo',\n",
              " 'mcflurry necesito quiero querer alfajor ganar chocolate',\n",
              " 'panga vender movistar mejor comprar bimbo carrefour']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "show_topics(H1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbMNkPv7_J_i"
      },
      "source": [
        "### LDA: Latent Dirichlet Allocation\n",
        "\n",
        "LDA es un m√©todo Bayesiano basado en la distribuci√≥n de Dirichlet, la cual es una distribuci√≥n sobre probabilidades en K categorias. LDA supone que los documentos que tenemos pertenecen a K categorias distintas cuya distribuci√≥n es desconocida, sin embargo, asume que todos los fragmentos que componen el texto fueron generados a trav√©s de un mismo proceso generativo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bct-Ck5f6fs"
      },
      "source": [
        "La distribuci√≥n Dirichlet es una generalizaci√≥n de la distribuci√≥n Beta en un espacio multidimensional. As√≠ como la distribuci√≥n beta es la distribuci√≥n previa de la binomial, la distribuci√≥n de Dirichlet es la distribuci√≥n previa de la multinomial. \n",
        "\n",
        "$$ P(w\\mid d) = P(d)\\sum_c P(k\\mid d)P(w\\mid k) $$\n",
        "\n",
        "*¬øNotan alguna similitud con SVD?*\n",
        "\n",
        "[David Blei, Andrew Ng, Michael Jordan: Latent Dirichlet Allocation (https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cN1vPUB3_J_j"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1dC1tN6_J_k",
        "outputId": "728ba140-326f-43d1-a06d-a3b8f86af4a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=7)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "lda.fit(vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Interpretando los t√≥picos\n",
        "\n",
        "Podemos ver las 10 palabras m√°s relevantes de los 7 t√≥picos que encontr√≥ LDA de la siguiente forma:"
      ],
      "metadata": {
        "id": "7aICU5GKtNEp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF-MpBfDgk2O",
        "outputId": "722ace35-4822-4d3e-d580-f2e641d7ed0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic  0 mercadona movistar nuevo adidas marcar toyota comprar carrefour mejorar anunciar\n",
            "Topic  1 adir cruzcampo acabo nikeplus correr carrefour banco ritmar heineken milka\n",
            "Topic  2 bimbo cruzcampo gustar heineken adir color arruinaunacitacon4palabras mercadona mujer movistar\n",
            "Topic  3 milka heineken ganar mejor querer chocolate mercadona refugiar carrefour buscar\n",
            "Topic  4 cerveza heineken cruzcampo mercadona mundo peugeot taller necesito adidas mecanico\n",
            "Topic  5 adidas heineken galicia gracia bimbo estrella comprar favor hacer mercadona\n",
            "Topic  6 heineken suzuki toyota alianza alcampo carrefour adidas supermercado mercadona caixa\n"
          ]
        }
      ],
      "source": [
        "for idx, topic in enumerate(lda.components_):\n",
        "    print (\"Topic \", idx, \" \".join(vocab[i] for i in topic.argsort()[:-10 - 1:-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra alternativa es utilizando una librer√≠a especifica para estas visualizaciones. `pyLDAvis` es una librer√≠a de Python para la visualizaci√≥n de modelos de modelado de t√≥picos. Se trata de una portabilidad del fabuloso paquete de R de Carson Sievert y Kenny Shirley.\n",
        "\n",
        "`pyLDAvis` est√° dise√±ada para ayudar a los usuarios a interpretar los temas en un modelo de t√≥picos que se ha ajustado a un corpus de datos de texto. El paquete extrae informaci√≥n de un modelo LDA.\n",
        "\n",
        "La visualizaci√≥n est√° dise√±ada para usarse dentro de un notebook de Jupyter, pero tambi√©n se puede guardar en un archivo HTML independiente para compartirlo f√°cilmente."
      ],
      "metadata": {
        "id": "Cclo_eRivRwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "\n",
        "pyLDAvis.enable_notebook()"
      ],
      "metadata": {
        "id": "eaPP3P_6tNkL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.sklearn.prepare(lda, vectors, vectorizer, mds='tsne')"
      ],
      "metadata": {
        "id": "pgvdGqeluJSu",
        "outputId": "b3a27605-5775-4d15-a7fc-f872ef5d10d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=               x          y  topics  cluster       Freq\n",
              "topic                                                  \n",
              "1     -29.594002  60.112713       1        1  16.676527\n",
              "6     -45.996586  11.891685       2        1  14.643260\n",
              "0      20.368856  70.019325       3        1  14.177102\n",
              "3      53.928768  31.704309       4        1  13.797790\n",
              "4     -12.437127 -26.423267       5        1  13.769867\n",
              "2       3.965971  21.797720       6        1  13.593864\n",
              "5      37.524284 -16.517805       7        1  13.341589, topic_info=           Term       Freq      Total Category  logprob  loglift\n",
              "4161      milka  27.000000  27.000000  Default  30.0000  30.0000\n",
              "320        adir  36.000000  36.000000  Default  29.0000  29.0000\n",
              "4404   nikeplus  10.000000  10.000000  Default  28.0000  28.0000\n",
              "6043     suzuki   9.000000   9.000000  Default  27.0000  27.0000\n",
              "239       acabo  11.000000  11.000000  Default  26.0000  26.0000\n",
              "...         ...        ...        ...      ...      ...      ...\n",
              "320        adir   2.502521  36.243925   Topic7  -6.1051  -0.6587\n",
              "4471      nuevo   2.186228  17.230517   Topic7  -6.2403  -0.0502\n",
              "1922  cruzcampo   2.406396  37.537635   Topic7  -6.1443  -0.7329\n",
              "1272  carrefour   2.256442  29.798338   Topic7  -6.2086  -0.5664\n",
              "4283   movistar   2.238576  28.017037   Topic7  -6.2166  -0.5127\n",
              "\n",
              "[434 rows x 6 columns], token_table=      Topic      Freq        Term\n",
              "term                             \n",
              "32        1  0.274757          10\n",
              "32        3  0.274757          10\n",
              "32        4  0.549513          10\n",
              "59        1  0.708213      160mil\n",
              "135       6  0.526481          45\n",
              "...     ...       ...         ...\n",
              "6721      2  0.176610   zapatilla\n",
              "6721      3  0.353220   zapatilla\n",
              "6721      5  0.176610   zapatilla\n",
              "6721      7  0.176610   zapatilla\n",
              "6722      6  0.762942  zapatillas\n",
              "\n",
              "[703 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 7, 1, 4, 5, 3, 6])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el571401108779422248386181531\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el571401108779422248386181531_data = {\"mdsDat\": {\"x\": [-29.59400177001953, -45.996585845947266, 20.36885643005371, 53.928768157958984, -12.437127113342285, 3.9659712314605713, 37.52428436279297], \"y\": [60.11271286010742, 11.891684532165527, 70.01932525634766, 31.704309463500977, -26.423267364501953, 21.797719955444336, -16.517805099487305], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"Freq\": [16.676526957163006, 14.64326046529508, 14.177102495936817, 13.797790341195803, 13.769867155642727, 13.59386360122673, 13.341588983539845]}, \"tinfo\": {\"Term\": [\"milka\", \"adir\", \"nikeplus\", \"suzuki\", \"acabo\", \"correr\", \"adidas\", \"heineken\", \"galicia\", \"cerveza\", \"ritmar\", \"estrella\", \"ganar\", \"alianza\", \"gracia\", \"alcampo\", \"cruzcampo\", \"supermercado\", \"arruinaunacitacon4palabras\", \"taller\", \"color\", \"banco\", \"mecanico\", \"refugiar\", \"necesito\", \"ofrecer\", \"bimbo\", \"chocolate\", \"reparacion\", \"negociaci\\u00f3n\", \"nikeplus\", \"correr\", \"ritmar\", \"acabo\", \"ofrecer\", \"diciembre\", \"abrir\", \"vizcaya\", \"bilbao\", \"organizar\", \"mcflurry\", \"montar\", \"abril\", \"argentaria\", \"780\", \"negociar\", \"corrio\", \"asesor\", \"faltar\", \"conmigo\", \"forzar\", \"balance\", \"50\", \"mueble\", \"concha\", \"adelantar\", \"kcafavglobalmusicstar\", \"caracas\", \"160mil\", \"lunarlon\", \"carrera\", \"quien\", \"adir\", \"amigo\", \"encontrar\", \"leroy\", \"tomar\", \"banco\", \"ikea\", \"cruzcampo\", \"sabadell\", \"menos\", \"necesitar\", \"carrefour\", \"ahora\", \"bueno\", \"santander\", \"milka\", \"bankia\", \"heineken\", \"movistar\", \"decir\", \"toyota\", \"mercadona\", \"comprar\", \"poder\", \"querer\", \"mejor\", \"suzuki\", \"alianza\", \"negociaci\\u00f3n\", \"siglo\", \"supermercado\", \"forjar\", \"entrenamiento\", \"novio\", \"intercambiar\", \"asociacion\", \"iniciar\", \"lindo\", \"napaacc\", \"barato\", \"saldo\", \"encargar\", \"helar\", \"copiar\", \"training\", \"verdad\", \"comision\", \"bancopopular\", \"tecnologia\", \"atletismo\", \"extrane\", \"siguemeytesigo\", \"willem\", \"posible\", \"ibex\", \"liberbank\", \"desarrollar\", \"alcampo\", \"medalla\", \"caixa\", \"corona\", \"online\", \"heineken\", \"pillar\", \"gracias\", \"toyota\", \"siempre\", \"llegar\", \"venir\", \"carrefour\", \"pagar\", \"vestir\", \"mercadona\", \"adidas\", \"comprar\", \"bankia\", \"movistar\", \"peugeot\", \"jejeje\", \"aldub81stweeksary\", \"pasate\", \"dudar\", \"dieno\", \"marcos\", \"kenia\", \"asics\", \"imelda\", \"horas\", \"entrevista\", \"buenas\", \"direct\", \"beneficio\", \"arrasar\", \"haz\", \"anticapitalismo\", \"agotar\", \"lejos\", \"adicolor\", \"terelu\", \"europeo\", \"turquia\", \"incorporar\", \"superstar\", \"hostia\", \"traves\", \"telcel\", \"mejorar\", \"bonito\", \"sergio\", \"seriar\", \"empezar\", \"anunciar\", \"equipo\", \"nuevo\", \"marcar\", \"movistar\", \"panga\", \"mercadona\", \"video\", \"bolsa\", \"vender\", \"adidas\", \"zapatilla\", \"bueno\", \"toyota\", \"comprar\", \"alcampo\", \"bankia\", \"carrefour\", \"bimbo\", \"peugeot\", \"gustar\", \"adir\", \"galicia\", \"cruzcampo\", \"refugiar\", \"alfajor\", \"graduados\", \"programa\", \"potencial\", \"diseno\", \"zapar\", \"presionan\", \"ganar\", \"lado\", \"valle\", \"sed\\u00e1n\", \"frias\", \"visitar\", \"teatro\", \"doler\", \"directo\", \"puleva\", \"pbbpadaluckmayward\", \"borracho\", \"mano\", \"hermanar\", \"declarar\", \"enterate\", \"vivienda\", \"premiar\", \"relleno\", \"calor\", \"morir\", \"congelar\", \"cumplir\", \"chocolate\", \"buscar\", \"tengo\", \"milka\", \"fibra\", \"cargar\", \"quedar\", \"quiero\", \"querer\", \"decathlon\", \"momento\", \"heineken\", \"mejor\", \"mientras\", \"traer\", \"10\", \"cerveza\", \"mercadona\", \"medio\", \"chico\", \"carrefour\", \"poder\", \"bimbo\", \"nuevo\", \"movistar\", \"parecer\", \"vender\", \"vodafone\", \"adir\", \"cruzcampo\", \"taller\", \"mecanico\", \"necesito\", \"reparacion\", \"oreo\", \"yeezy\", \"sportage\", \"captar\", \"componente\", \"solucionar\", \"990\", \"osito\", \"hamburgo\", \"diamundialcontraelcancer\", \"asorbaex\", \"batallar\", \"rebook\", \"desvelar\", \"click\", \"podrir\", \"quejandote\", \"suede\", \"pabelloneuropa\", \"disfrutar\", \"buena\", \"500\", \"efecto\", \"chocotorta\", \"mego\", \"alexander\", \"limon\", \"shoes\", \"sucursal\", \"probar\", \"cerveza\", \"mundo\", \"viernes\", \"tiempo\", \"manana\", \"peugeot\", \"mahou\", \"tenis\", \"cruzcampo\", \"hombre\", \"comer\", \"heineken\", \"vender\", \"seguro\", \"mandar\", \"mercadona\", \"gala6ghvip5\", \"carrefour\", \"adidas\", \"milka\", \"bimbo\", \"banco\", \"santander\", \"poder\", \"bankia\", \"movistar\", \"mejor\", \"llevar\", \"arruinaunacitacon4palabras\", \"color\", \"nikes\", \"bombazo\", \"zapatillas\", \"90\", \"95\", \"presto\", \"mujer\", \"encantar\", \"extrano\", \"caminar\", \"sudaderilla\", \"hypervenom\", \"tortilla\", \"ciclo\", \"devolucion\", \"mallas\", \"calle\", \"sevilla\", \"negro\", \"chaval\", \"patata\", \"control\", \"roscar\", \"lossimsaniversario\", \"conocer\", \"banderazo\", \"crudo\", \"denominacion\", \"45\", \"grabar\", \"pantalon\", \"modelar\", \"gustar\", \"lorenzo\", \"bimbo\", \"clausular\", \"hacendar\", \"poner\", \"fundador\", \"camiseta\", \"soler\", \"cruzcampo\", \"hombre\", \"llevar\", \"cliente\", \"salir\", \"adir\", \"heineken\", \"mercadona\", \"movistar\", \"toyota\", \"adidas\", \"poder\", \"santander\", \"comprar\", \"estrellar\", \"conseguir\", \"espanola\", \"queja\", \"carrefourarg\", \"fallece\", \"corazon\", \"parra\", \"patta\", \"name\", \"galicia\", \"ordinario\", \"electrico\", \"estrella\", \"funcionar\", \"hipotecario\", \"empresas\", \"apostar\", \"coronar\", \"donitas\", \"panadero\", \"cabr\\u00f3n\", \"ropita\", \"barcelona\", \"liderar\", \"romeo\", \"nikefootball\", \"versiones\", \"disenadores\", \"videos\", \"gracia\", \"reclamar\", \"ayudar\", \"favor\", \"adidas\", \"emplear\", \"alguien\", \"mexicano\", \"servitje\", \"jajaja\", \"bimbo\", \"super\", \"hacer\", \"comprar\", \"pasar\", \"lorenzo\", \"heineken\", \"poder\", \"hyundai\", \"gustar\", \"mercadona\", \"mejor\", \"adir\", \"nuevo\", \"cruzcampo\", \"carrefour\", \"movistar\"], \"Freq\": [27.0, 36.0, 10.0, 9.0, 11.0, 9.0, 38.0, 58.0, 8.0, 14.0, 6.0, 7.0, 9.0, 5.0, 10.0, 8.0, 37.0, 5.0, 4.0, 4.0, 5.0, 17.0, 4.0, 4.0, 4.0, 5.0, 26.0, 8.0, 4.0, 4.0, 9.704622297798768, 9.245984770326235, 6.457952833733172, 10.201593286958294, 4.995802052258755, 2.738139821696373, 2.3773714174436544, 2.2909593217613904, 2.1113748009357125, 2.8605668832770434, 1.9770832873780357, 4.966415303307257, 2.3508890061806396, 1.6165738731699448, 1.6094895208704258, 1.4942730391292494, 1.9516627216355162, 1.2151475813623636, 2.6840995797412255, 1.5131442217784836, 1.1165690832042419, 1.0910143829919947, 1.0509719594525169, 4.878527660996187, 0.9913315601446124, 0.9646123616014614, 0.9589738588722259, 0.949314088110914, 0.938600087254185, 0.938600087254185, 2.213998136829044, 3.8752362845311925, 21.30315546303747, 3.875043867210952, 3.6708708134065886, 2.2439145510632996, 3.6046654527753312, 8.24898531488005, 2.1469690083093056, 14.10879574673095, 3.4033309993256893, 3.5562112317875094, 3.0678457492460676, 8.68678076629647, 4.138735697994478, 4.274127329386092, 4.504048133124643, 5.663703449239615, 4.455537904681029, 6.256404999634075, 4.722552547983132, 3.266402406259139, 4.11795899342092, 4.456462259483112, 3.9871851328854833, 3.339977376968217, 3.213695132674096, 3.2419431830111933, 8.669922230306879, 5.434278793779233, 3.848570539538896, 2.5726193841470466, 5.021815100112706, 2.3835552294795823, 1.9659029515362592, 3.3441953211158904, 1.7701124399277819, 2.574527090519553, 3.8104041194724765, 1.6980062253697679, 1.5830269236935612, 4.122027659726825, 1.260397789932275, 1.2506401851261615, 2.582432732401491, 1.6571393797286023, 1.1860571999786964, 2.9425394491697423, 1.1432375703163342, 1.1237517643518995, 3.4085762578299876, 1.0965803837383699, 1.0483323628740993, 1.6578405695148184, 1.0282903746065173, 2.274863434603449, 0.9782034630234258, 0.9782034630234258, 1.7730642130611018, 5.423088875251797, 2.9998512671846056, 4.6115174603777715, 2.5639492135903814, 3.046624438901102, 19.750054164743794, 1.9621878305673741, 4.177085212989334, 8.235178842264094, 4.202172534204084, 3.495167804367845, 2.9232211985676506, 5.266044603689819, 2.855105836200777, 2.5232459765471273, 4.866787027697155, 5.069608470139215, 3.50104376328842, 3.3781934772497033, 3.141819211723398, 2.5671228252717513, 3.0279847213689406, 3.0160215431399373, 3.013660186313018, 2.9554168698037344, 1.8357033511677399, 1.6641211209888378, 1.5201570915014853, 1.5005753428522555, 1.5005753428522555, 1.457706009270202, 1.425532871977904, 1.7506225126394774, 1.7784097560533483, 2.7493283008232985, 1.232353582980707, 2.2703239743052306, 1.160863777988326, 1.034914898987508, 1.028926378787164, 1.0260585210849342, 1.000304550562464, 1.662077308709179, 0.9841319156612394, 0.9761160122421396, 3.2613514589149353, 0.9228693662936064, 1.2455397835323834, 0.9165847737583492, 3.4585007751940875, 1.3962180734877718, 2.1342932160599495, 1.7680784931614737, 3.2560453149392234, 3.458140527635412, 1.4798898037093424, 6.672568462994712, 4.7834929403338835, 8.273315258473005, 2.8564058111760535, 8.414350464456838, 3.107947821441804, 2.430935552730436, 3.1670816457631172, 5.261453696487125, 2.296977630291809, 2.9873771355468546, 3.7203494023686443, 3.552437057403183, 2.5151704027250177, 3.1403290657636043, 3.526050126304568, 3.280633057665362, 2.6644700754789135, 2.6823842888467637, 2.845157548002789, 2.349411881551489, 2.4240649661829563, 4.059155349610162, 2.667227659216232, 1.2178151740659853, 1.2178151740659853, 1.2142930822322353, 3.34940245317836, 1.202976473151692, 1.1335907299692431, 6.74249166645815, 1.1286554086377252, 1.0910027078852993, 1.0796991184022016, 1.5538760139355137, 1.4874044541128169, 1.0242570083500406, 0.9754593538694654, 0.9551858217191901, 1.6466730336356978, 0.9262732503361519, 0.9182861926844936, 0.9151636651288689, 0.9059575455886157, 0.8662485370808429, 0.8598028969092045, 2.099028400812044, 1.7865211726704593, 0.8347735584542472, 1.1179208047198133, 1.3004008844618036, 1.182976783097573, 1.5323451985508667, 4.895377759425075, 3.9406889318964518, 2.9887866296715853, 14.877487032960065, 1.5130972608371418, 1.4773809556127602, 3.7088994067038263, 3.516372040798031, 4.966017258169544, 2.597340056233511, 2.1266584905483583, 11.825555178871143, 4.998582489551303, 1.9398310790694364, 1.9725122574869227, 1.7784959894567889, 3.6316327538759023, 4.719653109519013, 1.6508546921442735, 1.602482968161563, 4.024377776409047, 3.1817928451929505, 3.416612575227226, 2.9123412412165894, 3.270847683759955, 2.0178390779193482, 2.2222015997240647, 2.0196847578437516, 2.56697404671292, 2.4608609701804514, 4.349973834156089, 4.117519566477745, 4.175069104837882, 3.9151947221053174, 1.892424661316762, 1.828616415411145, 1.7441150195322217, 1.5595233648525268, 1.4209599243025208, 1.3895511083689118, 1.370486011418092, 2.8365113251862404, 1.3129564861706975, 1.225173929938121, 1.2251739299381208, 1.2200988839830333, 1.186240990637659, 1.1782882506694135, 2.6530078212197, 1.0730336852047522, 1.071231416708586, 1.0448987088430786, 1.0318553716578092, 1.4891103795393654, 1.434289653892623, 1.0166893162631747, 1.3020562453881612, 0.94031283891822, 1.3167423870715018, 0.9105465894903484, 1.359409642931476, 1.4319703428667525, 2.182795397374535, 3.028606678066153, 7.794500641496062, 4.5075881624747, 2.288707698560797, 2.1592868481327234, 3.235477224590266, 4.47782439641257, 2.284057711367675, 1.5324246899326772, 6.4085919805254825, 2.7670379166399175, 2.217035676404368, 7.4390079309031725, 3.074386830950877, 1.9651523696188664, 2.109665572371856, 4.517396259768318, 1.8747965623238456, 3.854108584111917, 4.137134867973451, 3.641014120039014, 3.5970270119141934, 3.0754543566811674, 2.7478427845173305, 2.874259974495847, 2.784451553651604, 2.9825746346599296, 2.5854849828248936, 2.1949799641083145, 4.318768797493625, 4.5996342868208675, 1.937206293075316, 1.4931329045698005, 2.9522671160323424, 1.354082326966716, 1.7613244477096042, 1.1804099292047934, 3.3905110580688493, 2.222304459465736, 2.1548622332408613, 1.6308681374117329, 1.0584438234709663, 1.0293652286975554, 0.9983588750958022, 0.9872021777654869, 1.824835689893432, 0.9757122559513685, 0.9739629891814536, 2.496682536241917, 2.9299328805757603, 0.9256562667460566, 0.9142631439635481, 0.9105381323080963, 0.9026686671610862, 0.8825557972467428, 2.948193051355066, 0.8766461285464276, 0.874958062241565, 0.8381659999645702, 1.2027697457503879, 1.1281867142227089, 1.3942153192292817, 1.9249996868199761, 6.576638999950273, 2.269007638442132, 8.34261781788723, 2.320568128616751, 2.386338615087177, 2.8937283615803127, 1.9093091964350168, 3.0864865482669015, 2.4208066562864885, 7.7678940926268965, 2.883736516423081, 3.0318478080367446, 3.149013597069185, 2.3428957390270226, 5.352688961498677, 6.049080227571885, 4.072975215916371, 3.387351948402172, 2.896478737597165, 3.180611854168608, 2.6940618916484027, 2.3863442774466304, 2.253366127028221, 2.9426544255141986, 2.2928223959953784, 1.7713125761428519, 1.5455119067481902, 1.3220898732979127, 1.3130452908664796, 1.8190397152767614, 1.2364410932930325, 1.2364410932930325, 1.1701885906754694, 6.185407405516887, 1.049278569770559, 1.5644709060616875, 5.182231808996532, 1.6554366341673923, 0.920222807204859, 1.2834558674348884, 0.9066110482154166, 2.0174498075281857, 0.8700128547198364, 0.8426339274446812, 1.2350711793929334, 0.7856106405391075, 1.4948978511098359, 1.4078344701248569, 0.77572513875391, 0.7558911109323501, 0.7387711120040777, 0.7271616142242011, 0.7234812438858345, 6.173534330149277, 2.44752278546054, 2.9003438014969505, 3.6841037532794463, 16.6249726744913, 2.789280792333727, 2.775457762808586, 1.3795717878524745, 2.0301772957424795, 2.2088795462670285, 5.816454334112201, 2.0663674573713884, 3.5265781563755976, 4.634239393763627, 2.4528073645285393, 2.015211470419729, 6.564589525976015, 3.0718841914938184, 2.196748577463965, 2.7286111900876078, 3.1595590480260607, 2.3577600702061936, 2.502520686935204, 2.186228093919284, 2.406396061645293, 2.2564417977089763, 2.2385757755895503], \"Total\": [27.0, 36.0, 10.0, 9.0, 11.0, 9.0, 38.0, 58.0, 8.0, 14.0, 6.0, 7.0, 9.0, 5.0, 10.0, 8.0, 37.0, 5.0, 4.0, 4.0, 5.0, 17.0, 4.0, 4.0, 4.0, 5.0, 26.0, 8.0, 4.0, 4.0, 10.178041692787088, 9.719441420987245, 6.931366040716911, 11.439152817017007, 5.7684465890576435, 3.2118455997343505, 2.850938457963621, 2.764506367008365, 2.5849379369515812, 3.505456791538819, 2.4507492515324723, 6.264484444754798, 2.996533400745106, 2.090201987082213, 2.082899048176934, 1.9683193731171087, 2.692588260524888, 1.6889618558802149, 3.7328444769354725, 2.1510681506050844, 1.590088932950769, 1.5644199359500868, 1.5243770063014137, 7.1358741727477755, 1.4647369008084203, 1.43801816668728, 1.4323797218848904, 1.4227200354063283, 1.4120053272341666, 1.4120053272341666, 3.40594973155125, 6.120755517940842, 36.243924779467115, 6.149817820637189, 6.307593750348298, 3.6748681202088327, 6.434159907792955, 17.163394819017736, 3.5315695348175544, 37.53763454545255, 6.778834510296248, 7.30702667960448, 5.943531234213311, 29.798338287192333, 10.639724606711443, 12.278122860621684, 14.59380072918852, 27.43493664441417, 19.409275635984745, 58.65986304811525, 28.01703706059114, 9.27058496677032, 23.825969910609345, 34.207183384866866, 21.582209910507302, 17.90119783518221, 14.322196552280428, 17.70150759732111, 9.14514596202544, 5.909504693703451, 4.3238448965036955, 3.047802403133793, 5.985428557224644, 2.8587277622486793, 2.4411289652843444, 4.199334514288659, 2.245470289475769, 3.267958810728549, 4.858231063179261, 2.173162963994122, 2.058252196179866, 5.562057127879805, 1.7355537158417556, 1.7258573096105796, 3.574121166515114, 2.3094379523987025, 1.6612134071943847, 4.152722904405481, 1.6187398477698889, 1.598926888485615, 4.882876878095432, 1.5717966281892852, 1.523626650309629, 2.4129563839987007, 1.5036024912783654, 3.3428229419141884, 1.4533592999126166, 1.4533592999126166, 2.6693906802238945, 8.593596325871127, 4.720040744138537, 7.76864512035364, 4.08066705096161, 5.282696915827106, 58.65986304811525, 3.2438449468236863, 8.997635207330516, 23.825969910609345, 10.772526273790117, 10.211879705471086, 7.416351901030474, 29.798338287192333, 7.6384235340473206, 5.985574173357314, 34.207183384866866, 38.30357323894616, 21.582209910507302, 19.409275635984745, 28.01703706059114, 12.952153235485637, 3.5035850278895473, 3.4916224978543027, 3.4892670772053878, 3.6173224237518333, 2.3113046509669233, 2.139721218470321, 1.9957676199280197, 1.9761754331243562, 1.9761754331243562, 1.9343572851101989, 1.9011343890979673, 2.3893850489957007, 2.4277773749596485, 3.800411024124397, 1.7079547259286134, 3.1741898184094275, 1.6364638970919991, 1.511134676740613, 1.5048923563548247, 1.5016717882713102, 1.4760982567057523, 2.462402821052726, 1.4597324151821243, 1.4517494305655123, 4.883770178511291, 1.3985658803323164, 1.8879448773378904, 1.3922311206769526, 5.332664026248391, 2.1574190331558865, 3.4210477408448328, 2.8446762839111255, 6.062448115566299, 6.815893819327179, 2.4049495407978827, 17.23051719632945, 11.134548173602926, 28.01703706059114, 6.541620103096023, 34.207183384866866, 8.595855473742688, 6.031581851901676, 10.438364433186194, 38.30357323894616, 5.662195502317227, 12.278122860621684, 23.825969910609345, 21.582209910507302, 8.593596325871127, 19.409275635984745, 29.798338287192333, 26.83735887796634, 12.952153235485637, 18.250271360609325, 36.243924779467115, 8.932643656110178, 37.53763454545255, 4.535433323377675, 3.3009224412107017, 1.6939784718146529, 1.6939784718146529, 1.6904775352846881, 4.668946854197836, 1.6791400814490196, 1.6098653858929413, 9.586931944059602, 1.6048550402576283, 1.5671660419210625, 1.5558735783327264, 2.2521705027224583, 2.1749135088496105, 1.5004282501904356, 1.4516226874468379, 1.4313837795413111, 2.477989584134376, 1.402437335543102, 1.3944501920210999, 1.3914286618509226, 1.3823474672553728, 1.34241251634441, 1.3363476240967196, 3.2676416298199915, 2.8003888965674233, 1.3109369969530582, 1.7556591297548485, 2.0527083113364046, 1.887476165120307, 2.449135695157066, 8.043364451317405, 6.552910764206861, 4.918992742783737, 27.43493664441417, 2.4219397322910714, 2.37273139640275, 7.536071969914638, 7.095874174511608, 14.322196552280428, 5.749913272458914, 4.377563667746494, 58.65986304811525, 17.70150759732111, 3.9623493875449185, 4.17330676245522, 3.63958606710629, 14.82706853848862, 34.207183384866866, 3.353028356853637, 3.1745679899195722, 29.798338287192333, 17.90119783518221, 26.83735887796634, 17.23051719632945, 28.01703706059114, 6.3999966660243315, 10.438364433186194, 7.349481280726577, 36.243924779467115, 37.53763454545255, 4.826187696184088, 4.593362226757463, 4.820175156944913, 4.586392246782216, 2.368442234870865, 2.3045772783920606, 2.2200160462448566, 2.0352850306301837, 1.9018332191505023, 1.8657704590514106, 1.8464504848728496, 3.8588039770571863, 1.7887718249420494, 1.701094032859336, 1.701094032859336, 1.6958608468363419, 1.6620042834309638, 1.6540625176721235, 3.753497020589779, 1.5487963364264825, 1.5469934673717243, 1.5207842470731965, 1.5076708176744666, 2.184071874808462, 2.1047169069230405, 1.4925577493480697, 1.936282237081874, 1.4160746046622184, 1.9995031121336262, 1.3863085647446358, 2.0765198301299224, 2.227406084133196, 3.5287723640890256, 5.068052765850048, 14.82706853848862, 8.275954572130065, 4.254580233551073, 3.977840756027255, 7.780185615351777, 12.952153235485637, 4.91251708283429, 2.5324355588357763, 37.53763454545255, 7.817211434726885, 5.250598233921776, 58.65986304811525, 10.438364433186194, 4.27308404765279, 5.111702084165198, 34.207183384866866, 4.077122893720335, 29.798338287192333, 38.30357323894616, 27.43493664441417, 26.83735887796634, 17.163394819017736, 14.59380072918852, 17.90119783518221, 19.409275635984745, 28.01703706059114, 17.70150759732111, 8.825356471642184, 4.794971005531574, 5.505459136894391, 2.413357120537605, 1.9696602067280775, 3.9321467387620714, 1.8307671526476086, 2.407991068302012, 1.6565619413195831, 4.7899794784959875, 3.151107545006118, 3.0923966766723785, 2.356241264574829, 1.534595178047323, 1.505516096410493, 1.4745096965029434, 1.4633528368476016, 2.71045614897258, 1.4518771581174406, 1.4502724781343421, 3.7331103880707577, 4.436887921732333, 1.4019368752213568, 1.3904139303733754, 1.3866889359842323, 1.3788203109661283, 1.3587071080827529, 4.54904509893224, 1.3527967500834353, 1.3511575051407274, 1.3143373358087542, 1.8994020906334272, 1.781449788988983, 2.392410891799275, 3.5672093833960874, 18.250271360609325, 4.682647728664156, 26.83735887796634, 4.880613447264795, 5.219727846826117, 7.414749781237941, 3.9656312646503533, 8.405026819758838, 5.864963224337089, 37.53763454545255, 7.817211434726885, 8.825356471642184, 9.59894989594705, 5.977965152612121, 36.243924779467115, 58.65986304811525, 34.207183384866866, 28.01703706059114, 23.825969910609345, 38.30357323894616, 17.90119783518221, 14.59380072918852, 21.582209910507302, 3.419637170711393, 2.7701774111846933, 2.248170379271334, 2.0223685612815094, 1.7989349934435774, 1.789897828309363, 2.49626239596133, 1.7132736997909803, 1.7132736997909803, 1.6470220076666262, 8.932643656110178, 1.526111368832198, 2.2966908635514183, 7.801907786886922, 2.5075988332816164, 1.3970551187586415, 1.95674639818002, 1.3834772814087093, 3.104551757698954, 1.346953111563197, 1.3194659367871038, 1.9360705050072173, 1.2624426976843932, 2.4032111367889475, 2.26806988366161, 1.252557056910101, 1.2329040188058884, 1.215603129176916, 1.2039939205246681, 1.2003132062697666, 10.747050551300994, 4.169130319618804, 5.224991978917741, 6.79216378914933, 38.30357323894616, 5.68345897163382, 5.669118736865933, 2.502137221089008, 4.332168176860382, 5.049905103600367, 26.83735887796634, 4.881139689211294, 12.72549652428327, 21.582209910507302, 6.837933013058443, 4.682647728664156, 58.65986304811525, 17.90119783518221, 7.644092647596382, 18.250271360609325, 34.207183384866866, 17.70150759732111, 36.243924779467115, 17.23051719632945, 37.53763454545255, 29.798338287192333, 28.01703706059114], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.9729, -5.0214, -5.3802, -4.923, -5.637, -6.2383, -6.3796, -6.4166, -6.4982, -6.1945, -6.5639, -5.6429, -6.3908, -6.7652, -6.7696, -6.8439, -6.5769, -7.0507, -6.2582, -6.8314, -7.1353, -7.1584, -7.1958, -5.6607, -7.2543, -7.2816, -7.2874, -7.2976, -7.3089, -7.3089, -6.4507, -5.8909, -4.1867, -5.891, -5.9451, -6.4373, -5.9633, -5.1355, -6.4815, -4.5988, -6.0208, -5.9769, -6.1246, -5.0837, -5.8252, -5.793, -5.7406, -5.5115, -5.7514, -5.4119, -5.6932, -6.0619, -5.8302, -5.7512, -5.8625, -6.0396, -6.0781, -6.0694, -4.9557, -5.4228, -5.7678, -6.1706, -5.5017, -6.2469, -6.4396, -5.9083, -6.5445, -6.1699, -5.7778, -6.5861, -6.6562, -5.6992, -6.8841, -6.8919, -6.1668, -6.6104, -6.9449, -6.0363, -6.9817, -6.9989, -5.8892, -7.0233, -7.0683, -6.61, -7.0876, -6.2936, -7.1376, -7.1376, -6.5428, -5.4249, -6.017, -5.587, -6.174, -6.0015, -4.1324, -6.4415, -5.6859, -5.0071, -5.6799, -5.8641, -6.0428, -5.4542, -6.0664, -6.19, -5.5331, -5.4923, -5.8625, -5.8982, -5.9707, -6.1727, -5.9753, -5.9792, -5.98, -5.9995, -6.4757, -6.5739, -6.6644, -6.6773, -6.6773, -6.7063, -6.7286, -6.5232, -6.5075, -6.0718, -6.8742, -6.2633, -6.934, -7.0489, -7.0547, -7.0574, -7.0829, -6.5751, -7.0992, -7.1073, -5.901, -7.1634, -6.8636, -7.1703, -5.8423, -6.7494, -6.325, -6.5133, -5.9027, -5.8424, -6.6912, -5.1852, -5.518, -4.9701, -6.0336, -4.9532, -5.9492, -6.1949, -5.9304, -5.4228, -6.2516, -5.9888, -5.7694, -5.8155, -6.1608, -5.9388, -5.823, -5.8951, -6.1032, -6.0965, -6.0376, -6.229, -6.1977, -5.6551, -6.075, -6.859, -6.859, -6.8619, -5.8473, -6.8713, -6.9307, -5.1476, -6.935, -6.969, -6.9794, -6.6153, -6.659, -7.0321, -7.0809, -7.1019, -6.5573, -7.1326, -7.1413, -7.1447, -7.1548, -7.1996, -7.2071, -6.3146, -6.4758, -7.2366, -6.9446, -6.7934, -6.888, -6.6293, -5.4678, -5.6847, -5.9612, -4.3562, -6.6419, -6.6658, -5.7453, -5.7986, -5.4534, -6.1016, -6.3015, -4.5858, -5.4469, -6.3935, -6.3767, -6.4803, -5.7664, -5.5043, -6.5548, -6.5845, -5.6637, -5.8986, -5.8274, -5.9871, -5.871, -6.354, -6.2576, -6.3531, -6.1133, -6.1555, -5.5839, -5.6388, -5.6249, -5.6892, -6.4162, -6.4505, -6.4978, -6.6096, -6.7027, -6.725, -6.7389, -6.0115, -6.7817, -6.8509, -6.8509, -6.8551, -6.8832, -6.89, -6.0783, -6.9835, -6.9852, -7.0101, -7.0227, -6.6559, -6.6934, -7.0375, -6.7901, -7.1156, -6.7789, -7.1477, -6.747, -6.695, -6.2734, -5.9459, -5.0006, -5.5483, -6.226, -6.2843, -5.8799, -5.5549, -6.2281, -6.6272, -5.1964, -6.0363, -6.2579, -5.0473, -5.9309, -6.3785, -6.3075, -5.5461, -6.4255, -5.7049, -5.634, -5.7618, -5.7739, -5.9306, -6.0432, -5.9982, -6.03, -5.9612, -6.1041, -6.2679, -5.5782, -5.5152, -6.3799, -6.6403, -5.9586, -6.738, -6.4751, -6.8753, -5.8202, -6.2426, -6.2734, -6.5521, -6.9844, -7.0122, -7.0428, -7.054, -6.4397, -7.0658, -7.0675, -6.1262, -5.9662, -7.1184, -7.1308, -7.1349, -7.1436, -7.1661, -5.96, -7.1728, -7.1747, -7.2177, -6.8565, -6.9206, -6.7088, -6.3862, -5.1576, -6.2218, -4.9198, -6.1994, -6.1714, -5.9786, -6.3944, -5.9141, -6.1571, -4.9912, -5.9821, -5.932, -5.8941, -6.1898, -5.3636, -5.2413, -5.6368, -5.8211, -5.9777, -5.8841, -6.0501, -6.1714, -6.2287, -5.9431, -6.1926, -6.4507, -6.5871, -6.7432, -6.7501, -6.4241, -6.8102, -6.8102, -6.8653, -5.2002, -6.9743, -6.5749, -5.3772, -6.5184, -7.1056, -6.7729, -7.1205, -6.3206, -7.1617, -7.1937, -6.8113, -7.2637, -6.6204, -6.6804, -7.2764, -7.3023, -7.3252, -7.341, -7.3461, -5.2022, -6.1274, -5.9576, -5.7184, -4.2115, -5.9966, -6.0016, -6.7007, -6.3143, -6.2299, -5.2617, -6.2966, -5.7621, -5.489, -6.1252, -6.3217, -5.1407, -5.9001, -6.2355, -6.0186, -5.872, -6.1647, -6.1051, -6.2403, -6.1443, -6.2086, -6.2166], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7435, 1.7412, 1.7204, 1.6767, 1.6474, 1.6316, 1.6095, 1.6033, 1.5888, 1.5879, 1.5764, 1.559, 1.5485, 1.5342, 1.5333, 1.5156, 1.4693, 1.4619, 1.4613, 1.4394, 1.4376, 1.4308, 1.4193, 1.4109, 1.4008, 1.3919, 1.3899, 1.3866, 1.3828, 1.3828, 1.3604, 1.3341, 1.2598, 1.3293, 1.2498, 1.2979, 1.2118, 1.0585, 1.2935, 0.8126, 1.1021, 1.071, 1.1298, 0.5585, 0.847, 0.7359, 0.6155, 0.2134, 0.3196, -0.447, 0.0107, 0.748, 0.0357, -0.2469, 0.1024, 0.1123, 0.2968, 0.0937, 1.8678, 1.8374, 1.8047, 1.7517, 1.7457, 1.7394, 1.7047, 1.6935, 1.6833, 1.6827, 1.6783, 1.6745, 1.6587, 1.6216, 1.6013, 1.5991, 1.5962, 1.5893, 1.5843, 1.5767, 1.5734, 1.5685, 1.5618, 1.5612, 1.5473, 1.5459, 1.5412, 1.5363, 1.5253, 1.5253, 1.512, 1.4608, 1.4679, 1.3997, 1.4565, 1.3708, 0.8326, 1.4185, 1.1538, 0.8588, 0.9798, 0.849, 0.9902, 0.188, 0.9371, 1.0574, -0.0288, -0.1011, 0.1024, 0.1728, -0.2668, 0.3027, 1.8077, 1.8071, 1.807, 1.7514, 1.7232, 1.7022, 1.6813, 1.6782, 1.6782, 1.6706, 1.6656, 1.6425, 1.6423, 1.6298, 1.6272, 1.6184, 1.6102, 1.575, 1.5733, 1.5727, 1.5644, 1.5605, 1.5593, 1.5566, 1.5498, 1.5378, 1.5376, 1.5355, 1.5205, 1.5184, 1.4817, 1.478, 1.3319, 1.275, 1.468, 1.0049, 1.1087, 0.7338, 1.1249, 0.551, 0.9362, 1.0448, 0.7609, -0.0316, 1.0513, 0.5401, 0.0966, 0.1493, 0.7249, 0.1321, -0.1807, -0.1482, 0.3723, 0.0361, -0.5911, 0.618, -0.7864, 1.8697, 1.7675, 1.6506, 1.6506, 1.6498, 1.6485, 1.6472, 1.6299, 1.6287, 1.6287, 1.6185, 1.6153, 1.6095, 1.6007, 1.5989, 1.5831, 1.5762, 1.572, 1.5659, 1.5629, 1.5617, 1.5581, 1.5426, 1.5397, 1.5381, 1.5312, 1.5293, 1.5293, 1.5242, 1.5135, 1.5117, 1.4841, 1.4721, 1.4824, 1.3687, 1.5103, 1.5069, 1.2717, 1.2786, 0.9215, 1.186, 1.2587, 0.3792, 0.7162, 1.2664, 1.2313, 1.2646, 0.5739, -0.0, 1.2721, 1.297, -0.0214, 0.2532, -0.0805, 0.2029, -0.1671, 0.8264, 0.4337, 0.689, -0.6669, -0.7442, 1.8788, 1.8733, 1.839, 1.8245, 1.7583, 1.7513, 1.7414, 1.7164, 1.6912, 1.688, 1.6846, 1.6749, 1.6734, 1.6545, 1.6545, 1.6534, 1.6455, 1.6435, 1.6357, 1.6157, 1.6152, 1.6074, 1.6035, 1.5997, 1.5992, 1.5987, 1.5859, 1.5733, 1.5649, 1.5623, 1.559, 1.5409, 1.5023, 1.4678, 1.3397, 1.3751, 1.3627, 1.3717, 1.1053, 0.9206, 1.2169, 1.4804, 0.215, 0.9441, 1.1205, -0.0823, 0.7603, 1.2059, 1.0977, -0.0418, 1.2058, -0.0626, -0.2429, -0.0369, -0.027, 0.2634, 0.3129, 0.1536, 0.041, -0.2573, 0.059, 0.5912, 1.891, 1.8158, 1.7758, 1.7186, 1.7089, 1.6939, 1.6828, 1.6567, 1.65, 1.6463, 1.6343, 1.6276, 1.6241, 1.6154, 1.6056, 1.6019, 1.5999, 1.5981, 1.5974, 1.5933, 1.5806, 1.5804, 1.5763, 1.5749, 1.5719, 1.5641, 1.5618, 1.5617, 1.561, 1.5457, 1.5386, 1.5387, 1.4556, 1.3787, 0.9749, 1.271, 0.8271, 1.2521, 1.2129, 1.0546, 1.2646, 0.9938, 1.1107, 0.4202, 0.9983, 0.9271, 0.881, 1.0589, 0.0829, -0.2763, -0.1325, -0.1172, -0.1117, -0.4929, 0.1017, 0.1847, -0.2639, 1.8641, 1.8252, 1.7759, 1.7454, 1.7063, 1.7045, 1.6978, 1.6881, 1.6881, 1.6725, 1.6468, 1.6397, 1.6304, 1.6052, 1.599, 1.5968, 1.5926, 1.5916, 1.5832, 1.5772, 1.5658, 1.5648, 1.5399, 1.5395, 1.5374, 1.5351, 1.5251, 1.5163, 1.51, 1.508, 1.4599, 1.4817, 1.4257, 1.4025, 1.1796, 1.3025, 1.3001, 1.4189, 1.2563, 1.1874, 0.4852, 1.1547, 0.731, 0.4759, 0.989, 1.1711, -0.1758, 0.2517, 0.7673, 0.1139, -0.3677, -0.0017, -0.6587, -0.0502, -0.7329, -0.5664, -0.5127]}, \"token.table\": {\"Topic\": [1, 3, 4, 1, 6, 1, 5, 1, 6, 6, 5, 1, 1, 1, 2, 1, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 3, 1, 2, 3, 4, 5, 6, 7, 2, 3, 3, 5, 4, 1, 5, 7, 2, 1, 2, 7, 3, 1, 3, 4, 5, 7, 7, 1, 3, 6, 1, 3, 2, 5, 2, 1, 2, 7, 1, 1, 2, 3, 5, 6, 2, 6, 1, 2, 3, 4, 5, 6, 7, 2, 7, 2, 7, 5, 3, 6, 1, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 6, 3, 4, 5, 3, 1, 2, 3, 4, 5, 6, 1, 3, 4, 5, 7, 1, 2, 3, 6, 4, 6, 1, 2, 3, 4, 6, 5, 1, 4, 1, 2, 3, 4, 5, 6, 7, 7, 1, 2, 3, 4, 5, 6, 6, 4, 2, 3, 4, 5, 5, 6, 2, 3, 5, 6, 1, 5, 1, 2, 5, 6, 7, 6, 1, 5, 6, 2, 5, 1, 2, 3, 4, 5, 6, 7, 1, 4, 1, 1, 6, 7, 6, 2, 7, 2, 5, 7, 1, 1, 6, 1, 2, 3, 4, 5, 6, 7, 4, 2, 3, 4, 1, 2, 3, 5, 6, 7, 4, 6, 2, 5, 6, 5, 1, 3, 3, 4, 7, 2, 4, 5, 4, 7, 3, 5, 7, 3, 5, 1, 4, 7, 7, 6, 7, 2, 1, 3, 6, 4, 2, 3, 3, 7, 3, 7, 7, 3, 2, 4, 6, 7, 1, 5, 6, 7, 2, 4, 2, 1, 4, 7, 6, 7, 1, 3, 5, 3, 7, 1, 4, 6, 7, 6, 1, 3, 5, 7, 1, 2, 3, 4, 7, 4, 1, 2, 3, 4, 5, 6, 7, 1, 3, 6, 7, 1, 2, 3, 4, 5, 6, 7, 5, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 4, 7, 1, 2, 5, 6, 3, 3, 6, 2, 3, 4, 5, 6, 7, 2, 1, 5, 3, 3, 2, 6, 2, 3, 6, 7, 3, 1, 3, 4, 3, 1, 6, 2, 7, 5, 2, 1, 2, 3, 4, 5, 6, 7, 2, 3, 5, 6, 6, 7, 6, 1, 3, 5, 6, 6, 1, 2, 3, 4, 5, 6, 7, 2, 3, 5, 6, 4, 1, 3, 4, 5, 7, 3, 1, 5, 2, 4, 6, 3, 4, 5, 1, 2, 3, 4, 5, 7, 3, 5, 1, 3, 6, 1, 2, 3, 4, 5, 6, 7, 3, 7, 1, 4, 7, 1, 2, 4, 5, 7, 4, 6, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 6, 1, 3, 4, 5, 7, 2, 1, 5, 7, 5, 2, 1, 1, 6, 7, 1, 6, 2, 1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 7, 5, 1, 5, 7, 5, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 7, 1, 2, 3, 4, 5, 7, 3, 6, 7, 4, 1, 2, 3, 4, 5, 6, 7, 2, 6, 1, 2, 3, 4, 5, 6, 7, 5, 1, 2, 5, 6, 7, 2, 4, 4, 6, 4, 6, 1, 5, 4, 4, 1, 2, 4, 5, 7, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 6, 1, 4, 5, 6, 5, 5, 6, 7, 4, 4, 5, 1, 7, 7, 6, 1, 2, 3, 5, 7, 2, 1, 2, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 4, 1, 2, 3, 5, 3, 3, 6, 7, 6, 5, 1, 2, 3, 4, 5, 6, 2, 2, 2, 3, 5, 6, 5, 5, 4, 5, 6, 5, 1, 2, 4, 7, 2, 2, 3, 6, 2, 5, 4, 2, 3, 3, 3, 4, 5, 5, 3, 1, 5, 1, 5, 6, 7, 6, 1, 2, 3, 4, 5, 6, 7, 1, 4, 2, 3, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 2, 7, 7, 1, 2, 5, 7, 1, 2, 3, 4, 6, 7, 7, 2, 5, 4, 4, 5, 1, 1, 2, 3, 4, 7, 2, 5, 4, 1, 2, 3, 5, 7, 6], \"Freq\": [0.27475651943987844, 0.27475651943987844, 0.5495130388797569, 0.7082126254854846, 0.5264814674740683, 0.6560056966657439, 0.6699908264432565, 0.9602001603248648, 0.5462191074128818, 0.8305678647762984, 0.5415796460249309, 0.6674379132575956, 0.7015233858918749, 0.8741906118365594, 0.08741906118365594, 0.695401506855557, 0.6659244768466862, 0.07832167461989348, 0.13053612436648912, 0.13053612436648912, 0.026107224873297825, 0.1044288994931913, 0.07832167461989348, 0.443822822846063, 0.5794074490491412, 0.055181661814203926, 0.0827724927213059, 0.0827724927213059, 0.13795415453550983, 0.0827724927213059, 0.6617543858876388, 0.3759495802623346, 0.1879747901311673, 0.09398739506558365, 0.09398739506558365, 0.09398739506558365, 0.09398739506558365, 0.09398739506558365, 0.5818285861237674, 0.3490971516742604, 0.8591994128356035, 0.721340129774214, 0.9088368640675089, 0.1763942592165271, 0.1763942592165271, 0.5291827776495813, 0.8460945983049097, 0.6504257714069254, 0.16260644285173134, 0.16260644285173134, 0.6110736703553331, 0.146715900585833, 0.44014770175749895, 0.146715900585833, 0.146715900585833, 0.146715900585833, 0.722816350827071, 0.9568453251696842, 0.5854956134485947, 0.8342073383521028, 0.5920796828646214, 1.0120558966963662, 0.9180042264153229, 0.5878569794987285, 0.6362146234859933, 0.19138785361487412, 0.19138785361487412, 0.5741635608446224, 0.6392145593521158, 0.4661082544774695, 0.11652706361936738, 0.11652706361936738, 0.17479059542905107, 0.11652706361936738, 0.6254194655186054, 0.7392093453346364, 0.2060870315316668, 0.15456527364875008, 0.15456527364875008, 0.1030435157658334, 0.15456527364875008, 0.1030435157658334, 0.1030435157658334, 0.7191583811590149, 0.17978959528975372, 0.41610992254977264, 0.41610992254977264, 0.5896710227525551, 0.7893883006223493, 0.2631294335407831, 0.7737129667254607, 0.03726149076543471, 0.03726149076543471, 0.11178447229630413, 0.11178447229630413, 0.14904596306173884, 0.2980919261234777, 0.22356894459260826, 0.1657939864788063, 0.3315879729576126, 0.1657939864788063, 0.1657939864788063, 0.1657939864788063, 0.5077017835787833, 0.4635168155243321, 0.7171285182661216, 0.47512327986281777, 0.8370354543068034, 0.3257826986589924, 0.0814456746647481, 0.2443370239942443, 0.0814456746647481, 0.0814456746647481, 0.1628913493294962, 0.15260393983421444, 0.15260393983421444, 0.6104157593368578, 0.15260393983421444, 0.5165101154186904, 0.12872257446540158, 0.6436128723270078, 0.12872257446540158, 0.6895255995524502, 0.5695866487133154, 0.8488095128751126, 0.2379528397575518, 0.1189764198787759, 0.1189764198787759, 0.1189764198787759, 0.3569292596363277, 0.9826633468535567, 0.7028789748605743, 0.42145520623028787, 0.30203026468319216, 0.16779459149066234, 0.13423567319252985, 0.13423567319252985, 0.13423567319252985, 0.06711783659626493, 0.06711783659626493, 0.5558844558834051, 0.5872077269587576, 0.13488843022532274, 0.06744421511266137, 0.2697768604506455, 0.539553720901291, 0.06744421511266137, 0.7132988779128208, 0.6300069824778489, 0.12432608345083905, 0.12432608345083905, 0.6216304172541953, 0.12432608345083905, 0.7061774829572159, 0.6833621904572447, 0.2048922765150398, 0.2048922765150398, 0.2048922765150398, 0.4097845530300796, 0.2664182213318694, 0.7992546639956081, 0.10417806227139789, 0.20835612454279578, 0.10417806227139789, 0.31253418681419365, 0.10417806227139789, 0.9081894671586794, 0.19045448831705414, 0.3809089766341083, 0.19045448831705414, 0.6177644921620256, 0.5258084620304787, 0.18533783225102446, 0.18533783225102446, 0.18533783225102446, 0.09266891612551223, 0.09266891612551223, 0.09266891612551223, 0.2316722903137806, 0.6827164656315261, 0.5298080147869101, 0.9297706348529265, 0.21982635437813572, 0.6594790631344072, 0.7219754200308349, 0.7211422648946344, 0.8660115756401664, 0.8011978240892358, 0.7351739219432395, 0.24505797398107984, 0.6442153831193876, 0.9259791391474668, 0.7427797369992707, 0.7401061654139625, 0.37295903616537324, 0.05327986230933903, 0.05327986230933903, 0.05327986230933903, 0.15983958692801709, 0.21311944923735612, 0.05327986230933903, 0.8166146138634991, 0.1739156666570653, 0.1739156666570653, 0.5217469999711959, 0.3236041750065679, 0.10786805833552263, 0.10786805833552263, 0.10786805833552263, 0.10786805833552263, 0.21573611667104525, 0.7449275001719661, 0.7608396815302121, 0.7492346529928884, 0.6045720698679329, 0.7378831790944547, 0.5878569794987285, 0.9340424085915363, 0.8653121513701405, 0.8237987636874001, 0.6986246555905862, 0.8305689779265887, 0.2141810629309055, 0.6425431887927165, 0.4578603898224264, 0.6888842456429454, 0.7424163405654537, 0.8293427150152803, 0.5164536351410612, 0.8708181112835363, 0.49484959587481225, 0.32989973058320815, 0.175949189567657, 0.175949189567657, 0.527847568702971, 0.5110524291395683, 0.634697474279989, 0.3173487371399945, 0.5794221772746896, 0.6341562501198059, 0.15853906252995148, 0.15853906252995148, 0.7483082859341574, 0.8192930518798045, 0.5260017417676984, 0.4158091398741917, 0.8896122902607722, 0.2563475568580169, 0.6408688921450423, 0.8772860541154736, 0.8122147939811735, 0.6563287664972135, 0.3233737791608499, 0.6467475583216998, 0.5586911074944115, 0.8036766649498587, 0.14722848727492815, 0.14722848727492815, 0.5889139490997126, 0.4128921899530648, 0.8257843799061296, 0.6996119135271549, 0.6288956417955027, 0.8880322327205552, 0.7975757419629449, 0.5043333246406454, 0.2521666623203227, 0.24527099772739733, 0.24527099772739733, 0.49054199545479465, 0.22389788253021198, 0.671693647590636, 0.10430865743441883, 0.7301606020409318, 0.10430865743441883, 0.10430865743441883, 0.5613405475590333, 0.1860975707197998, 0.0930487853598999, 0.0930487853598999, 0.5582927121593994, 0.11114031375547256, 0.44456125502189026, 0.11114031375547256, 0.11114031375547256, 0.11114031375547256, 0.590326274293653, 0.16438111744875658, 0.054793705816252196, 0.16438111744875658, 0.054793705816252196, 0.10958741163250439, 0.38355594071376536, 0.16438111744875658, 0.1915808696056932, 0.1915808696056932, 0.3831617392113864, 0.1915808696056932, 0.23574718631019914, 0.1571647908734661, 0.07858239543673305, 0.1571647908734661, 0.07858239543673305, 0.07858239543673305, 0.3143295817469322, 0.5590427946462075, 0.6300820412190066, 0.10228458929538502, 0.3409486309846167, 0.017047431549230836, 0.20456917859077003, 0.11933202084461585, 0.10228458929538502, 0.11933202084461585, 0.2797890595788147, 0.8393671787364442, 0.7234071199084864, 0.7157913718454815, 0.12792285437715523, 0.12792285437715523, 0.3837685631314657, 0.3837685631314657, 0.5169675776535929, 0.7150181582882514, 0.6642240507319961, 0.13081997381526259, 0.13081997381526259, 0.13081997381526259, 0.13081997381526259, 0.26163994763052517, 0.26163994763052517, 0.6880611009680299, 0.5663204363618236, 0.2831602181809118, 1.0120558966963662, 0.6888241034890308, 0.8233449475707669, 0.20583623689269173, 0.8906820140857543, 0.1980235231127497, 0.1980235231127497, 0.3960470462254994, 0.8562657895039323, 0.6981388976130468, 1.0021206777932057, 0.623109237230217, 0.6644993549055008, 0.5442372173851903, 0.27211860869259513, 0.6880611009680299, 0.4409035220667818, 0.4815749820879065, 0.9203175432017024, 0.19585032899755822, 0.2937754934963373, 0.09792516449877911, 0.09792516449877911, 0.09792516449877911, 0.09792516449877911, 0.09792516449877911, 0.1133098706225885, 0.226619741245177, 0.226619741245177, 0.3399296118677655, 0.4271087888497969, 0.4271087888497969, 0.7359937944323277, 0.7082126254854846, 0.20356163309727307, 0.40712326619454614, 0.20356163309727307, 0.6887635048247733, 0.12853163786051722, 0.12853163786051722, 0.12853163786051722, 0.12853163786051722, 0.3855949135815517, 0.12853163786051722, 0.12853163786051722, 0.19562955421399758, 0.19562955421399758, 0.39125910842799516, 0.19562955421399758, 0.7186857849181921, 0.1796211187752972, 0.44905279693824307, 0.1796211187752972, 0.1796211187752972, 0.0898105593876486, 0.9347012044072698, 0.8160769604435806, 0.8708218081950989, 0.6355877337977377, 0.21186257793257923, 0.21186257793257923, 0.29823785950273457, 0.5964757190054691, 0.5001242528364569, 0.16947709021428267, 0.11298472680952178, 0.11298472680952178, 0.28246181702380446, 0.16947709021428267, 0.11298472680952178, 0.5625705998415477, 0.18752353328051588, 0.5474182831663774, 0.2737091415831887, 0.13685457079159435, 0.1169345033467323, 0.14616812918341537, 0.2338690066934646, 0.14616812918341537, 0.14616812918341537, 0.1169345033467323, 0.08770087751004922, 0.3996583367097544, 0.3996583367097544, 0.2523755232548038, 0.5047510465096076, 0.2523755232548038, 0.2186992475239274, 0.036449874587321233, 0.5467481188098184, 0.14579949834928493, 0.07289974917464247, 0.28033117558352316, 0.5606623511670463, 0.22843756845112556, 0.4568751369022511, 0.22843756845112556, 0.7981502778231749, 0.4871612758994265, 0.17846283992082151, 0.1070777039524929, 0.2855405438733144, 0.1070777039524929, 0.1070777039524929, 0.1070777039524929, 0.0713851359683286, 0.7006850007382732, 0.14013700014765465, 0.20876916164033157, 0.6263074849209948, 0.12083198273798887, 0.12083198273798887, 0.24166396547597774, 0.6041599136899444, 0.6071564285997143, 0.9716982222645103, 0.5047504390539442, 0.16825014635131474, 0.16825014635131474, 0.8298453624111141, 0.925102563978287, 0.5080476337619745, 0.22538320048651608, 0.6761496014595483, 0.8110931465439911, 0.98250727417306, 0.8287211134150239, 0.7143989100635345, 0.11607312637290144, 0.05803656318645072, 0.4062559423051551, 0.1741096895593522, 0.05803656318645072, 0.11607312637290144, 0.11607312637290144, 0.8667844839691616, 0.18929725023670624, 0.5678917507101188, 0.6552601732894594, 0.844436892128402, 0.8558085802800797, 0.7774429636324439, 0.25914765454414795, 0.6632747601644685, 0.13091706626931915, 0.39275119880795745, 0.13091706626931915, 0.13091706626931915, 0.13091706626931915, 0.13091706626931915, 0.7578823917463132, 0.152867330147576, 0.45860199044272804, 0.152867330147576, 0.152867330147576, 0.417988399663205, 0.15625008139593274, 0.15625008139593274, 0.15625008139593274, 0.3125001627918655, 0.15625008139593274, 0.15625008139593274, 0.15625008139593274, 0.5836779027904299, 0.14624302374566903, 0.14624302374566903, 0.14624302374566903, 0.14624302374566903, 0.14624302374566903, 0.29248604749133805, 0.8597794131605283, 0.7192102856244145, 0.5836779027904299, 0.713044336924148, 0.07720723973989528, 0.23162171921968586, 0.23162171921968586, 0.07720723973989528, 0.3088289589595811, 0.07720723973989528, 0.07720723973989528, 0.6165522806379397, 0.3082761403189698, 0.16758655077840293, 0.11172436718560196, 0.05586218359280098, 0.16758655077840293, 0.16758655077840293, 0.16758655077840293, 0.16758655077840293, 0.6456626842928147, 0.13486631774552527, 0.26973263549105053, 0.13486631774552527, 0.4045989532365758, 0.13486631774552527, 0.5982967194950347, 0.5915488251854191, 0.7141865197549884, 0.3570932598774942, 0.6211699492161773, 0.6036598904375532, 0.19731444130540207, 0.5919433239162063, 0.590326274293653, 0.8071058945546982, 0.1326951234001189, 0.1326951234001189, 0.5307804936004756, 0.2653902468002378, 0.988939423945883, 0.6464151407820469, 0.2094650767463689, 0.06982169224878963, 0.06982169224878963, 0.3491084612439482, 0.13964338449757926, 0.06982169224878963, 0.06982169224878963, 0.6535140945060469, 0.16337852362651173, 0.16337852362651173, 0.16337852362651173, 0.2818539267767745, 0.563707853553549, 0.14092696338838726, 0.14092696338838726, 0.6016831665052311, 0.2398581774463296, 0.2398581774463296, 0.4797163548926592, 0.881944395341938, 0.7628131651820395, 0.8721452036306696, 0.8656302328796677, 0.7983668244757431, 0.7921151604221144, 0.7252576655904553, 0.4425539516333309, 0.14751798387777698, 0.14751798387777698, 0.14751798387777698, 0.14751798387777698, 0.5761849897656398, 0.16728100189126088, 0.16728100189126088, 0.16728100189126088, 0.33456200378252177, 0.16728100189126088, 0.3426112287527461, 0.06852224575054922, 0.13704449150109843, 0.06852224575054922, 0.20556673725164765, 0.13704449150109843, 0.06852224575054922, 0.6427257419408071, 0.23402301214957405, 0.23402301214957405, 0.23402301214957405, 0.4680460242991481, 0.5846162203822671, 0.7030676957204474, 0.4616625944215869, 0.4616625944215869, 0.5357462791325558, 0.44895271101369644, 0.18565747245992434, 0.3713149449198487, 0.09282873622996217, 0.09282873622996217, 0.09282873622996217, 0.09282873622996217, 0.9843157800897323, 0.8288587449250292, 0.17050405292405377, 0.17050405292405377, 0.17050405292405377, 0.34100810584810753, 0.5359716116999821, 0.9008943892018202, 0.2833846722947107, 0.5667693445894214, 0.651637652916672, 0.6575554697680066, 0.2048701868152399, 0.2048701868152399, 0.2048701868152399, 0.4097403736304798, 0.8353620717709188, 0.20475983992859134, 0.614279519785774, 0.20475983992859134, 0.9841286336349198, 0.8288115282301747, 0.6664763875734006, 0.614391899467707, 0.204797299822569, 0.7182715464037064, 0.20329365223541354, 0.6098809567062407, 0.20329365223541354, 0.7897535607656093, 0.6774616767258614, 0.2513926678650452, 0.5027853357300904, 0.621681782442998, 0.1554204456107495, 0.1554204456107495, 0.1554204456107495, 0.6781915387682252, 0.16788403641099456, 0.3357680728219891, 0.16788403641099456, 0.08394201820549728, 0.04197100910274864, 0.1259130273082459, 0.08394201820549728, 0.23961813902500778, 0.47923627805001556, 0.6019696179125446, 0.5296764815559959, 0.6850570622392012, 0.6380944796214323, 0.09580044904551786, 0.09580044904551786, 0.2874013471365536, 0.19160089809103573, 0.2874013471365536, 0.13483718320607924, 0.4045115496182377, 0.13483718320607924, 0.13483718320607924, 0.13483718320607924, 0.13483718320607924, 0.7224175725323265, 0.2408058575107755, 0.8226369083774071, 0.16706834984205018, 0.5012050495261505, 0.16706834984205018, 0.33413669968410037, 0.11633513418817334, 0.11633513418817334, 0.34900540256452006, 0.11633513418817334, 0.11633513418817334, 0.11633513418817334, 0.8331158857342883, 0.23504081368923976, 0.4700816273784795, 0.4597883989092218, 0.6120622230260228, 0.3060311115130114, 0.7234564636450151, 0.4081920730742261, 0.13606402435807538, 0.13606402435807538, 0.27212804871615076, 0.13606402435807538, 0.665069395535384, 0.8678381145003005, 0.5955429276258158, 0.17660993859903898, 0.17660993859903898, 0.35321987719807796, 0.17660993859903898, 0.17660993859903898, 0.7629420261524796], \"Term\": [\"10\", \"10\", \"10\", \"160mil\", \"45\", \"50\", \"500\", \"780\", \"90\", \"95\", \"990\", \"abril\", \"abrir\", \"acabo\", \"acabo\", \"adelantar\", \"adicolor\", \"adidas\", \"adidas\", \"adidas\", \"adidas\", \"adidas\", \"adidas\", \"adidas\", \"adir\", \"adir\", \"adir\", \"adir\", \"adir\", \"adir\", \"agotar\", \"ahora\", \"ahora\", \"ahora\", \"ahora\", \"ahora\", \"ahora\", \"ahora\", \"alcampo\", \"alcampo\", \"aldub81stweeksary\", \"alexander\", \"alfajor\", \"alguien\", \"alguien\", \"alguien\", \"alianza\", \"amigo\", \"amigo\", \"amigo\", \"anticapitalismo\", \"anunciar\", \"anunciar\", \"anunciar\", \"anunciar\", \"anunciar\", \"apostar\", \"argentaria\", \"arrasar\", \"arruinaunacitacon4palabras\", \"asesor\", \"asics\", \"asociacion\", \"asorbaex\", \"atletismo\", \"ayudar\", \"ayudar\", \"ayudar\", \"balance\", \"banco\", \"banco\", \"banco\", \"banco\", \"banco\", \"bancopopular\", \"banderazo\", \"bankia\", \"bankia\", \"bankia\", \"bankia\", \"bankia\", \"bankia\", \"bankia\", \"barato\", \"barato\", \"barcelona\", \"barcelona\", \"batallar\", \"beneficio\", \"beneficio\", \"bilbao\", \"bimbo\", \"bimbo\", \"bimbo\", \"bimbo\", \"bimbo\", \"bimbo\", \"bimbo\", \"bolsa\", \"bolsa\", \"bolsa\", \"bolsa\", \"bolsa\", \"bombazo\", \"bonito\", \"borracho\", \"buena\", \"buenas\", \"bueno\", \"bueno\", \"bueno\", \"bueno\", \"bueno\", \"bueno\", \"buscar\", \"buscar\", \"buscar\", \"buscar\", \"cabr\\u00f3n\", \"caixa\", \"caixa\", \"caixa\", \"calle\", \"calor\", \"caminar\", \"camiseta\", \"camiseta\", \"camiseta\", \"camiseta\", \"camiseta\", \"captar\", \"caracas\", \"cargar\", \"carrefour\", \"carrefour\", \"carrefour\", \"carrefour\", \"carrefour\", \"carrefour\", \"carrefour\", \"carrefourarg\", \"carrera\", \"cerveza\", \"cerveza\", \"cerveza\", \"cerveza\", \"cerveza\", \"chaval\", \"chico\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocotorta\", \"ciclo\", \"clausular\", \"clausular\", \"clausular\", \"clausular\", \"click\", \"click\", \"cliente\", \"cliente\", \"cliente\", \"cliente\", \"cliente\", \"color\", \"comer\", \"comer\", \"comer\", \"comision\", \"componente\", \"comprar\", \"comprar\", \"comprar\", \"comprar\", \"comprar\", \"comprar\", \"comprar\", \"concha\", \"congelar\", \"conmigo\", \"conocer\", \"conocer\", \"conseguir\", \"control\", \"copiar\", \"corazon\", \"corona\", \"corona\", \"coronar\", \"correr\", \"corrio\", \"crudo\", \"cruzcampo\", \"cruzcampo\", \"cruzcampo\", \"cruzcampo\", \"cruzcampo\", \"cruzcampo\", \"cruzcampo\", \"cumplir\", \"decathlon\", \"decathlon\", \"decathlon\", \"decir\", \"decir\", \"decir\", \"decir\", \"decir\", \"decir\", \"declarar\", \"denominacion\", \"desarrollar\", \"desvelar\", \"devolucion\", \"diamundialcontraelcancer\", \"diciembre\", \"dieno\", \"direct\", \"directo\", \"disenadores\", \"diseno\", \"diseno\", \"disfrutar\", \"doler\", \"donitas\", \"dudar\", \"efecto\", \"electrico\", \"empezar\", \"empezar\", \"emplear\", \"emplear\", \"emplear\", \"empresas\", \"encantar\", \"encantar\", \"encargar\", \"encontrar\", \"encontrar\", \"encontrar\", \"enterate\", \"entrenamiento\", \"entrevista\", \"equipo\", \"espanola\", \"estrella\", \"estrella\", \"estrellar\", \"europeo\", \"extrane\", \"extrano\", \"extrano\", \"fallece\", \"faltar\", \"favor\", \"favor\", \"favor\", \"fibra\", \"fibra\", \"forjar\", \"forzar\", \"frias\", \"funcionar\", \"fundador\", \"fundador\", \"gala6ghvip5\", \"gala6ghvip5\", \"gala6ghvip5\", \"galicia\", \"galicia\", \"ganar\", \"ganar\", \"ganar\", \"ganar\", \"grabar\", \"gracia\", \"gracia\", \"gracia\", \"gracia\", \"gracias\", \"gracias\", \"gracias\", \"gracias\", \"gracias\", \"graduados\", \"gustar\", \"gustar\", \"gustar\", \"gustar\", \"gustar\", \"gustar\", \"gustar\", \"hacendar\", \"hacendar\", \"hacendar\", \"hacendar\", \"hacer\", \"hacer\", \"hacer\", \"hacer\", \"hacer\", \"hacer\", \"hacer\", \"hamburgo\", \"haz\", \"heineken\", \"heineken\", \"heineken\", \"heineken\", \"heineken\", \"heineken\", \"heineken\", \"helar\", \"helar\", \"hermanar\", \"hipotecario\", \"hombre\", \"hombre\", \"hombre\", \"hombre\", \"horas\", \"hostia\", \"hypervenom\", \"hyundai\", \"hyundai\", \"hyundai\", \"hyundai\", \"hyundai\", \"hyundai\", \"ibex\", \"ikea\", \"ikea\", \"imelda\", \"incorporar\", \"iniciar\", \"iniciar\", \"intercambiar\", \"jajaja\", \"jajaja\", \"jajaja\", \"jejeje\", \"kcafavglobalmusicstar\", \"kenia\", \"lado\", \"lejos\", \"leroy\", \"leroy\", \"liberbank\", \"liderar\", \"limon\", \"lindo\", \"llegar\", \"llegar\", \"llegar\", \"llegar\", \"llegar\", \"llegar\", \"llegar\", \"llevar\", \"llevar\", \"llevar\", \"llevar\", \"lorenzo\", \"lorenzo\", \"lossimsaniversario\", \"lunarlon\", \"mahou\", \"mahou\", \"mahou\", \"mallas\", \"manana\", \"manana\", \"manana\", \"manana\", \"manana\", \"manana\", \"manana\", \"mandar\", \"mandar\", \"mandar\", \"mandar\", \"mano\", \"marcar\", \"marcar\", \"marcar\", \"marcar\", \"marcar\", \"marcos\", \"mcflurry\", \"mecanico\", \"medalla\", \"medalla\", \"medalla\", \"medio\", \"medio\", \"mego\", \"mejor\", \"mejor\", \"mejor\", \"mejor\", \"mejor\", \"mejor\", \"mejorar\", \"mejorar\", \"menos\", \"menos\", \"menos\", \"mercadona\", \"mercadona\", \"mercadona\", \"mercadona\", \"mercadona\", \"mercadona\", \"mercadona\", \"mexicano\", \"mexicano\", \"mientras\", \"mientras\", \"mientras\", \"milka\", \"milka\", \"milka\", \"milka\", \"milka\", \"modelar\", \"modelar\", \"momento\", \"momento\", \"momento\", \"montar\", \"morir\", \"movistar\", \"movistar\", \"movistar\", \"movistar\", \"movistar\", \"movistar\", \"movistar\", \"mueble\", \"mueble\", \"mujer\", \"mujer\", \"mundo\", \"mundo\", \"mundo\", \"mundo\", \"name\", \"napaacc\", \"necesitar\", \"necesitar\", \"necesitar\", \"necesito\", \"negociaci\\u00f3n\", \"negociar\", \"negro\", \"negro\", \"nikefootball\", \"nikeplus\", \"nikes\", \"novio\", \"nuevo\", \"nuevo\", \"nuevo\", \"nuevo\", \"nuevo\", \"nuevo\", \"nuevo\", \"ofrecer\", \"online\", \"online\", \"ordinario\", \"oreo\", \"organizar\", \"osito\", \"osito\", \"pabelloneuropa\", \"pagar\", \"pagar\", \"pagar\", \"pagar\", \"pagar\", \"pagar\", \"panadero\", \"panga\", \"panga\", \"panga\", \"panga\", \"pantalon\", \"parecer\", \"parecer\", \"parecer\", \"parecer\", \"parecer\", \"parecer\", \"parecer\", \"parra\", \"pasar\", \"pasar\", \"pasar\", \"pasar\", \"pasar\", \"pasar\", \"pasate\", \"patata\", \"patta\", \"pbbpadaluckmayward\", \"peugeot\", \"peugeot\", \"peugeot\", \"peugeot\", \"peugeot\", \"peugeot\", \"peugeot\", \"pillar\", \"pillar\", \"poder\", \"poder\", \"poder\", \"poder\", \"poder\", \"poder\", \"poder\", \"podrir\", \"poner\", \"poner\", \"poner\", \"poner\", \"poner\", \"posible\", \"potencial\", \"premiar\", \"premiar\", \"presionan\", \"presto\", \"probar\", \"probar\", \"programa\", \"puleva\", \"quedar\", \"quedar\", \"quedar\", \"quedar\", \"queja\", \"quejandote\", \"querer\", \"querer\", \"querer\", \"querer\", \"querer\", \"querer\", \"querer\", \"quien\", \"quien\", \"quien\", \"quien\", \"quiero\", \"quiero\", \"quiero\", \"quiero\", \"rebook\", \"reclamar\", \"reclamar\", \"reclamar\", \"refugiar\", \"relleno\", \"reparacion\", \"ritmar\", \"romeo\", \"ropita\", \"roscar\", \"sabadell\", \"sabadell\", \"sabadell\", \"sabadell\", \"sabadell\", \"saldo\", \"salir\", \"salir\", \"salir\", \"salir\", \"salir\", \"santander\", \"santander\", \"santander\", \"santander\", \"santander\", \"santander\", \"santander\", \"sed\\u00e1n\", \"seguro\", \"seguro\", \"seguro\", \"seguro\", \"sergio\", \"seriar\", \"servitje\", \"servitje\", \"sevilla\", \"shoes\", \"siempre\", \"siempre\", \"siempre\", \"siempre\", \"siempre\", \"siempre\", \"siglo\", \"siguemeytesigo\", \"soler\", \"soler\", \"soler\", \"soler\", \"solucionar\", \"sportage\", \"sucursal\", \"sucursal\", \"sudaderilla\", \"suede\", \"super\", \"super\", \"super\", \"super\", \"supermercado\", \"superstar\", \"superstar\", \"superstar\", \"suzuki\", \"taller\", \"teatro\", \"tecnologia\", \"tecnologia\", \"telcel\", \"tengo\", \"tengo\", \"tengo\", \"tenis\", \"terelu\", \"tiempo\", \"tiempo\", \"tomar\", \"tomar\", \"tomar\", \"tomar\", \"tortilla\", \"toyota\", \"toyota\", \"toyota\", \"toyota\", \"toyota\", \"toyota\", \"toyota\", \"traer\", \"traer\", \"training\", \"traves\", \"turquia\", \"valle\", \"vender\", \"vender\", \"vender\", \"vender\", \"vender\", \"venir\", \"venir\", \"venir\", \"venir\", \"venir\", \"venir\", \"verdad\", \"verdad\", \"versiones\", \"vestir\", \"vestir\", \"vestir\", \"vestir\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"videos\", \"viernes\", \"viernes\", \"visitar\", \"vivienda\", \"vivienda\", \"vizcaya\", \"vodafone\", \"vodafone\", \"vodafone\", \"vodafone\", \"vodafone\", \"willem\", \"yeezy\", \"zapar\", \"zapatilla\", \"zapatilla\", \"zapatilla\", \"zapatilla\", \"zapatilla\", \"zapatillas\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 7, 1, 4, 5, 3, 6]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el571401108779422248386181531\", ldavis_el571401108779422248386181531_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el571401108779422248386181531\", ldavis_el571401108779422248386181531_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el571401108779422248386181531\", ldavis_el571401108779422248386181531_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para m√°s informaci√≥ns sobre la librer√≠a `pyLDAvis`, se recomienda la lectura [del papaer original](http://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf) el cual fu√© presentado en la conferencia [*ACL Workshop on Interactive Language Learning, Visualization, and Interfaces*](http://nlp.stanford.edu/events/illvi2014/) en Baltimore el June 27, 2014."
      ],
      "metadata": {
        "id": "XZ8bz63cwLrn"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Topic Modeling.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "bea38c2984299ac640e8421861d34b2e05ee614f6236d2975c05eeb77366835f"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}