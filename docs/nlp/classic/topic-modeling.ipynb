{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RcCek8lsFze"
      },
      "source": [
        "Técnicas de reducción de dimensionalidad\n",
        "==================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Irja1O_J9X"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "Topic modeling es una técnica de aprendizaje automático no supervisado donde intentados descubrir tópicos que son abstractos al texto pero que pueden describir una colección de documentos. Es importante marcar que estos \"tópicos\" no son necesariamente equivalentes a la interpretación coloquial de tópicos, sino que responden a un patrón que emerge de las palabras que están en los documentos.\n",
        "\n",
        "La suposición básica para Topic Modeling es que cada documento está representado por una mescla de tópicos, y cada tópico consiste en una colección de palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJKJtlkCsFzn"
      },
      "source": [
        "### Para ejecutar este notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjntkNZ5sFzn"
      },
      "source": [
        "Para ejecutar este notebook, instalaremos las siguientes librerias:\n",
        "\n",
        "```\n",
        "nltk\n",
        "pandas\n",
        "numpy\n",
        "matplotlib\n",
        "tqdm\n",
        "spacy==2.3.5\n",
        "unidecode\n",
        "scikit-learn\n",
        "importlib-metadata==4.13.0\n",
        "pyLDAvis\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9zClL8PJsFzo"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Datasets/mascorpus/tweets_marketing.csv \\\n",
        "    --quiet --no-clobber --directory-prefix ./Datasets/mascorpus/\n",
        "    \n",
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/docs/nlp/classic/topic-modeling.txt \\\n",
        "    --quiet --no-clobber\n",
        "!pip install -r topic-modeling.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KgoST-ebsFzq"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download es_core_news_sm 1> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deshabilitamos algunos mensajes de advertencias:"
      ],
      "metadata": {
        "id": "uVCSKx1cu6Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "ltgAo3Y2u9md"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPpqVNrwSdhL"
      },
      "source": [
        "Primero importaremos algunas librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zPfF_O0U_J9a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE_O7bEjLebd"
      },
      "source": [
        "## Sobre el set de datos con el que vamos a trabajar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8lcRTa_Li4e"
      },
      "source": [
        "Utilizaremos como ejemplo un set de datos en español que contiene tweets que diferentes usuarios han publicado en relación a diferentes marcas de productos u empresas en el rubro de alimentación, construcción, automoviles, etc. Estos tweets, a su vez, están asociados a una de las diferentes fases en el proceso de ventas (también conocido como Marketing Funel) y por eso están tagueados con las fases de:\n",
        " - Awareness – el cliente es conciente de la existencia de un producto o servicio\n",
        " - Interest – activamente expresa el interes de un producto o servicio\n",
        " - Evaluation – aspira una marca o producto en particular\n",
        " - Purchase – toma el siguiente paso necesario para comprar el producto o servicio\n",
        " - Postpurchase - realización del proceso de compra. El cliente compara la diferencia entre lo que deseaba y lo que obtuvo\n",
        "\n",
        "Referencia: [Spanish Corpus of Tweets for Marketing](http://ceur-ws.org/Vol-2111/paper1.pdf\n",
        "\n",
        "> Nota: La version de este conjunto de datos que utilizaremos aqui es una versión preprocesada del original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gc44Q7do_J9h"
      },
      "outputs": [],
      "source": [
        "tweets = pd.read_csv('Datasets/mascorpus/tweets_marketing.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INJwReUXSs4K"
      },
      "source": [
        "Inspeccionamos el set de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Gd6EocPdG5A0",
        "outputId": "3b03557b-ffd3-4135-aa3b-354c71bcb4e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               TEXTO  SECTOR      MARCA  \\\n",
              "0  #tablondeanuncios Funda nordica ikea #madrid h...  RETAIL       IKEA   \n",
              "1  #tr Me ofrezco para montar muebles de Ikea - H...  RETAIL       IKEA   \n",
              "2  #VozPópuli Vozpópuli @voz_populi - #LoMásLeido...  RETAIL    ALCAMPO   \n",
              "3  #ZonaTecno Destacado: Todo lo que hay que sabe...  RETAIL  CARREFOUR   \n",
              "4  $Carrefour retira pez #Panga. OCU y grupos x #...  RETAIL  CARREFOUR   \n",
              "\n",
              "       CANAL  AWARENESS  EVALUATION  PURCHASE  POSTPURCHASE  NC2  \n",
              "0  Microblog          0           0       0.0             0  1.0  \n",
              "1  Microblog          0           0       0.0             0  1.0  \n",
              "2  Microblog          0           0       0.0             0  1.0  \n",
              "3  Microblog          0           0       0.0             0  1.0  \n",
              "4  Microblog          0           0       0.0             0  1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-429bb74f-97ce-4923-bbfa-3d30516ea753\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXTO</th>\n",
              "      <th>SECTOR</th>\n",
              "      <th>MARCA</th>\n",
              "      <th>CANAL</th>\n",
              "      <th>AWARENESS</th>\n",
              "      <th>EVALUATION</th>\n",
              "      <th>PURCHASE</th>\n",
              "      <th>POSTPURCHASE</th>\n",
              "      <th>NC2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#tablondeanuncios Funda nordica ikea #madrid h...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>IKEA</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#tr Me ofrezco para montar muebles de Ikea - H...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>IKEA</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#VozPópuli Vozpópuli @voz_populi - #LoMásLeido...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>ALCAMPO</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#ZonaTecno Destacado: Todo lo que hay que sabe...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>CARREFOUR</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>$Carrefour retira pez #Panga. OCU y grupos x #...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>CARREFOUR</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-429bb74f-97ce-4923-bbfa-3d30516ea753')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-429bb74f-97ce-4923-bbfa-3d30516ea753 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-429bb74f-97ce-4923-bbfa-3d30516ea753');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tweets.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "uXwJS2Og_J9l",
        "outputId": "c61d78a3-82e8-4ab2-d32e-2575366de134"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  TEXTO        SECTOR\n",
              "0     #tablondeanuncios Funda nordica ikea #madrid h...        RETAIL\n",
              "725   \"Ilcinsisti lis MB dispiniblis\" te odeeeeeo Mo...         TELCO\n",
              "964   #CarlosSlim y Bimbo lanzarán un vehículo eléct...  ALIMENTACION\n",
              "1298  ‼🏎Toyota #Day, 4ruedas ,1/4 milla, 1 #pasión, ...    AUTOMOCION\n",
              "1748  \"- Tú qué.\\n- Yo na.\"\\nConversaciones banco sa...         BANCA\n",
              "2348  - Cariño, te juro que sólo tenían Cruzcampo en...       BEBIDAS\n",
              "3023  #adidas #hockey Amenabar 2080 CABA https://t.c...      DEPORTES"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cdcafa0-3c38-492c-9fa0-01437c6af8bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXTO</th>\n",
              "      <th>SECTOR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#tablondeanuncios Funda nordica ikea #madrid h...</td>\n",
              "      <td>RETAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>\"Ilcinsisti lis MB dispiniblis\" te odeeeeeo Mo...</td>\n",
              "      <td>TELCO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>#CarlosSlim y Bimbo lanzarán un vehículo eléct...</td>\n",
              "      <td>ALIMENTACION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>‼🏎Toyota #Day, 4ruedas ,1/4 milla, 1 #pasión, ...</td>\n",
              "      <td>AUTOMOCION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1748</th>\n",
              "      <td>\"- Tú qué.\\n- Yo na.\"\\nConversaciones banco sa...</td>\n",
              "      <td>BANCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2348</th>\n",
              "      <td>- Cariño, te juro que sólo tenían Cruzcampo en...</td>\n",
              "      <td>BEBIDAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3023</th>\n",
              "      <td>#adidas #hockey Amenabar 2080 CABA https://t.c...</td>\n",
              "      <td>DEPORTES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cdcafa0-3c38-492c-9fa0-01437c6af8bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6cdcafa0-3c38-492c-9fa0-01437c6af8bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6cdcafa0-3c38-492c-9fa0-01437c6af8bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "tweets.groupby('SECTOR').head(1)[['TEXTO', 'SECTOR']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9FcIehJ_J9q"
      },
      "source": [
        "## Preprosesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfUnlH25HEeM"
      },
      "source": [
        "Como en toda tarea de NLP, y más generalmente, en Machine Learning, ocuparemos una porción de nuestro tiempo en preprocesar los datos para generar representaciones útiles y deshacernos de problemas especificos que podría exhibir nuestro set de datos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZISG0Cs_J-g"
      },
      "source": [
        "### Creando una rutina de preprosesamiento de texto\n",
        "\n",
        "Realizaremos las tareas cotidianas de preprocesamiento. Adicionalmente nuestra rutina va a: \n",
        "\n",
        " - Eliminar caracteres especiales: Acentos y caracteres especiales podrían complejizar el la representación de palabras, por lo que los eliminaremos.\n",
        " - Eliminaremos URLs y handles que son típicos en tweeter. Esto es especifico en este set de datos ya que una URL no representa información en este contexto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0eJxv1LA_J-g"
      },
      "outputs": [],
      "source": [
        "import unidecode\n",
        "import spacy\n",
        "import es_core_news_sm as spa\n",
        "import re\n",
        "import nltk\n",
        "from nltk import stem\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize.casual import TweetTokenizer\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "parser = spa.load() # Cargamos el parser en español\n",
        "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True) # Creamos un tokenizer\n",
        "stemmer = stem.SnowballStemmer(language='spanish') # Creamos un steammer\n",
        "lemmatizer = lambda word : \" \".join([token.lemma_ for token in parser(word)]) # Creamos un lemmatizer\n",
        "stopwords = set(stopwords.words('spanish')) # Instanciamos las stopwords en español\n",
        "urls_regex = re.compile('http\\S+') # Usamos una expresion regular para encontrar las URLs\n",
        "\n",
        "def process_text(text):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token for token in tokens if not re.match(urls_regex, token)]\n",
        "    tokens = [token for token in tokens if len(token) > 4]\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    tokens = [unidecode.unidecode(token) for token in tokens] # Quitamos acentos\n",
        "    tokens = [lemmatizer(token) for token in tokens]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4uXheye_J-j",
        "outputId": "92baf020-1119-45a9-e01e-910ca1cf173d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3763/3763 [01:35<00:00, 39.51it/s]\n"
          ]
        }
      ],
      "source": [
        "doc_list = []\n",
        "\n",
        "for doc in tqdm(tweets['TEXTO']):\n",
        "    tokens = process_text(doc)\n",
        "    doc_list.append(' '.join(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtykSqbA_J-l"
      },
      "source": [
        "Revisemos algunos resultados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QQgWOejW_J-l",
        "outputId": "c465d9c3-9405-4448-ecd8-a44b567df7cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#VozPópuli Vozpópuli @voz_populi - #LoMásLeidoHoy Mercadona, DIA o Alcampo guardan silencio ante la ola europea... https://t.co/aJTuA4J9UV'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tweets['TEXTO'][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "huZ2Cu2Q_J-n",
        "outputId": "211d694b-e234-4a1b-f4fb-8b479c15885c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# VozPopuli Vozpopuli # LoMasLeidoHoy Mercadona Alcampo guardar silenciar europeo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "doc_list[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WSbMjTnRYXT",
        "outputId": "137eb172-2181-44e3-a6aa-e39fb2dd13ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3763"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(doc_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PXVzn24_J-p"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLwWu__sX4Rq"
      },
      "source": [
        "Una vez que nuesto texto fue preprocesado para mantener solo aquellas palabras que nos son relevantes, pasamos al proceso de generar vectores a partir de las palabras que componen nuestro vocabulario. Nuestros modelos no pueden operar sobre palabras, y por lo tanto necesitamos una representación númerica de las mismas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JUldeeN6_J-7"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=True, sublinear_tf=True, norm='l2')\n",
        "vectors = vectorizer.fit_transform(doc_list).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pTQYz9ABsFz7",
        "outputId": "435fbdcc-1f3d-40f9-80d8-8ceb7973ca9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3763, 6733)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "vectors.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5YtJxjQXgxH"
      },
      "source": [
        "## Reducción de dimensionalidad: Featurization\n",
        "Una vez que tenemos nuestros palabras representadas como vectores, nos aparece el problema de que ¡aún son demasiado grandes! En el ejemplo anterior, estamos trabajando con vectores en un espacio de 6K+. Necesitamos reducir esta dimensionalidad. Para esto, utilizaremos métodos de reducción de dimensionalidad con el objetivo de generar features que nos sean más utiles. Estas features las generaremos de forma \"no supervisada\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI4HLD1tkTBT"
      },
      "source": [
        "### Métodos básados en descomposición de matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8tC0kyK_J-6"
      },
      "source": [
        "Los modelos basados en factorización de matrices intentan reducir la dimensionalidad de la matriz al aproximarla usando dos matrices que representan embeddings de palabras y embeddings de documentos (más una matriz singular que los vincula los unos con los otros). Este método es bastante popular no solo en NLP sino que también en sistemas de recomendación, método que fué ganador del Netflix Prize (Funk SVD).\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/700/1*Z0EUVs7QElEqRqXtqut_FQ.png\" />\n",
        "\n",
        "\n",
        "U y V(trapuesta) son ortogonales. Esto es de esperar porque si determinadas propiedades determinan un determinado factor latente, entonces esas propiedades serán poco relevantes en los restantes factores (pues sino, no haría sentido que conformen un factor distinto en un primer lugar).\n",
        "\n",
        "SVC es un metodo de decomposición exacto, lo que singnifica que las matrices U y V son lo suficientemente grandes para mapear exactamente la matriz A. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh1u5cZzkKbO"
      },
      "source": [
        "### LSI - Latent Semantic Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1pbwdPv_J-7"
      },
      "source": [
        "LSI es un caso particular de factorización de matrices. Cuando SVD es utilizado para procesar tópicos en texto y en donde los valores de la matriz A corresponden a frecuencias de palabras, este método se lo denomina Latent Semantic Analysis (sin embargo, en NLP no se lo suele nombrar como LSI).\n",
        "\n",
        "Dado que SVC es un método de decomposición exacto, tiende a producir matrices de poca densidad (sparse). Para evitar este problema, se utiliza una versión modificada de SVC conocida como Truncated SVD que solamente computa los k componentes mas grandes en la descomposición. Esto ayuda a que LSI combata efectivamente el problema de matrices sparse que tienden a generarse cuando se tienen cuerpos de texto con sinónimos y palabras que significan varias cosas dependiendo del contexto. Truncated SVD evíta ser un método de decomposición exacto al aproximar la matriz A utilizando los k tópicos más relevantes.\n",
        "\n",
        "<img src='https://github.com/fastai/course-nlp/raw/aabfeddf61fea29b18c72f841d057b56a216b7eb/images/svd_fb.png' />\n",
        "\n",
        "Facebook Research: Fast Randomized SVD [https://research.fb.com/fast-randomized-svd/])\n",
        "\n",
        "En esta configuración entonces:\n",
        " - Un documento es nada mas que la distribución de palabras que ocurren en el (Bag of words)\n",
        " - A es una matriz de m x n donde m es la cantidad de documentos ú observaciones, y n es la cantidad de palabras en el vocabulario.\n",
        " - Los valores de A corresponden a la frecuencia de la cada palabra del vocabulario en cada observación ú documento.\n",
        " - A es una matriz sujeta a ruido con distribución Gausiana.\n",
        "\n",
        "\n",
        "Referencia: Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions [https://arxiv.org/abs/0909.4061]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1iGWgQZca0C"
      },
      "source": [
        "El principal parametro en LSI es el numero de factores que queremos generar (el parametro K). No existe una regla para especificar este parametro ya que depende del escenario. Valores muy pequeños pueden forzar a los documentos a ser colisionar en los tópicos que son asignados, mientras que valores muy grandes pueden hacer que palabras poco frecuentes y raras terminen determinando su propio \"topico\". \n",
        "\n",
        "> Valores típicos de este parámetro están en 50 < k < 300\n",
        "\n",
        "En la librería `scikit-learn`, este valor lo especificaremos en `n_components`. El parametro `algorithm` hace referencia al método que utilizaremos para generar la descomposición:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ2uzF82_J--",
        "outputId": "ae935012-881c-428b-86ab-ae45333707ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=7, algorithm='randomized')\n",
        "USigma = svd.fit_transform(vectors)\n",
        "Sigma = svd.singular_values_\n",
        "VT = svd.components_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bFhXZc6eHQL"
      },
      "source": [
        "Si bien en el codigo anterior estamos viendo las 3 matrices, solo nos interesa la matriz VT. ¿Porque? Recuerden que nuestro \"input\" es un conjunto de palabras que luego vectorizamos utilizando TF-IDF. Cada documento está representado por este conjunto de palabras. Nuestro objetivo es disponer una forma donde podamos convertir este set de palabras a \"tópicos\" que sean más informativos que las palabras propiamente dichas. **En consecuencia, lo único que nos interesa aqui es la matriz VT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvvt3kpu_J_A",
        "outputId": "06618569-3f8d-474b-9424-f9d3fb6281ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 6733)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "VT.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwu_KCg__J_C"
      },
      "source": [
        "Internamente, TrucatedSVC es un wrapper de la clase randomized_svd donde la matríz Q que vimos anteriormente se genera a través de un método de sampling aleatorio. Las siguientes lineas son equivalentes a lo que vimos anteriormente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kigl-Xl_J_D",
        "outputId": "4edce893-6ac1-4125-95c7-b016a41b27ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:376: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.extmath import randomized_svd\n",
        "\n",
        "U, Sigma, VT = randomized_svd(vectors, \n",
        "                              n_components=7,\n",
        "                              n_iter=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV9fOGLB_J_F"
      },
      "source": [
        "Podemos validar que U es una matriz ortogonal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLYEo9Gm_J_F",
        "outputId": "f96afd3d-242b-4ba7-d5a6-976a2fe35a82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "np.allclose(U.T @ U, np.eye(U.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSv1wUgK_J_I"
      },
      "source": [
        "Lo siguiente es solo a titulo informativo, pero si vemos los valores de la matriz Sigma, veremos la importancia relativa de los documentos con respecto a los tópicos que encontramos. Si los gráficamos vemos que sus valores comienzan a decrecer relativamente rápido, sosteniendo la supoción de que Truncated SVD genera los K más relevantes tópicos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "HVI80HRw_J_I",
        "outputId": "ad69eb56-6bf5-4fcd-dcdb-6973964c3bcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6e204a7d90>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dcnC/sSAgGBsIMgCoQQCbigVEvFatHWKoj7QrFoxfZ2+93b9l5trffaWncroLZVxLphWxfcW5cKkrAIggICSpAlEAhLCNk+vz/moDESM8AkJzN5Px8PHjNzvt8z8zkPH77n5HvOfL/m7oiISOJKCrsAERGpXwp6EZEEp6AXEUlwCnoRkQSnoBcRSXApYRdwMJ06dfLevXuHXYaISNzIz8/f5u4ZB2trlEHfu3dv8vLywi5DRCRumNnHtbVp6EZEJMEp6EVEEpyCXkQkwSnoRUQSXFQXY80sDZgFHAc4cIW7v1Ot/cfA5GrveQyQ4e5FZrYe2A1UAhXunhO78kVEpC7R3nVzBzDP3c8zs2ZAq+qN7n4rcCuAmZ0N3ODuRdW6jHX3bbEoWEREDk2dQW9m7YExwGUA7l4GlH3FLpOAObEoTkREjlw0Y/R9gELgITNbbGazzKz1wTqaWSvgDOCpapsdeMnM8s1sSm0fYmZTzCzPzPIKCwsP4RCCD3HnrldX8/6nxYe8r4hIIosm6FOAbOA+dx8O7AV+Vkvfs4G3awzbnOTu2cB4YJqZjTnYju4+w91z3D0nI+OgP+76SsX7ynls4QYumrWAlZt2HfL+IiKJKpqgLwAK3H1B8PpJIsF/MBOpMWzj7huDx63AXGDk4ZX61dJaNWPO1aNokZrM5FkL+HDz7vr4GBGRuFNn0Lv7ZmCDmQ0MNp0GrKjZLxjLPwX4W7Vtrc2s7YHnwDhgeQzqPqieHVsx5+pRNEtO4sKZ81m1RWEvIhLtffTXAbPN7D0gC7jZzKaa2dRqfc4FXnL3vdW2dQHeMrOlwLvAc+4+LxaF16Z3p9bMmTKK5CTjwpnzWa2wF5EmzhrjmrE5OTl+pJOafVS4h4kz5uMOj00ZRf/ObWJUnYhI42Nm+bX9TilhfxnbL6MNc64eBcCkmfP5qHBPyBWJiIQjYYMeoH/nNjw2JRd3Z9KM+azbtrfunUREEkxCBz1A/85tefTqUVRWRcJ+vcJeRJqYhA96gKO7tGX21bmUVVYxaeZ8Pt6usBeRpqNJBD3AoKPaMfuqXErLK5k0Yz6fbC8JuyQRkQbRZIIe4Jiu7XjkqlxKyiuZNHM+G4oU9iKS+JpU0AMc2609j1yZy579FUyaOZ+CHQp7EUlsTS7oAY7rHgn7XfvKmTRzPht37gu7JBGRetMkgx5gSGZ7Hr4yl50l5UyaMZ9NxQp7EUlMTTboAYb1SOPhK3PZsbeMSTPms7m4NOySRERirkkHPUBWjzT+fOVItu0pY9LM+WzZpbAXkcTS5IMeILtnB/58xfFs3VXKpJnz2aqwF5EEoqAPjOiVzp+vGMnm4iDsdyvsRSQxKOiryemdzp8uH8mm4lImz1xA4e79YZckInLEFPQ1jOyTzoOXHU/Bjn1MnjWfbXsU9iIS3xT0BzGqb0ceuCyHT4pKuGjWAor2loVdkojIYYsq6M0szcyeNLMPzGylmY2u0X6qmRWb2ZLg3y+rtZ1hZh+a2Rozq21R8UbnhH6deODS41m3bS8XzpzPDoW9iMSpaM/o7wDmufsgYBiw8iB93nT3rODfjQBmlgzcA4wHBgOTzGxwDOpuECf2/zzsJ89awM4Shb2IxJ86gz5Y9HsM8ACAu5e5+84o338ksMbd17p7GfAYMOFwiw3DSQM6MfOSHNYU7lHYi0hciuaMvg9QCDxkZovNbJaZtT5Iv9FmttTMXjCzY4Nt3YEN1foUBNu+xMymmFmemeUVFhYeyjHUuzFHZzDj4hGs3rKHix94l+KS8rBLEhGJWjRBnwJkA/e5+3BgL1BzrH0R0MvdhwF3Ac8caiHuPsPdc9w9JyMj41B3r3enDuzM/ReP4MPNu7nkwQUU71PYi0h8iCboC4ACd18QvH6SSPB/xt13ufue4PnzQKqZdQI2Aj2qdc0MtsWlsYM6c99F2azYtItLHnyXXaUKexFp/OoMenffDGwws4HBptOAFdX7mNlRZmbB85HB+24HFgIDzKyPmTUDJgJ/j2H9De60Y7pw7+QRrPi0mEsffJfdCnsRaeSivevmOmC2mb0HZAE3m9lUM5satJ8HLDezpcCdwESPqACuBV4kcqfO4+7+fmwPoeF9fXAX7r4wm2UFxVz20EL27K8IuyQRkVqZu4ddw5fk5OR4Xl5e2GXU6YVlm7h2zmKye6bxp8tH0rp5StgliUgTZWb57p5zsDb9MvYIjB/SlTsnDmfRJzu5/KGF7NWZvYg0Qgr6I/TNoV25/YIs8j4u4oo/LaSkTGEvIo2Lgj4Gzh7WjT9ckMXC9UVc+ac89pVVhl2SiMhnFPQxMiGrO7edn8WCddu56i8LKS1X2ItI46Cgj6Fzhnfnd98dxr8/2s7Vf8lT2ItIo6Cgj7FvZ2dy63nDeGvNNqY8nK+wF5HQKejrwXkjMvnfbw/ljVWFTH0kn/0VCnsRCY+Cvp6cf3wPbvn2EP75YSHXPLJIYS8ioVHQ16OJI3ty87lDeO2DrUybvYiyiqqwSxKRJkhBX88uzO3Jr885jldWbmXaowp7EWl4CvoGcNGoXtw44VheXrGF6+YsorxSYS8iDUdB30AuGd2b/z57MC++v4UfzFmssBeRBqOgb0CXndiHX5w1mBeWb2b6Y0uoUNiLSAPQdIsN7MqT+uDu/Pq5lZjB7RdkkZKs71sRqT8K+hBcdXJfqty5+fkPSDLjtvOHKexFpN4o6EMyZUw/Kqvgf+d9QJLB78/PIjnJwi5LRBJQVEFvZmnALOA4wIEr3P2dau2TgZ8CBuwGrnH3pUHb+mBbJVBR28T4TdE1p/ajyp1bX/yQJDNu/e4whb2IxFy0Z/R3APPc/bxg7ddWNdrXAae4+w4zGw/MAHKrtY91921HXm7imTa2P1VVzu9fXkVSkvF/3xlKksJeRGKozqA3s/bAGOAyAHcvA8qq93H3f1d7OR/IjF2Jie+60wZQ6c7tr6wmyeCWbyvsRSR2ojmj7wMUAg+Z2TAgH7je3ffW0v9K4IVqrx14ycwcuN/dZxxsJzObAkwB6NmzZ5TlJ47ppx9NlcOdr64myYybzx2isBeRmIjmVo8UIBu4z92HA3uBnx2so5mNJRL0P622+SR3zwbGA9PMbMzB9nX3Ge6e4+45GRkZh3IMCeOG0wdw7dj+PLZwA//5zHKqqhrfwu0iEn+iCfoCoMDdFwSvnyQS/F9gZkOJXLCd4O7bD2x3943B41ZgLjDySItOVGbGj8YdzfdP7cecdz/h4gcXsLm4NOyyRCTO1Rn07r4Z2GBmA4NNpwErqvcxs57A08DF7r6q2vbWZtb2wHNgHLA8RrUnJDPjx98YyC3fHsKij3fyjdvf4Pllm8IuS0TiWLS/0rkOmG1m7wFZwM1mNtXMpgbtvwQ6Avea2RIzywu2dwHeMrOlwLvAc+4+L4b1JyQzY+LInjx//cn07tiK789exH88sZQ9+yvCLk1E4pC5N75x4JycHM/Ly6u7YxNQXlnFna+u5p7X15DZoRV/uCCLEb06hF2WiDQyZpZf2++U9Lv7Ri41OYkfjRvI498bTZU759//Dn94eZUmRBORqCno40RO73ReuP5kJmR1445XV3PeH99h/bba7nAVEfmcgj6OtG2Rym3nZ3H3hcNZW7iHM+98k8cXbqAxDr+JSOOhoI9DZw3txrzpYxiWmcZPnnqPax5ZxI69ZXXvKCJNkoI+TnVLa8nsq3L5+fhBvPrBFs644w3eXF0Ydlki0ggp6ONYUpLxvVP6Mff7J9K2RSoXP/AuNz27gtLyyrBLE5FGREGfAI7r3p5/XHsSl47uxQNvreOce97mg827wi5LRBoJBX2CaNksmf+ZcBwPXX482/aU8a273+aBt9ZpvhwRUdAnmrEDOzNv+smMGdCJm55dwaUPvcuWXZovR6QpU9AnoE5tmjPzkhx+c+5xLFxfxBm3v8G85ZvDLktEQqKgT1BmxuTcXjz3g5PJ7NCKqY/k85Mnl7JX8+WINDkK+gTXL6MNT11zAtPG9uOJ/ALOvPNNFn+yI+yyRKQBKeibgGYpSfz4G4P465TRVFQ65/3xHe54ZbXmyxFpIhT0TcjIPum8MP1kzh7alT+8sooLZsznk+0lYZclIvVMQd/EtGuRyu0Th3PHxCxWbdnNmXe+yZP5BZovRySBKeibqAlZ3Zk3fQzHdmvHfzyxlGsfXczOEs2XI5KIogp6M0szsyfN7AMzW2lmo2u0m5ndaWZrzOw9M8uu1napma0O/l0a6wOQw9c9rSWPXj2Kn54xiBff38wZt7/Jv9dsC7ssEYmxaM/o7wDmufsgYBiwskb7eGBA8G8KcB+AmaUDvwJyiSwK/isz0/JIjUhyknHNqf14ZtqJtGqezIWzFvCb51awv0Lz5YgkijqD3szaA2OABwDcvczdd9boNgH4i0fMB9LMrCvwDeBldy9y9x3Ay8AZMT0CiYnjurfnuetO5qJRPZn55jrOueffrNqyO+yyRCQGojmj7wMUAg+Z2WIzm2VmrWv06Q5sqPa6INhW2/YvMbMpZpZnZnmFhZpuNwwtmyXz63OG8MClOWzdVcrZd73Fn95epwu1InEumqBPAbKB+9x9OLAX+FmsC3H3Ge6e4+45GRkZsX57OQSnHdOFedPHcGL/Tvz3P1Zw2UML2ar5ckTiVjRBXwAUuPuC4PWTRIK/uo1Aj2qvM4NttW2XRi6jbXMeuDSHm845jgXrtnPGHW/y0vuaL0ckHtUZ9O6+GdhgZgODTacBK2p0+ztwSXD3zSig2N03AS8C48ysQ3ARdlywTeKAmXHxqF48e91JdEtrwZSH8/n50+9RUqb5ckTiSUqU/a4DZptZM2AtcLmZTQVw9z8CzwNnAmuAEuDyoK3IzG4CFgbvc6O7F8WwfmkA/Tu35elrTuS2l1dx/xsfMX9tEbdfkMWwHmlhlyYiUbDGeKEtJyfH8/Lywi5DDuKdj7bzo8eXsHX3fqafPoBrTu1PcpKFXZZIk2dm+e6ec7A2/TJWDsnofh154foxjB/Sld+9tIqJM95hQ5HmyxFpzBT0csjat0rlrknDuf2CLD7YtJsz73iTuYs1X45IY6Wgl8N2zvDuPH/9yQzq2pYb/rqU6+YsprikPOyyRKQGBb0ckR7prXhsymh+/I2BzFu+mfF3vME7H20PuywRqUZBL0csOcmYNrY/T3//BFqkJnPhrPn89oWVlFVoYRORxkBBLzEzNDONZ39wEhOP78n9/1rLufe+zZqtmi9HJGwKeompVs1S+O23hzDzkhw2FZfyzTvf4u7XVvPGqkLWbdurs3yREET7gymRQ/L1wV0Y1uNkfvLke/zupVWfbTeDo9q1oEeHVmSmt4w8dmhJj/RW9EhvxVHtWui+fJEYU9BLvenctgUPXXY8m4pL2VBUwoYd+4LHEgqK9vHOR9uZu2sj1e/KTE02uqVFvgB6pLcks0PkC6BHh8jzTm2aYaYvApFDoaCXemUWCe5uaS3JPUj7/opKPt1Z+vkXwGdfBvt46f0tbN/7xeUNW6Ymf/4XQPCYGXwp9EhvRbsWqQ1zYCJxREEvoWqekkyfTq3p06nmEgcRe/dXVAv/EjYU7QseS3h3XRF79n9xgrX2LVMjXwTVwr/6XwctUpMb4rBEGhUFvTRqrZunMPCotgw8qu2X2tyd4n3lXwj/A18Gq7bu5rUPt37p4m9G2+af/SXwhesDHVrRNa0Fqcm6P0ESj4Je4paZkdaqGWmtmjEks/2X2quqnMI9+yk48JdAtS+C/I938Ox7m6is+vwCQXKSRS4Upx/4i6DVZ88zO7Sic9vmJOlCscQhBb0krKQko0u7FnRp14IRvb7cXlFZVe1C8RevD/xrVSFbd+//Qv9mKUlckNODGyccqwvCElcU9NJkpSQnfXZb58GUlldGwn9HCQVFJSxcv4OH53/MgC5tuGR074YtVuQIKOhFatEiNZn+ndvQv3MbACbn9mLv/gpuenYFQzPTyNLCKxInorryZGbrzWyZmS0xsy+tCGJmPw7alpjZcjOrNLP0aPYViRdJScbvzx9Gl3YtmDZ7ETtq3Pop0lgdyi0GY90962ArmLj7rUFbFvBz4F81lgysdV+ReJLWqhn3Ts6mcPd+bnh8CVVVmoNfGr/6uJdsEjCnHt5XpFEYmpnGL88ezD8/LOTef64JuxyROkUb9A68ZGb5Zjaltk5m1go4A3jqMPadYmZ5ZpZXWFgYZVki4Zic25Nzsrpx28ureHvNtrDLEflK0Qb9Se6eDYwHppnZmFr6nQ28XWPYJqp93X2Gu+e4e05GRka09YuEwsz4zblD6JfRhusfW8zm4tKwSxKpVVRB7+4bg8etwFxgZC1dJ1Jj2OYQ9hWJK62bp3DfRdmUlFVy7aOLKK/UFMzSONUZ9GbW2szaHngOjAOWH6Rfe+AU4G+Huq9IvOrfuS23fGcoeR/v4P/mfRB2OSIHFc199F2AucEvAVOAR919nplNBXD3Pwb9zgVecve9de0bq+JFGoNvDetG3voiZr65jhG9OnDGcV3DLknkC8y98d0elpOT43l5uuVe4sf+ikrO/+M7rC3cyz+uO4netczGKVJfzCy/tlvYNVWfSAw0T0nmnsnZJCUZ18xeRGl5ZdgliXxGQS8SI5kdWnH7BVms3LSLX/3t/bDLEfmMgl4khsYO6sy1Y/vz17wNPJ63IexyRAAFvUjM3fD1ozmhX0d+8cxyVny6K+xyRBT0IrGWnGTcMXE47Vum8v3Z+ewqLQ+7JGniFPQi9SCjbXPuvjCbDTv28dMn36Mx3t0mTYeCXqSejOyTzs/OGMQLyzfz4Nvrwy5HmjAFvUg9uurkPowb3IXfPr+S/I+L6t5BpB4o6EXqkZlx63eH0b1DS6bNXsz2Pfvr3kkkxhT0IvWsfctU7p2cTVFJGdP/uoRKLVYiDUxBL9IAju3WnpsmHMubq7dx56urwy5HmhgFvUgDOT+nB+eNyOTO11bzzw+3hl2ONCEKepEGYmbcNOE4BnZpyw1/XcLGnfvCLkmaCAW9SANq2SyZeydnU17pTJu9iLIKLVYi9U9BL9LA+ma04f/OG8qSDTu5+fmVYZcjTYCCXiQEZw7pyhUn9uFP/17Ps+99GnY5kuCiCnozW29my8xsiZl9aUUQMzvVzIqD9iVm9stqbWeY2YdmtsbMfhbL4kXi2c/GDyK7Zxo/ffI9PircE3Y5ksAO5Yx+rLtn1baCCfBm0J7l7jcCmFkycA8wHhgMTDKzwUdWskhiaJaSxN0XZtM8NZlrHsmnpKwi7JIkQdX30M1IYI27r3X3MuAxYEI9f6ZI3OiW1pLbL8hi9dY9/Nfc5Zr8TOpFtEHvwEtmlm9mU2rpM9rMlprZC2Z2bLCtO1B99YWCYNuXmNkUM8szs7zCwsIoyxKJf2OOzuD60wbw9OKNPLZQi5VI7EUb9Ce5ezaRIZhpZjamRvsioJe7DwPuAp451ELcfYa757h7TkZGxqHuLhLXrvvaAE4e0Ilf/f19lm8sDrscSTBRBb27bwwetwJziQzJVG/f5e57gufPA6lm1gnYCPSo1jUz2CYi1RxYrKRj62ZcMzuf4hItViKxU2fQm1lrM2t74DkwDlheo89RZmbB85HB+24HFgIDzKyPmTUDJgJ/j+0hiCSG9NbNuGdyNpt2lvKjJ5ZqvF5iJpoz+i7AW2a2FHgXeM7d55nZVDObGvQ5D1ge9LkTmOgRFcC1wIvASuBxd38/9ochkhiye3bgP795DK+s3MKMN9aGXY4kCGuMZw05OTmel/el2/VFmgR359pHFzPv/c08elUuuX07hl2SxAEzy6/t9nf9MlakkTEzbvnOEHqlt+LaOYvZurs07JIkzinoRRqhti1SufeibHaXlvODOYupqNTkZ3L4FPQijdSgo9rxm3OGMH9tEbe9vCrsciSOKehFGrHvjMhk0sge3PvPj3h15Zawy5E4paAXaeR+dfaxHNutHTf8dQkbikrCLkfikIJepJFrkRpZrMSB789exP6KyrBLkjijoBeJA706tub33x3Gso3F3PTsirDLkTijoBeJE+OOPYrvjenLI/M/4ZnFmklEoqegF4kj//GNgYzsnc7Pn17G6i27wy5H4oSCXiSOpCYncdeFw2ndPJmpj+Szd78WK5G6KehF4kyXdi24c9Jw1m3by8+eXqbJz6ROCnqROHRCv078aNxA/rH0Ux6Z/3HY5Ugjp6AXiVPXnNKPrw3qzI3PrmDJhp1hlyONmIJeJE4lJRm3nT+Mzm1bMG32InbsLQu7JGmkFPQicSytVTPuuyibwt37+eHjS6iq0ni9fFlUQW9m681smZktMbMvTRRvZpPN7L2gz7/NbFi0+4rIkRmamcYvzh7M6x8Wct+/Pgq7HGmEUg6h71h331ZL2zrgFHffYWbjgRlAbpT7isgRuii3J3nri/j9Sx+S1SONE/t3CrskaURiMnTj7v929x3By/lEFgEXkQZiZtx87hD6ZrTh+scWs7lYi5XI56INegdeMrN8M5tSR98rgRcOc18ROUytm6fwx4uyKSmr5Lo5iyjXYiUSiDboT3L3bGA8MM3Mxhysk5mNJRL0Pz2MfaeYWZ6Z5RUWFkZ/BCLymf6d2/Lbbw9h4fod3Prih2GXI41EVEHv7huDx63AXGBkzT5mNhSYBUxw9+2Hsm/QPsPdc9w9JyMj41CPQ0QCE7K6c/GoXsx4Yy3zlm8OuxxpBOoMejNrbWZtDzwHxgHLa/TpCTwNXOzuqw5lXxGJvf866xiGZrbnx08s5ePte8MuR0IWzRl9F+AtM1sKvAs85+7zzGyqmU0N+vwS6AjcW+M2yoPuG+NjEJEamqckc8+F2SQlGdc8sojSci1W0pRZY5wQKScnx/PydMu9yJF67YMtXPGnPCYe34NbvjM07HKkHplZvrvnHKxNv4wVSWBfG9SFaWP78djCDTyRtyHsciQkCnqRBHfD6Uczum9HfvG35azctCvsciQECnqRBJeSnMQdk7Jo1yKV789exO7S8rBLkgamoBdpAjq3bcFdk4bzSVEJP33qPS1W0sQo6EWaiNy+HfnJNwby/LLNPPT2+rDLkQZ0KJOaiUicmzKmL/kf7+Dm51eys6SMUf06MrxHB1o2Sw67NKlHur1SpIkp3lfO1IfzWbBuO1UOqcnGsMw0cvumM7JPR0b06kCb5joHjDdfdXulgl6kidpVWk7e+iIWrCtiwdoilm0sprLKSU4yjuvWjty+Hcntk05O73Tat0wNu1ypg4JeROq0d38Fiz7ZwYK1RSxYt52lG4opq6zCDI45qh25fdPJ7RM5609v3SzscqUGBb2IHLLS8koWf7KTd9dFgn/RJzsoLY9MfTygc5sg+CNn/Z3btQi5WlHQi8gRK6uoYtnGncxfGxnuyV9fxN6yyBw6fTq1Ds7208nt25HuaS1DrrbpUdCLSMxVVFbx/qe7Pjvjf3ddEbtKKwDontaS3L7pjOrTkZF90unVsRVmFnLFiU1BLyL1rrLK+XDzbhas286CtUW8u76Ior1lAHRp15zcIPRH9U2nX0YbBX+MKehFpMG5O2u27mH+uqLIWf/a7WzdvR+Ajq2bRYZ5gou7g45qS1KSgv9IfFXQ62ZZEakXZsaALm0Z0KUtF4/qhbvz8faSz874F6wr4oVgBaz2LVM5vnck+HP7pjO4aztSkvXD/VhR0ItIgzAzendqTe9Orbng+J4AFOwoiQzzBOP8r6zcAkCb5imM6NXhs1s6h3RPo1mKgv9wRTV0Y2brgd1AJVBR888Diwy23QGcCZQAl7n7oqDtUuC/gq6/dvc/1/V5GroRaZq27CoNfsAVubi7euseAFqkJjGiVwdG9u5Ibt90snqk0SJV0zZUd8Rj9EHQ57j7tlrazwSuIxL0ucAd7p5rZulAHpADOJAPjHD3HV/1eQp6EQHYtmc/C9cFv95dV8QHm3fhDs2Sk8jqEZm2YXS/jozu27HJX9xtiDH6CcBfPPKtMd/M0sysK3Aq8LK7FwWFvAycAcyJ0eeKSALr1KY544d0ZfyQrgAUl5SzcP3nt3Pe+8+PuOu1NQzu2o7rTx/AuMFdmnzgH0y0Qe/AS2bmwP3uPqNGe3eg+jplBcG22rZ/iZlNAaYA9OzZM8qyRKQpad8qldMHd+H0wV0A2LO/gnnLN3P3a6v53sP5DO7ajumnD+DrCvwviPbqxknung2MB6aZ2ZhYF+LuM9w9x91zMjIyYv32IpKA2jRP4bwRmbzyw1P4/XeHUVJWwZSH8znrrrd46f3NWmAlEFXQu/vG4HErMBcYWaPLRqBHtdeZwbbatouIxExKchLfCQL/d98dxp79nwf+yyu2NPnArzPozay1mbU98BwYByyv0e3vwCUWMQoodvdNwIvAODPrYGYdgn1fjOkRiIgEUpKTOG9EJq9WC/yr/5LH2Xe/xStNOPCjGaPvAswNxrtSgEfdfZ6ZTQVw9z8CzxO542YNkdsrLw/aiszsJmBh8F43HrgwKyJSXw4E/jlZ3Zi7eCN3vbaGq/6Sx3Hd2zH9tKM57ZjOTWoMX1MgiEjCK6+s4pkg8D8pKmFI9/ZMP30AXxuUOIGvuW5ERIgEfuQMfzUbivYlVOAr6EVEqimvrGLuoo3c9Xok8IdmRgJ/7MD4DXwFvYjIQdQM/GGZ7Zl++tGcOjAj7gJfQS8i8hXKK6t4elEBd722hoId8Rn4CnoRkSiUV1bxVH4k8Dfu3MewHmlMP30Apx7d+ANfQS8icgjKKj4/w9+4cx9ZQeCf0ogDX0EvInIYyiqqeGpRAXfHQeAr6EVEjkDNwB/eM43ppx/NmAGdGk3gK+hFRGKgrKKKJ/MLuOf1xhf4CnoRkRgqq6jiifwN3PPaGj4tLiU7CPyTQwx8Bb2ISD3YX1EZOcMPAn9Erw5MP30AJ/Vv+MBX0IbsFrcAAAWrSURBVIuI1KP9FZU8kVfAva+HF/gKehGRBnAg8O95fQ2bikvJ6dWB6acfzYn9639NWwW9iEgD2l9RyePBGf6m4lKO7x0J/BP61V/gK+hFREKwv6KSxxdu4J7XP2LzrvoNfAW9iEiIagb+yN7pTD99AKNjGPgxCXozSwbygI3uflaNtj8AY4OXrYDO7p4WtFUCy4K2T9z9W3V9loJeRBJRaXklj+dt4N56CPxYBf0PgRygXc2gr9HvOmC4u18RvN7j7m0OpWAFvYgksgOBf8/ra9iyaz8j+0QC/4R+nQ77Pb8q6OtcHDx4g0zgm8CsKLpPAuZEX56ISNPSIjWZS0b35l8/Hsv/fOtYPt6+lwtnLuCC+9+htLwy5p8XzeLgALcDPwHaflUnM+sF9AFeq7a5hZnlARXALe7+TC37TgGmAPTs2TPKskRE4leL1GQuPaE3Fxzfg78u3MDKTbtokZoc88+pM+jN7Cxgq7vnm9mpdXSfCDzp7tW/knq5+0Yz6wu8ZmbL3P2jmju6+wxgBkSGbqI+AhGROHcg8OtLNEM3JwLfMrP1wGPA18zskVr6TqTGsI27bwwe1wL/BIYfbrEiInLo6gx6d/+5u2e6e28iQf6au19Us5+ZDQI6AO9U29bBzJoHzzsR+dJYEaPaRUQkCtGO0X+Jmd0I5Ln734NNE4HH/Iu38RwD3G9mVUS+VG5xdwW9iEgD0g+mREQSwBHfXikiIvFLQS8ikuAU9CIiCU5BLyKS4BrlxVgzKwQ+PszdOwHbYlhOmBLlWBLlOEDH0hglynHAkR1LL3fPOFhDowz6I2FmebVdeY43iXIsiXIcoGNpjBLlOKD+jkVDNyIiCU5BLyKS4BIx6GeEXUAMJcqxJMpxgI6lMUqU44B6OpaEG6MXEZEvSsQzehERqUZBLyKS4BIm6M3sDDP70MzWmNnPwq7ncJnZg2a21cyWh13LkTKzHmb2upmtMLP3zez6sGs6XGbWwszeNbOlwbH8T9g1HQkzSzazxWb2bNi1HAkzW29my8xsSbCSXdwyszQze9LMPjCzlWY2OmbvnQhj9GaWDKwCvg4UAAuBSfE4JbKZjQH2AH9x9+PCrudImFlXoKu7LzKztkA+cE6c/ncxoLW77zGzVOAt4Hp3nx9yaYfFzH4I5ADt3P2ssOs5XMGCSDnuHvc/mDKzPwNvuvssM2sGtHL3nbF470Q5ox8JrHH3te5eRmQlrAkh13RY3P0NoCjsOmLB3Te5+6Lg+W5gJdA93KoOj0fsCV6mBv/i8izJzDKBbwKzwq5FIsysPTAGeADA3ctiFfKQOEHfHdhQ7XUBcRooicrMehNZRnJBuJUcvmC4YwmwFXjZ3eP1WG4HfgJUhV1IDDjwkpnlm9mUsIs5An2AQuChYEhtlpm1jtWbJ0rQSyNmZm2Ap4Dp7r4r7HoOl7tXunsWkAmMNLO4G1ozs7OAre6eH3YtMXKSu2cD44FpwdBnPEoBsoH73H04sBeI2bXGRAn6jUCPaq8zg20SsmA8+ylgtrs/HXY9sRD8Sf06cEbYtRyGE4FvBWPbjwFfM7NHwi3p8Ln7xuBxKzCXyDBuPCoACqr9lfgkkeCPiUQJ+oXAADPrE1zEmAj8vY59pJ4FFzAfAFa6+21h13MkzCzDzNKC5y2JXPj/INyqDp27/9zdM929N5H/T15z94tCLuuwmFnr4CI/wTDHOCAu71Zz983ABjMbGGw6DYjZTQuHvTh4Y+LuFWZ2LfAikAw86O7vh1zWYTGzOcCpQCczKwB+5e4PhFvVYTsRuBhYFoxtA/w/d38+xJoOV1fgz8EdXknA4+4e17cmJoAuwNzI+QQpwKPuPi/cko7IdcDs4GR1LXB5rN44IW6vFBGR2iXK0I2IiNRCQS8ikuAU9CIiCU5BLyKS4BT0IiIJTkEvIpLgFPQiIgnu/wNl9K9eSXB8FQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(Sigma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR8CpAYe_J_K"
      },
      "source": [
        "#### Interpretando los tópicos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra5f0S7FfKjG"
      },
      "source": [
        "La siguiente función solo toma la matriz de VT y obtiene las 8 palabras más importantes en este topico. Si quieren pueden variar este parametro para ver más palabras e inspeccionar los tópicos. Esto es importante porque LSI es un método no supervisado, por lo tanto no sabemos a priori cuando un tópico es bueno o malo. El sentido debemos darselo nosotros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fBNIN0xE_J_K"
      },
      "outputs": [],
      "source": [
        "vocab = {value:key for (key, value) in vectorizer.vocabulary_.items()}\n",
        "\n",
        "def show_topics(a):\n",
        "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[-8:-1]]\n",
        "    topic_words = ([top_words(t) for t in a])\n",
        "    return [' '.join(t) for t in topic_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDhDFVY9_J_M",
        "outputId": "4e926128-fda6-4fd2-af70-a914e61d5730"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['medalla querer ganar gustar comprar cerveza cruzcampo',\n",
              " 'olimpia nikes siempre nuevo zapatilla camiseta adidas',\n",
              " 'comprar nuevo conocer gustar aldub81stweeksary superstar cruzcampo',\n",
              " 'bueno querer invitar beber arruinaunacitacon4palabras cerveza gustar',\n",
              " '10 terminar carrera milka ritmar correr acabo',\n",
              " 'alfajor querer ganar carrefour comprar mercadona chocolate',\n",
              " 'panga vender movistar mejor comprar bimbo carrefour']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "show_topics(VT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKCo8UOd_J_Q"
      },
      "source": [
        "Limitaciones en LSI:\n",
        " - LSI sufre de un problema llamado \"Indeterminación del signo\", que básicamente significa que el signo en la matríz VT y USigma dependen del algorimo que se utilizó para generarlos y de las condiciones iniciales (initial random state). En este contexto, que significa que un tópico esté relacionado con una palabra en un valor negativo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no6V6rtO_J_Q"
      },
      "source": [
        "### NMF: Non-negative Matrix Factorization\n",
        "\n",
        "Motivación: En lugar de construir nuestros factores imponiendo la restricción de que sean ortogonales, la idea es de construirlos de tal forma que sean no-negativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NQwyjnN8_J_R"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nmf = NMF(n_components=7, random_state = 1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdTfBg2n_J_U",
        "outputId": "556cd182-72e3-4bea-a407-955beba36c23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:294: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "W1 = nmf.fit_transform(vectors)\n",
        "H1 = nmf.components_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIYwacxIfxqQ"
      },
      "source": [
        "En este caso, la matriz que nos interesa es H1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S39Zrr06_J_a",
        "outputId": "64cebfe0-fe61-4bd9-e047-a4e9d71659ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 6733)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "H1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkEBkOc-fqtT"
      },
      "source": [
        "#### Interpretando los tópicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8qfO_Dx_J_d",
        "outputId": "93817fe2-e6ce-4b7a-c9dd-8dafbab86c1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['novio comprar querer corona medalla cerveza ganar',\n",
              " 'olimpia color nikes siempre nuevo zapatilla camiseta',\n",
              " 'tenis napaacc cliente nuevo conocer aldub81stweeksary superstar',\n",
              " 'mahou invitar querer beber arruinaunacitacon4palabras cerveza gustar',\n",
              " '50 10 terminar carrera ritmar correr acabo',\n",
              " 'mcflurry necesito quiero querer alfajor ganar chocolate',\n",
              " 'panga vender movistar mejor comprar bimbo carrefour']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "show_topics(H1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbMNkPv7_J_i"
      },
      "source": [
        "### LDA: Latent Dirichlet Allocation\n",
        "\n",
        "LDA es un método Bayesiano basado en la distribución de Dirichlet, la cual es una distribución sobre probabilidades en K categorias. LDA supone que los documentos que tenemos pertenecen a K categorias distintas cuya distribución es desconocida, sin embargo, asume que todos los fragmentos que componen el texto fueron generados a través de un mismo proceso generativo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bct-Ck5f6fs"
      },
      "source": [
        "La distribución Dirichlet es una generalización de la distribución Beta en un espacio multidimensional. Así como la distribución beta es la distribución previa de la binomial, la distribución de Dirichlet es la distribución previa de la multinomial. \n",
        "\n",
        "$$ P(w\\mid d) = P(d)\\sum_c P(k\\mid d)P(w\\mid k) $$\n",
        "\n",
        "*¿Notan alguna similitud con SVD?*\n",
        "\n",
        "[David Blei, Andrew Ng, Michael Jordan: Latent Dirichlet Allocation (https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cN1vPUB3_J_j"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1dC1tN6_J_k",
        "outputId": "728ba140-326f-43d1-a06d-a3b8f86af4a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=7)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "lda.fit(vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Interpretando los tópicos\n",
        "\n",
        "Podemos ver las 10 palabras más relevantes de los 7 tópicos que encontró LDA de la siguiente forma:"
      ],
      "metadata": {
        "id": "7aICU5GKtNEp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF-MpBfDgk2O",
        "outputId": "722ace35-4822-4d3e-d580-f2e641d7ed0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic  0 mercadona movistar nuevo adidas marcar toyota comprar carrefour mejorar anunciar\n",
            "Topic  1 adir cruzcampo acabo nikeplus correr carrefour banco ritmar heineken milka\n",
            "Topic  2 bimbo cruzcampo gustar heineken adir color arruinaunacitacon4palabras mercadona mujer movistar\n",
            "Topic  3 milka heineken ganar mejor querer chocolate mercadona refugiar carrefour buscar\n",
            "Topic  4 cerveza heineken cruzcampo mercadona mundo peugeot taller necesito adidas mecanico\n",
            "Topic  5 adidas heineken galicia gracia bimbo estrella comprar favor hacer mercadona\n",
            "Topic  6 heineken suzuki toyota alianza alcampo carrefour adidas supermercado mercadona caixa\n"
          ]
        }
      ],
      "source": [
        "for idx, topic in enumerate(lda.components_):\n",
        "    print (\"Topic \", idx, \" \".join(vocab[i] for i in topic.argsort()[:-10 - 1:-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra alternativa es utilizando una librería especifica para estas visualizaciones. `pyLDAvis` es una librería de Python para la visualización de modelos de modelado de tópicos. Se trata de una portabilidad del fabuloso paquete de R de Carson Sievert y Kenny Shirley.\n",
        "\n",
        "`pyLDAvis` está diseñada para ayudar a los usuarios a interpretar los temas en un modelo de tópicos que se ha ajustado a un corpus de datos de texto. El paquete extrae información de un modelo LDA.\n",
        "\n",
        "La visualización está diseñada para usarse dentro de un notebook de Jupyter, pero también se puede guardar en un archivo HTML independiente para compartirlo fácilmente."
      ],
      "metadata": {
        "id": "Cclo_eRivRwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "\n",
        "pyLDAvis.enable_notebook()"
      ],
      "metadata": {
        "id": "eaPP3P_6tNkL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.sklearn.prepare(lda, vectors, vectorizer, mds='tsne')"
      ],
      "metadata": {
        "id": "pgvdGqeluJSu",
        "outputId": "b3a27605-5775-4d15-a7fc-f872ef5d10d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=               x          y  topics  cluster       Freq\n",
              "topic                                                  \n",
              "1     -29.594002  60.112713       1        1  16.676527\n",
              "6     -45.996586  11.891685       2        1  14.643260\n",
              "0      20.368856  70.019325       3        1  14.177102\n",
              "3      53.928768  31.704309       4        1  13.797790\n",
              "4     -12.437127 -26.423267       5        1  13.769867\n",
              "2       3.965971  21.797720       6        1  13.593864\n",
              "5      37.524284 -16.517805       7        1  13.341589, topic_info=           Term       Freq      Total Category  logprob  loglift\n",
              "4161      milka  27.000000  27.000000  Default  30.0000  30.0000\n",
              "320        adir  36.000000  36.000000  Default  29.0000  29.0000\n",
              "4404   nikeplus  10.000000  10.000000  Default  28.0000  28.0000\n",
              "6043     suzuki   9.000000   9.000000  Default  27.0000  27.0000\n",
              "239       acabo  11.000000  11.000000  Default  26.0000  26.0000\n",
              "...         ...        ...        ...      ...      ...      ...\n",
              "320        adir   2.502521  36.243925   Topic7  -6.1051  -0.6587\n",
              "4471      nuevo   2.186228  17.230517   Topic7  -6.2403  -0.0502\n",
              "1922  cruzcampo   2.406396  37.537635   Topic7  -6.1443  -0.7329\n",
              "1272  carrefour   2.256442  29.798338   Topic7  -6.2086  -0.5664\n",
              "4283   movistar   2.238576  28.017037   Topic7  -6.2166  -0.5127\n",
              "\n",
              "[434 rows x 6 columns], token_table=      Topic      Freq        Term\n",
              "term                             \n",
              "32        1  0.274757          10\n",
              "32        3  0.274757          10\n",
              "32        4  0.549513          10\n",
              "59        1  0.708213      160mil\n",
              "135       6  0.526481          45\n",
              "...     ...       ...         ...\n",
              "6721      2  0.176610   zapatilla\n",
              "6721      3  0.353220   zapatilla\n",
              "6721      5  0.176610   zapatilla\n",
              "6721      7  0.176610   zapatilla\n",
              "6722      6  0.762942  zapatillas\n",
              "\n",
              "[703 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 7, 1, 4, 5, 3, 6])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el571401108779422248386181531\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el571401108779422248386181531_data = {\"mdsDat\": {\"x\": [-29.59400177001953, -45.996585845947266, 20.36885643005371, 53.928768157958984, -12.437127113342285, 3.9659712314605713, 37.52428436279297], \"y\": [60.11271286010742, 11.891684532165527, 70.01932525634766, 31.704309463500977, -26.423267364501953, 21.797719955444336, -16.517805099487305], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"Freq\": [16.676526957163006, 14.64326046529508, 14.177102495936817, 13.797790341195803, 13.769867155642727, 13.59386360122673, 13.341588983539845]}, \"tinfo\": {\"Term\": [\"milka\", \"adir\", \"nikeplus\", \"suzuki\", \"acabo\", \"correr\", \"adidas\", \"heineken\", \"galicia\", \"cerveza\", \"ritmar\", \"estrella\", \"ganar\", \"alianza\", \"gracia\", \"alcampo\", \"cruzcampo\", \"supermercado\", \"arruinaunacitacon4palabras\", \"taller\", \"color\", \"banco\", \"mecanico\", \"refugiar\", \"necesito\", \"ofrecer\", \"bimbo\", \"chocolate\", \"reparacion\", \"negociaci\\u00f3n\", \"nikeplus\", \"correr\", \"ritmar\", \"acabo\", \"ofrecer\", \"diciembre\", \"abrir\", \"vizcaya\", \"bilbao\", \"organizar\", \"mcflurry\", \"montar\", \"abril\", \"argentaria\", \"780\", \"negociar\", \"corrio\", \"asesor\", \"faltar\", \"conmigo\", \"forzar\", \"balance\", \"50\", \"mueble\", \"concha\", \"adelantar\", \"kcafavglobalmusicstar\", \"caracas\", \"160mil\", \"lunarlon\", \"carrera\", \"quien\", \"adir\", \"amigo\", \"encontrar\", \"leroy\", \"tomar\", \"banco\", \"ikea\", \"cruzcampo\", \"sabadell\", \"menos\", \"necesitar\", \"carrefour\", \"ahora\", \"bueno\", \"santander\", \"milka\", \"bankia\", \"heineken\", \"movistar\", \"decir\", \"toyota\", \"mercadona\", \"comprar\", \"poder\", \"querer\", \"mejor\", \"suzuki\", \"alianza\", \"negociaci\\u00f3n\", \"siglo\", \"supermercado\", \"forjar\", \"entrenamiento\", \"novio\", \"intercambiar\", \"asociacion\", \"iniciar\", \"lindo\", \"napaacc\", \"barato\", \"saldo\", \"encargar\", \"helar\", \"copiar\", \"training\", \"verdad\", \"comision\", \"bancopopular\", \"tecnologia\", \"atletismo\", \"extrane\", \"siguemeytesigo\", \"willem\", \"posible\", \"ibex\", \"liberbank\", \"desarrollar\", \"alcampo\", \"medalla\", \"caixa\", \"corona\", \"online\", \"heineken\", \"pillar\", \"gracias\", \"toyota\", \"siempre\", \"llegar\", \"venir\", \"carrefour\", \"pagar\", \"vestir\", \"mercadona\", \"adidas\", \"comprar\", \"bankia\", \"movistar\", \"peugeot\", \"jejeje\", \"aldub81stweeksary\", \"pasate\", \"dudar\", \"dieno\", \"marcos\", \"kenia\", \"asics\", \"imelda\", \"horas\", \"entrevista\", \"buenas\", \"direct\", \"beneficio\", \"arrasar\", \"haz\", \"anticapitalismo\", \"agotar\", \"lejos\", \"adicolor\", \"terelu\", \"europeo\", \"turquia\", \"incorporar\", \"superstar\", \"hostia\", \"traves\", \"telcel\", \"mejorar\", \"bonito\", \"sergio\", \"seriar\", \"empezar\", \"anunciar\", \"equipo\", \"nuevo\", \"marcar\", \"movistar\", \"panga\", \"mercadona\", \"video\", \"bolsa\", \"vender\", \"adidas\", \"zapatilla\", \"bueno\", \"toyota\", \"comprar\", \"alcampo\", \"bankia\", \"carrefour\", \"bimbo\", \"peugeot\", \"gustar\", \"adir\", \"galicia\", \"cruzcampo\", \"refugiar\", \"alfajor\", \"graduados\", \"programa\", \"potencial\", \"diseno\", \"zapar\", \"presionan\", \"ganar\", \"lado\", \"valle\", \"sed\\u00e1n\", \"frias\", \"visitar\", \"teatro\", \"doler\", \"directo\", \"puleva\", \"pbbpadaluckmayward\", \"borracho\", \"mano\", \"hermanar\", \"declarar\", \"enterate\", \"vivienda\", \"premiar\", \"relleno\", \"calor\", \"morir\", \"congelar\", \"cumplir\", \"chocolate\", \"buscar\", \"tengo\", \"milka\", \"fibra\", \"cargar\", \"quedar\", \"quiero\", \"querer\", \"decathlon\", \"momento\", \"heineken\", \"mejor\", \"mientras\", \"traer\", \"10\", \"cerveza\", \"mercadona\", \"medio\", \"chico\", \"carrefour\", \"poder\", \"bimbo\", \"nuevo\", \"movistar\", \"parecer\", \"vender\", \"vodafone\", \"adir\", \"cruzcampo\", \"taller\", \"mecanico\", \"necesito\", \"reparacion\", \"oreo\", \"yeezy\", \"sportage\", \"captar\", \"componente\", \"solucionar\", \"990\", \"osito\", \"hamburgo\", \"diamundialcontraelcancer\", \"asorbaex\", \"batallar\", \"rebook\", \"desvelar\", \"click\", \"podrir\", \"quejandote\", \"suede\", \"pabelloneuropa\", \"disfrutar\", \"buena\", \"500\", \"efecto\", \"chocotorta\", \"mego\", \"alexander\", \"limon\", \"shoes\", \"sucursal\", \"probar\", \"cerveza\", \"mundo\", \"viernes\", \"tiempo\", \"manana\", \"peugeot\", \"mahou\", \"tenis\", \"cruzcampo\", \"hombre\", \"comer\", \"heineken\", \"vender\", \"seguro\", \"mandar\", \"mercadona\", \"gala6ghvip5\", \"carrefour\", \"adidas\", \"milka\", \"bimbo\", \"banco\", \"santander\", \"poder\", \"bankia\", \"movistar\", \"mejor\", \"llevar\", \"arruinaunacitacon4palabras\", \"color\", \"nikes\", \"bombazo\", \"zapatillas\", \"90\", \"95\", \"presto\", \"mujer\", \"encantar\", \"extrano\", \"caminar\", \"sudaderilla\", \"hypervenom\", \"tortilla\", \"ciclo\", \"devolucion\", \"mallas\", \"calle\", \"sevilla\", \"negro\", \"chaval\", \"patata\", \"control\", \"roscar\", \"lossimsaniversario\", \"conocer\", \"banderazo\", \"crudo\", \"denominacion\", \"45\", \"grabar\", \"pantalon\", \"modelar\", \"gustar\", \"lorenzo\", \"bimbo\", \"clausular\", \"hacendar\", \"poner\", \"fundador\", \"camiseta\", \"soler\", \"cruzcampo\", \"hombre\", \"llevar\", \"cliente\", \"salir\", \"adir\", \"heineken\", \"mercadona\", \"movistar\", \"toyota\", \"adidas\", \"poder\", \"santander\", \"comprar\", \"estrellar\", \"conseguir\", \"espanola\", \"queja\", \"carrefourarg\", \"fallece\", \"corazon\", \"parra\", \"patta\", \"name\", \"galicia\", \"ordinario\", \"electrico\", \"estrella\", \"funcionar\", \"hipotecario\", \"empresas\", \"apostar\", \"coronar\", \"donitas\", \"panadero\", \"cabr\\u00f3n\", \"ropita\", \"barcelona\", \"liderar\", \"romeo\", \"nikefootball\", \"versiones\", \"disenadores\", \"videos\", \"gracia\", \"reclamar\", \"ayudar\", \"favor\", \"adidas\", \"emplear\", \"alguien\", \"mexicano\", \"servitje\", \"jajaja\", \"bimbo\", \"super\", \"hacer\", \"comprar\", \"pasar\", \"lorenzo\", \"heineken\", \"poder\", \"hyundai\", \"gustar\", \"mercadona\", \"mejor\", \"adir\", \"nuevo\", \"cruzcampo\", \"carrefour\", \"movistar\"], \"Freq\": [27.0, 36.0, 10.0, 9.0, 11.0, 9.0, 38.0, 58.0, 8.0, 14.0, 6.0, 7.0, 9.0, 5.0, 10.0, 8.0, 37.0, 5.0, 4.0, 4.0, 5.0, 17.0, 4.0, 4.0, 4.0, 5.0, 26.0, 8.0, 4.0, 4.0, 9.704622297798768, 9.245984770326235, 6.457952833733172, 10.201593286958294, 4.995802052258755, 2.738139821696373, 2.3773714174436544, 2.2909593217613904, 2.1113748009357125, 2.8605668832770434, 1.9770832873780357, 4.966415303307257, 2.3508890061806396, 1.6165738731699448, 1.6094895208704258, 1.4942730391292494, 1.9516627216355162, 1.2151475813623636, 2.6840995797412255, 1.5131442217784836, 1.1165690832042419, 1.0910143829919947, 1.0509719594525169, 4.878527660996187, 0.9913315601446124, 0.9646123616014614, 0.9589738588722259, 0.949314088110914, 0.938600087254185, 0.938600087254185, 2.213998136829044, 3.8752362845311925, 21.30315546303747, 3.875043867210952, 3.6708708134065886, 2.2439145510632996, 3.6046654527753312, 8.24898531488005, 2.1469690083093056, 14.10879574673095, 3.4033309993256893, 3.5562112317875094, 3.0678457492460676, 8.68678076629647, 4.138735697994478, 4.274127329386092, 4.504048133124643, 5.663703449239615, 4.455537904681029, 6.256404999634075, 4.722552547983132, 3.266402406259139, 4.11795899342092, 4.456462259483112, 3.9871851328854833, 3.339977376968217, 3.213695132674096, 3.2419431830111933, 8.669922230306879, 5.434278793779233, 3.848570539538896, 2.5726193841470466, 5.021815100112706, 2.3835552294795823, 1.9659029515362592, 3.3441953211158904, 1.7701124399277819, 2.574527090519553, 3.8104041194724765, 1.6980062253697679, 1.5830269236935612, 4.122027659726825, 1.260397789932275, 1.2506401851261615, 2.582432732401491, 1.6571393797286023, 1.1860571999786964, 2.9425394491697423, 1.1432375703163342, 1.1237517643518995, 3.4085762578299876, 1.0965803837383699, 1.0483323628740993, 1.6578405695148184, 1.0282903746065173, 2.274863434603449, 0.9782034630234258, 0.9782034630234258, 1.7730642130611018, 5.423088875251797, 2.9998512671846056, 4.6115174603777715, 2.5639492135903814, 3.046624438901102, 19.750054164743794, 1.9621878305673741, 4.177085212989334, 8.235178842264094, 4.202172534204084, 3.495167804367845, 2.9232211985676506, 5.266044603689819, 2.855105836200777, 2.5232459765471273, 4.866787027697155, 5.069608470139215, 3.50104376328842, 3.3781934772497033, 3.141819211723398, 2.5671228252717513, 3.0279847213689406, 3.0160215431399373, 3.013660186313018, 2.9554168698037344, 1.8357033511677399, 1.6641211209888378, 1.5201570915014853, 1.5005753428522555, 1.5005753428522555, 1.457706009270202, 1.425532871977904, 1.7506225126394774, 1.7784097560533483, 2.7493283008232985, 1.232353582980707, 2.2703239743052306, 1.160863777988326, 1.034914898987508, 1.028926378787164, 1.0260585210849342, 1.000304550562464, 1.662077308709179, 0.9841319156612394, 0.9761160122421396, 3.2613514589149353, 0.9228693662936064, 1.2455397835323834, 0.9165847737583492, 3.4585007751940875, 1.3962180734877718, 2.1342932160599495, 1.7680784931614737, 3.2560453149392234, 3.458140527635412, 1.4798898037093424, 6.672568462994712, 4.7834929403338835, 8.273315258473005, 2.8564058111760535, 8.414350464456838, 3.107947821441804, 2.430935552730436, 3.1670816457631172, 5.261453696487125, 2.296977630291809, 2.9873771355468546, 3.7203494023686443, 3.552437057403183, 2.5151704027250177, 3.1403290657636043, 3.526050126304568, 3.280633057665362, 2.6644700754789135, 2.6823842888467637, 2.845157548002789, 2.349411881551489, 2.4240649661829563, 4.059155349610162, 2.667227659216232, 1.2178151740659853, 1.2178151740659853, 1.2142930822322353, 3.34940245317836, 1.202976473151692, 1.1335907299692431, 6.74249166645815, 1.1286554086377252, 1.0910027078852993, 1.0796991184022016, 1.5538760139355137, 1.4874044541128169, 1.0242570083500406, 0.9754593538694654, 0.9551858217191901, 1.6466730336356978, 0.9262732503361519, 0.9182861926844936, 0.9151636651288689, 0.9059575455886157, 0.8662485370808429, 0.8598028969092045, 2.099028400812044, 1.7865211726704593, 0.8347735584542472, 1.1179208047198133, 1.3004008844618036, 1.182976783097573, 1.5323451985508667, 4.895377759425075, 3.9406889318964518, 2.9887866296715853, 14.877487032960065, 1.5130972608371418, 1.4773809556127602, 3.7088994067038263, 3.516372040798031, 4.966017258169544, 2.597340056233511, 2.1266584905483583, 11.825555178871143, 4.998582489551303, 1.9398310790694364, 1.9725122574869227, 1.7784959894567889, 3.6316327538759023, 4.719653109519013, 1.6508546921442735, 1.602482968161563, 4.024377776409047, 3.1817928451929505, 3.416612575227226, 2.9123412412165894, 3.270847683759955, 2.0178390779193482, 2.2222015997240647, 2.0196847578437516, 2.56697404671292, 2.4608609701804514, 4.349973834156089, 4.117519566477745, 4.175069104837882, 3.9151947221053174, 1.892424661316762, 1.828616415411145, 1.7441150195322217, 1.5595233648525268, 1.4209599243025208, 1.3895511083689118, 1.370486011418092, 2.8365113251862404, 1.3129564861706975, 1.225173929938121, 1.2251739299381208, 1.2200988839830333, 1.186240990637659, 1.1782882506694135, 2.6530078212197, 1.0730336852047522, 1.071231416708586, 1.0448987088430786, 1.0318553716578092, 1.4891103795393654, 1.434289653892623, 1.0166893162631747, 1.3020562453881612, 0.94031283891822, 1.3167423870715018, 0.9105465894903484, 1.359409642931476, 1.4319703428667525, 2.182795397374535, 3.028606678066153, 7.794500641496062, 4.5075881624747, 2.288707698560797, 2.1592868481327234, 3.235477224590266, 4.47782439641257, 2.284057711367675, 1.5324246899326772, 6.4085919805254825, 2.7670379166399175, 2.217035676404368, 7.4390079309031725, 3.074386830950877, 1.9651523696188664, 2.109665572371856, 4.517396259768318, 1.8747965623238456, 3.854108584111917, 4.137134867973451, 3.641014120039014, 3.5970270119141934, 3.0754543566811674, 2.7478427845173305, 2.874259974495847, 2.784451553651604, 2.9825746346599296, 2.5854849828248936, 2.1949799641083145, 4.318768797493625, 4.5996342868208675, 1.937206293075316, 1.4931329045698005, 2.9522671160323424, 1.354082326966716, 1.7613244477096042, 1.1804099292047934, 3.3905110580688493, 2.222304459465736, 2.1548622332408613, 1.6308681374117329, 1.0584438234709663, 1.0293652286975554, 0.9983588750958022, 0.9872021777654869, 1.824835689893432, 0.9757122559513685, 0.9739629891814536, 2.496682536241917, 2.9299328805757603, 0.9256562667460566, 0.9142631439635481, 0.9105381323080963, 0.9026686671610862, 0.8825557972467428, 2.948193051355066, 0.8766461285464276, 0.874958062241565, 0.8381659999645702, 1.2027697457503879, 1.1281867142227089, 1.3942153192292817, 1.9249996868199761, 6.576638999950273, 2.269007638442132, 8.34261781788723, 2.320568128616751, 2.386338615087177, 2.8937283615803127, 1.9093091964350168, 3.0864865482669015, 2.4208066562864885, 7.7678940926268965, 2.883736516423081, 3.0318478080367446, 3.149013597069185, 2.3428957390270226, 5.352688961498677, 6.049080227571885, 4.072975215916371, 3.387351948402172, 2.896478737597165, 3.180611854168608, 2.6940618916484027, 2.3863442774466304, 2.253366127028221, 2.9426544255141986, 2.2928223959953784, 1.7713125761428519, 1.5455119067481902, 1.3220898732979127, 1.3130452908664796, 1.8190397152767614, 1.2364410932930325, 1.2364410932930325, 1.1701885906754694, 6.185407405516887, 1.049278569770559, 1.5644709060616875, 5.182231808996532, 1.6554366341673923, 0.920222807204859, 1.2834558674348884, 0.9066110482154166, 2.0174498075281857, 0.8700128547198364, 0.8426339274446812, 1.2350711793929334, 0.7856106405391075, 1.4948978511098359, 1.4078344701248569, 0.77572513875391, 0.7558911109323501, 0.7387711120040777, 0.7271616142242011, 0.7234812438858345, 6.173534330149277, 2.44752278546054, 2.9003438014969505, 3.6841037532794463, 16.6249726744913, 2.789280792333727, 2.775457762808586, 1.3795717878524745, 2.0301772957424795, 2.2088795462670285, 5.816454334112201, 2.0663674573713884, 3.5265781563755976, 4.634239393763627, 2.4528073645285393, 2.015211470419729, 6.564589525976015, 3.0718841914938184, 2.196748577463965, 2.7286111900876078, 3.1595590480260607, 2.3577600702061936, 2.502520686935204, 2.186228093919284, 2.406396061645293, 2.2564417977089763, 2.2385757755895503], \"Total\": [27.0, 36.0, 10.0, 9.0, 11.0, 9.0, 38.0, 58.0, 8.0, 14.0, 6.0, 7.0, 9.0, 5.0, 10.0, 8.0, 37.0, 5.0, 4.0, 4.0, 5.0, 17.0, 4.0, 4.0, 4.0, 5.0, 26.0, 8.0, 4.0, 4.0, 10.178041692787088, 9.719441420987245, 6.931366040716911, 11.439152817017007, 5.7684465890576435, 3.2118455997343505, 2.850938457963621, 2.764506367008365, 2.5849379369515812, 3.505456791538819, 2.4507492515324723, 6.264484444754798, 2.996533400745106, 2.090201987082213, 2.082899048176934, 1.9683193731171087, 2.692588260524888, 1.6889618558802149, 3.7328444769354725, 2.1510681506050844, 1.590088932950769, 1.5644199359500868, 1.5243770063014137, 7.1358741727477755, 1.4647369008084203, 1.43801816668728, 1.4323797218848904, 1.4227200354063283, 1.4120053272341666, 1.4120053272341666, 3.40594973155125, 6.120755517940842, 36.243924779467115, 6.149817820637189, 6.307593750348298, 3.6748681202088327, 6.434159907792955, 17.163394819017736, 3.5315695348175544, 37.53763454545255, 6.778834510296248, 7.30702667960448, 5.943531234213311, 29.798338287192333, 10.639724606711443, 12.278122860621684, 14.59380072918852, 27.43493664441417, 19.409275635984745, 58.65986304811525, 28.01703706059114, 9.27058496677032, 23.825969910609345, 34.207183384866866, 21.582209910507302, 17.90119783518221, 14.322196552280428, 17.70150759732111, 9.14514596202544, 5.909504693703451, 4.3238448965036955, 3.047802403133793, 5.985428557224644, 2.8587277622486793, 2.4411289652843444, 4.199334514288659, 2.245470289475769, 3.267958810728549, 4.858231063179261, 2.173162963994122, 2.058252196179866, 5.562057127879805, 1.7355537158417556, 1.7258573096105796, 3.574121166515114, 2.3094379523987025, 1.6612134071943847, 4.152722904405481, 1.6187398477698889, 1.598926888485615, 4.882876878095432, 1.5717966281892852, 1.523626650309629, 2.4129563839987007, 1.5036024912783654, 3.3428229419141884, 1.4533592999126166, 1.4533592999126166, 2.6693906802238945, 8.593596325871127, 4.720040744138537, 7.76864512035364, 4.08066705096161, 5.282696915827106, 58.65986304811525, 3.2438449468236863, 8.997635207330516, 23.825969910609345, 10.772526273790117, 10.211879705471086, 7.416351901030474, 29.798338287192333, 7.6384235340473206, 5.985574173357314, 34.207183384866866, 38.30357323894616, 21.582209910507302, 19.409275635984745, 28.01703706059114, 12.952153235485637, 3.5035850278895473, 3.4916224978543027, 3.4892670772053878, 3.6173224237518333, 2.3113046509669233, 2.139721218470321, 1.9957676199280197, 1.9761754331243562, 1.9761754331243562, 1.9343572851101989, 1.9011343890979673, 2.3893850489957007, 2.4277773749596485, 3.800411024124397, 1.7079547259286134, 3.1741898184094275, 1.6364638970919991, 1.511134676740613, 1.5048923563548247, 1.5016717882713102, 1.4760982567057523, 2.462402821052726, 1.4597324151821243, 1.4517494305655123, 4.883770178511291, 1.3985658803323164, 1.8879448773378904, 1.3922311206769526, 5.332664026248391, 2.1574190331558865, 3.4210477408448328, 2.8446762839111255, 6.062448115566299, 6.815893819327179, 2.4049495407978827, 17.23051719632945, 11.134548173602926, 28.01703706059114, 6.541620103096023, 34.207183384866866, 8.595855473742688, 6.031581851901676, 10.438364433186194, 38.30357323894616, 5.662195502317227, 12.278122860621684, 23.825969910609345, 21.582209910507302, 8.593596325871127, 19.409275635984745, 29.798338287192333, 26.83735887796634, 12.952153235485637, 18.250271360609325, 36.243924779467115, 8.932643656110178, 37.53763454545255, 4.535433323377675, 3.3009224412107017, 1.6939784718146529, 1.6939784718146529, 1.6904775352846881, 4.668946854197836, 1.6791400814490196, 1.6098653858929413, 9.586931944059602, 1.6048550402576283, 1.5671660419210625, 1.5558735783327264, 2.2521705027224583, 2.1749135088496105, 1.5004282501904356, 1.4516226874468379, 1.4313837795413111, 2.477989584134376, 1.402437335543102, 1.3944501920210999, 1.3914286618509226, 1.3823474672553728, 1.34241251634441, 1.3363476240967196, 3.2676416298199915, 2.8003888965674233, 1.3109369969530582, 1.7556591297548485, 2.0527083113364046, 1.887476165120307, 2.449135695157066, 8.043364451317405, 6.552910764206861, 4.918992742783737, 27.43493664441417, 2.4219397322910714, 2.37273139640275, 7.536071969914638, 7.095874174511608, 14.322196552280428, 5.749913272458914, 4.377563667746494, 58.65986304811525, 17.70150759732111, 3.9623493875449185, 4.17330676245522, 3.63958606710629, 14.82706853848862, 34.207183384866866, 3.353028356853637, 3.1745679899195722, 29.798338287192333, 17.90119783518221, 26.83735887796634, 17.23051719632945, 28.01703706059114, 6.3999966660243315, 10.438364433186194, 7.349481280726577, 36.243924779467115, 37.53763454545255, 4.826187696184088, 4.593362226757463, 4.820175156944913, 4.586392246782216, 2.368442234870865, 2.3045772783920606, 2.2200160462448566, 2.0352850306301837, 1.9018332191505023, 1.8657704590514106, 1.8464504848728496, 3.8588039770571863, 1.7887718249420494, 1.701094032859336, 1.701094032859336, 1.6958608468363419, 1.6620042834309638, 1.6540625176721235, 3.753497020589779, 1.5487963364264825, 1.5469934673717243, 1.5207842470731965, 1.5076708176744666, 2.184071874808462, 2.1047169069230405, 1.4925577493480697, 1.936282237081874, 1.4160746046622184, 1.9995031121336262, 1.3863085647446358, 2.0765198301299224, 2.227406084133196, 3.5287723640890256, 5.068052765850048, 14.82706853848862, 8.275954572130065, 4.254580233551073, 3.977840756027255, 7.780185615351777, 12.952153235485637, 4.91251708283429, 2.5324355588357763, 37.53763454545255, 7.817211434726885, 5.250598233921776, 58.65986304811525, 10.438364433186194, 4.27308404765279, 5.111702084165198, 34.207183384866866, 4.077122893720335, 29.798338287192333, 38.30357323894616, 27.43493664441417, 26.83735887796634, 17.163394819017736, 14.59380072918852, 17.90119783518221, 19.409275635984745, 28.01703706059114, 17.70150759732111, 8.825356471642184, 4.794971005531574, 5.505459136894391, 2.413357120537605, 1.9696602067280775, 3.9321467387620714, 1.8307671526476086, 2.407991068302012, 1.6565619413195831, 4.7899794784959875, 3.151107545006118, 3.0923966766723785, 2.356241264574829, 1.534595178047323, 1.505516096410493, 1.4745096965029434, 1.4633528368476016, 2.71045614897258, 1.4518771581174406, 1.4502724781343421, 3.7331103880707577, 4.436887921732333, 1.4019368752213568, 1.3904139303733754, 1.3866889359842323, 1.3788203109661283, 1.3587071080827529, 4.54904509893224, 1.3527967500834353, 1.3511575051407274, 1.3143373358087542, 1.8994020906334272, 1.781449788988983, 2.392410891799275, 3.5672093833960874, 18.250271360609325, 4.682647728664156, 26.83735887796634, 4.880613447264795, 5.219727846826117, 7.414749781237941, 3.9656312646503533, 8.405026819758838, 5.864963224337089, 37.53763454545255, 7.817211434726885, 8.825356471642184, 9.59894989594705, 5.977965152612121, 36.243924779467115, 58.65986304811525, 34.207183384866866, 28.01703706059114, 23.825969910609345, 38.30357323894616, 17.90119783518221, 14.59380072918852, 21.582209910507302, 3.419637170711393, 2.7701774111846933, 2.248170379271334, 2.0223685612815094, 1.7989349934435774, 1.789897828309363, 2.49626239596133, 1.7132736997909803, 1.7132736997909803, 1.6470220076666262, 8.932643656110178, 1.526111368832198, 2.2966908635514183, 7.801907786886922, 2.5075988332816164, 1.3970551187586415, 1.95674639818002, 1.3834772814087093, 3.104551757698954, 1.346953111563197, 1.3194659367871038, 1.9360705050072173, 1.2624426976843932, 2.4032111367889475, 2.26806988366161, 1.252557056910101, 1.2329040188058884, 1.215603129176916, 1.2039939205246681, 1.2003132062697666, 10.747050551300994, 4.169130319618804, 5.224991978917741, 6.79216378914933, 38.30357323894616, 5.68345897163382, 5.669118736865933, 2.502137221089008, 4.332168176860382, 5.049905103600367, 26.83735887796634, 4.881139689211294, 12.72549652428327, 21.582209910507302, 6.837933013058443, 4.682647728664156, 58.65986304811525, 17.90119783518221, 7.644092647596382, 18.250271360609325, 34.207183384866866, 17.70150759732111, 36.243924779467115, 17.23051719632945, 37.53763454545255, 29.798338287192333, 28.01703706059114], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.9729, -5.0214, -5.3802, -4.923, -5.637, -6.2383, -6.3796, -6.4166, -6.4982, -6.1945, -6.5639, -5.6429, -6.3908, -6.7652, -6.7696, -6.8439, -6.5769, -7.0507, -6.2582, -6.8314, -7.1353, -7.1584, -7.1958, -5.6607, -7.2543, -7.2816, -7.2874, -7.2976, -7.3089, -7.3089, -6.4507, -5.8909, -4.1867, -5.891, -5.9451, -6.4373, -5.9633, -5.1355, -6.4815, -4.5988, -6.0208, -5.9769, -6.1246, -5.0837, -5.8252, -5.793, -5.7406, -5.5115, -5.7514, -5.4119, -5.6932, -6.0619, -5.8302, -5.7512, -5.8625, -6.0396, -6.0781, -6.0694, -4.9557, -5.4228, -5.7678, -6.1706, -5.5017, -6.2469, -6.4396, -5.9083, -6.5445, -6.1699, -5.7778, -6.5861, -6.6562, -5.6992, -6.8841, -6.8919, -6.1668, -6.6104, -6.9449, -6.0363, -6.9817, -6.9989, -5.8892, -7.0233, -7.0683, -6.61, -7.0876, -6.2936, -7.1376, -7.1376, -6.5428, -5.4249, -6.017, -5.587, -6.174, -6.0015, -4.1324, -6.4415, -5.6859, -5.0071, -5.6799, -5.8641, -6.0428, -5.4542, -6.0664, -6.19, -5.5331, -5.4923, -5.8625, -5.8982, -5.9707, -6.1727, -5.9753, -5.9792, -5.98, -5.9995, -6.4757, -6.5739, -6.6644, -6.6773, -6.6773, -6.7063, -6.7286, -6.5232, -6.5075, -6.0718, -6.8742, -6.2633, -6.934, -7.0489, -7.0547, -7.0574, -7.0829, -6.5751, -7.0992, -7.1073, -5.901, -7.1634, -6.8636, -7.1703, -5.8423, -6.7494, -6.325, -6.5133, -5.9027, -5.8424, -6.6912, -5.1852, -5.518, -4.9701, -6.0336, -4.9532, -5.9492, -6.1949, -5.9304, -5.4228, -6.2516, -5.9888, -5.7694, -5.8155, -6.1608, -5.9388, -5.823, -5.8951, -6.1032, -6.0965, -6.0376, -6.229, -6.1977, -5.6551, -6.075, -6.859, -6.859, -6.8619, -5.8473, -6.8713, -6.9307, -5.1476, -6.935, -6.969, -6.9794, -6.6153, -6.659, -7.0321, -7.0809, -7.1019, -6.5573, -7.1326, -7.1413, -7.1447, -7.1548, -7.1996, -7.2071, -6.3146, -6.4758, -7.2366, -6.9446, -6.7934, -6.888, -6.6293, -5.4678, -5.6847, -5.9612, -4.3562, -6.6419, -6.6658, -5.7453, -5.7986, -5.4534, -6.1016, -6.3015, -4.5858, -5.4469, -6.3935, -6.3767, -6.4803, -5.7664, -5.5043, -6.5548, -6.5845, -5.6637, -5.8986, -5.8274, -5.9871, -5.871, -6.354, -6.2576, -6.3531, -6.1133, -6.1555, -5.5839, -5.6388, -5.6249, -5.6892, -6.4162, -6.4505, -6.4978, -6.6096, -6.7027, -6.725, -6.7389, -6.0115, -6.7817, -6.8509, -6.8509, -6.8551, -6.8832, -6.89, -6.0783, -6.9835, -6.9852, -7.0101, -7.0227, -6.6559, -6.6934, -7.0375, -6.7901, -7.1156, -6.7789, -7.1477, -6.747, -6.695, -6.2734, -5.9459, -5.0006, -5.5483, -6.226, -6.2843, -5.8799, -5.5549, -6.2281, -6.6272, -5.1964, -6.0363, -6.2579, -5.0473, -5.9309, -6.3785, -6.3075, -5.5461, -6.4255, -5.7049, -5.634, -5.7618, -5.7739, -5.9306, -6.0432, -5.9982, -6.03, -5.9612, -6.1041, -6.2679, -5.5782, -5.5152, -6.3799, -6.6403, -5.9586, -6.738, -6.4751, -6.8753, -5.8202, -6.2426, -6.2734, -6.5521, -6.9844, -7.0122, -7.0428, -7.054, -6.4397, -7.0658, -7.0675, -6.1262, -5.9662, -7.1184, -7.1308, -7.1349, -7.1436, -7.1661, -5.96, -7.1728, -7.1747, -7.2177, -6.8565, -6.9206, -6.7088, -6.3862, -5.1576, -6.2218, -4.9198, -6.1994, -6.1714, -5.9786, -6.3944, -5.9141, -6.1571, -4.9912, -5.9821, -5.932, -5.8941, -6.1898, -5.3636, -5.2413, -5.6368, -5.8211, -5.9777, -5.8841, -6.0501, -6.1714, -6.2287, -5.9431, -6.1926, -6.4507, -6.5871, -6.7432, -6.7501, -6.4241, -6.8102, -6.8102, -6.8653, -5.2002, -6.9743, -6.5749, -5.3772, -6.5184, -7.1056, -6.7729, -7.1205, -6.3206, -7.1617, -7.1937, -6.8113, -7.2637, -6.6204, -6.6804, -7.2764, -7.3023, -7.3252, -7.341, -7.3461, -5.2022, -6.1274, -5.9576, -5.7184, -4.2115, -5.9966, -6.0016, -6.7007, -6.3143, -6.2299, -5.2617, -6.2966, -5.7621, -5.489, -6.1252, -6.3217, -5.1407, -5.9001, -6.2355, -6.0186, -5.872, -6.1647, -6.1051, -6.2403, -6.1443, -6.2086, -6.2166], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7435, 1.7412, 1.7204, 1.6767, 1.6474, 1.6316, 1.6095, 1.6033, 1.5888, 1.5879, 1.5764, 1.559, 1.5485, 1.5342, 1.5333, 1.5156, 1.4693, 1.4619, 1.4613, 1.4394, 1.4376, 1.4308, 1.4193, 1.4109, 1.4008, 1.3919, 1.3899, 1.3866, 1.3828, 1.3828, 1.3604, 1.3341, 1.2598, 1.3293, 1.2498, 1.2979, 1.2118, 1.0585, 1.2935, 0.8126, 1.1021, 1.071, 1.1298, 0.5585, 0.847, 0.7359, 0.6155, 0.2134, 0.3196, -0.447, 0.0107, 0.748, 0.0357, -0.2469, 0.1024, 0.1123, 0.2968, 0.0937, 1.8678, 1.8374, 1.8047, 1.7517, 1.7457, 1.7394, 1.7047, 1.6935, 1.6833, 1.6827, 1.6783, 1.6745, 1.6587, 1.6216, 1.6013, 1.5991, 1.5962, 1.5893, 1.5843, 1.5767, 1.5734, 1.5685, 1.5618, 1.5612, 1.5473, 1.5459, 1.5412, 1.5363, 1.5253, 1.5253, 1.512, 1.4608, 1.4679, 1.3997, 1.4565, 1.3708, 0.8326, 1.4185, 1.1538, 0.8588, 0.9798, 0.849, 0.9902, 0.188, 0.9371, 1.0574, -0.0288, -0.1011, 0.1024, 0.1728, -0.2668, 0.3027, 1.8077, 1.8071, 1.807, 1.7514, 1.7232, 1.7022, 1.6813, 1.6782, 1.6782, 1.6706, 1.6656, 1.6425, 1.6423, 1.6298, 1.6272, 1.6184, 1.6102, 1.575, 1.5733, 1.5727, 1.5644, 1.5605, 1.5593, 1.5566, 1.5498, 1.5378, 1.5376, 1.5355, 1.5205, 1.5184, 1.4817, 1.478, 1.3319, 1.275, 1.468, 1.0049, 1.1087, 0.7338, 1.1249, 0.551, 0.9362, 1.0448, 0.7609, -0.0316, 1.0513, 0.5401, 0.0966, 0.1493, 0.7249, 0.1321, -0.1807, -0.1482, 0.3723, 0.0361, -0.5911, 0.618, -0.7864, 1.8697, 1.7675, 1.6506, 1.6506, 1.6498, 1.6485, 1.6472, 1.6299, 1.6287, 1.6287, 1.6185, 1.6153, 1.6095, 1.6007, 1.5989, 1.5831, 1.5762, 1.572, 1.5659, 1.5629, 1.5617, 1.5581, 1.5426, 1.5397, 1.5381, 1.5312, 1.5293, 1.5293, 1.5242, 1.5135, 1.5117, 1.4841, 1.4721, 1.4824, 1.3687, 1.5103, 1.5069, 1.2717, 1.2786, 0.9215, 1.186, 1.2587, 0.3792, 0.7162, 1.2664, 1.2313, 1.2646, 0.5739, -0.0, 1.2721, 1.297, -0.0214, 0.2532, -0.0805, 0.2029, -0.1671, 0.8264, 0.4337, 0.689, -0.6669, -0.7442, 1.8788, 1.8733, 1.839, 1.8245, 1.7583, 1.7513, 1.7414, 1.7164, 1.6912, 1.688, 1.6846, 1.6749, 1.6734, 1.6545, 1.6545, 1.6534, 1.6455, 1.6435, 1.6357, 1.6157, 1.6152, 1.6074, 1.6035, 1.5997, 1.5992, 1.5987, 1.5859, 1.5733, 1.5649, 1.5623, 1.559, 1.5409, 1.5023, 1.4678, 1.3397, 1.3751, 1.3627, 1.3717, 1.1053, 0.9206, 1.2169, 1.4804, 0.215, 0.9441, 1.1205, -0.0823, 0.7603, 1.2059, 1.0977, -0.0418, 1.2058, -0.0626, -0.2429, -0.0369, -0.027, 0.2634, 0.3129, 0.1536, 0.041, -0.2573, 0.059, 0.5912, 1.891, 1.8158, 1.7758, 1.7186, 1.7089, 1.6939, 1.6828, 1.6567, 1.65, 1.6463, 1.6343, 1.6276, 1.6241, 1.6154, 1.6056, 1.6019, 1.5999, 1.5981, 1.5974, 1.5933, 1.5806, 1.5804, 1.5763, 1.5749, 1.5719, 1.5641, 1.5618, 1.5617, 1.561, 1.5457, 1.5386, 1.5387, 1.4556, 1.3787, 0.9749, 1.271, 0.8271, 1.2521, 1.2129, 1.0546, 1.2646, 0.9938, 1.1107, 0.4202, 0.9983, 0.9271, 0.881, 1.0589, 0.0829, -0.2763, -0.1325, -0.1172, -0.1117, -0.4929, 0.1017, 0.1847, -0.2639, 1.8641, 1.8252, 1.7759, 1.7454, 1.7063, 1.7045, 1.6978, 1.6881, 1.6881, 1.6725, 1.6468, 1.6397, 1.6304, 1.6052, 1.599, 1.5968, 1.5926, 1.5916, 1.5832, 1.5772, 1.5658, 1.5648, 1.5399, 1.5395, 1.5374, 1.5351, 1.5251, 1.5163, 1.51, 1.508, 1.4599, 1.4817, 1.4257, 1.4025, 1.1796, 1.3025, 1.3001, 1.4189, 1.2563, 1.1874, 0.4852, 1.1547, 0.731, 0.4759, 0.989, 1.1711, -0.1758, 0.2517, 0.7673, 0.1139, -0.3677, -0.0017, -0.6587, -0.0502, -0.7329, -0.5664, -0.5127]}, \"token.table\": {\"Topic\": [1, 3, 4, 1, 6, 1, 5, 1, 6, 6, 5, 1, 1, 1, 2, 1, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 3, 1, 2, 3, 4, 5, 6, 7, 2, 3, 3, 5, 4, 1, 5, 7, 2, 1, 2, 7, 3, 1, 3, 4, 5, 7, 7, 1, 3, 6, 1, 3, 2, 5, 2, 1, 2, 7, 1, 1, 2, 3, 5, 6, 2, 6, 1, 2, 3, 4, 5, 6, 7, 2, 7, 2, 7, 5, 3, 6, 1, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 6, 3, 4, 5, 3, 1, 2, 3, 4, 5, 6, 1, 3, 4, 5, 7, 1, 2, 3, 6, 4, 6, 1, 2, 3, 4, 6, 5, 1, 4, 1, 2, 3, 4, 5, 6, 7, 7, 1, 2, 3, 4, 5, 6, 6, 4, 2, 3, 4, 5, 5, 6, 2, 3, 5, 6, 1, 5, 1, 2, 5, 6, 7, 6, 1, 5, 6, 2, 5, 1, 2, 3, 4, 5, 6, 7, 1, 4, 1, 1, 6, 7, 6, 2, 7, 2, 5, 7, 1, 1, 6, 1, 2, 3, 4, 5, 6, 7, 4, 2, 3, 4, 1, 2, 3, 5, 6, 7, 4, 6, 2, 5, 6, 5, 1, 3, 3, 4, 7, 2, 4, 5, 4, 7, 3, 5, 7, 3, 5, 1, 4, 7, 7, 6, 7, 2, 1, 3, 6, 4, 2, 3, 3, 7, 3, 7, 7, 3, 2, 4, 6, 7, 1, 5, 6, 7, 2, 4, 2, 1, 4, 7, 6, 7, 1, 3, 5, 3, 7, 1, 4, 6, 7, 6, 1, 3, 5, 7, 1, 2, 3, 4, 7, 4, 1, 2, 3, 4, 5, 6, 7, 1, 3, 6, 7, 1, 2, 3, 4, 5, 6, 7, 5, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 4, 7, 1, 2, 5, 6, 3, 3, 6, 2, 3, 4, 5, 6, 7, 2, 1, 5, 3, 3, 2, 6, 2, 3, 6, 7, 3, 1, 3, 4, 3, 1, 6, 2, 7, 5, 2, 1, 2, 3, 4, 5, 6, 7, 2, 3, 5, 6, 6, 7, 6, 1, 3, 5, 6, 6, 1, 2, 3, 4, 5, 6, 7, 2, 3, 5, 6, 4, 1, 3, 4, 5, 7, 3, 1, 5, 2, 4, 6, 3, 4, 5, 1, 2, 3, 4, 5, 7, 3, 5, 1, 3, 6, 1, 2, 3, 4, 5, 6, 7, 3, 7, 1, 4, 7, 1, 2, 4, 5, 7, 4, 6, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 6, 1, 3, 4, 5, 7, 2, 1, 5, 7, 5, 2, 1, 1, 6, 7, 1, 6, 2, 1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 7, 5, 1, 5, 7, 5, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 7, 1, 2, 3, 4, 5, 7, 3, 6, 7, 4, 1, 2, 3, 4, 5, 6, 7, 2, 6, 1, 2, 3, 4, 5, 6, 7, 5, 1, 2, 5, 6, 7, 2, 4, 4, 6, 4, 6, 1, 5, 4, 4, 1, 2, 4, 5, 7, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 6, 1, 4, 5, 6, 5, 5, 6, 7, 4, 4, 5, 1, 7, 7, 6, 1, 2, 3, 5, 7, 2, 1, 2, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 4, 1, 2, 3, 5, 3, 3, 6, 7, 6, 5, 1, 2, 3, 4, 5, 6, 2, 2, 2, 3, 5, 6, 5, 5, 4, 5, 6, 5, 1, 2, 4, 7, 2, 2, 3, 6, 2, 5, 4, 2, 3, 3, 3, 4, 5, 5, 3, 1, 5, 1, 5, 6, 7, 6, 1, 2, 3, 4, 5, 6, 7, 1, 4, 2, 3, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 2, 7, 7, 1, 2, 5, 7, 1, 2, 3, 4, 6, 7, 7, 2, 5, 4, 4, 5, 1, 1, 2, 3, 4, 7, 2, 5, 4, 1, 2, 3, 5, 7, 6], \"Freq\": [0.27475651943987844, 0.27475651943987844, 0.5495130388797569, 0.7082126254854846, 0.5264814674740683, 0.6560056966657439, 0.6699908264432565, 0.9602001603248648, 0.5462191074128818, 0.8305678647762984, 0.5415796460249309, 0.6674379132575956, 0.7015233858918749, 0.8741906118365594, 0.08741906118365594, 0.695401506855557, 0.6659244768466862, 0.07832167461989348, 0.13053612436648912, 0.13053612436648912, 0.026107224873297825, 0.1044288994931913, 0.07832167461989348, 0.443822822846063, 0.5794074490491412, 0.055181661814203926, 0.0827724927213059, 0.0827724927213059, 0.13795415453550983, 0.0827724927213059, 0.6617543858876388, 0.3759495802623346, 0.1879747901311673, 0.09398739506558365, 0.09398739506558365, 0.09398739506558365, 0.09398739506558365, 0.09398739506558365, 0.5818285861237674, 0.3490971516742604, 0.8591994128356035, 0.721340129774214, 0.9088368640675089, 0.1763942592165271, 0.1763942592165271, 0.5291827776495813, 0.8460945983049097, 0.6504257714069254, 0.16260644285173134, 0.16260644285173134, 0.6110736703553331, 0.146715900585833, 0.44014770175749895, 0.146715900585833, 0.146715900585833, 0.146715900585833, 0.722816350827071, 0.9568453251696842, 0.5854956134485947, 0.8342073383521028, 0.5920796828646214, 1.0120558966963662, 0.9180042264153229, 0.5878569794987285, 0.6362146234859933, 0.19138785361487412, 0.19138785361487412, 0.5741635608446224, 0.6392145593521158, 0.4661082544774695, 0.11652706361936738, 0.11652706361936738, 0.17479059542905107, 0.11652706361936738, 0.6254194655186054, 0.7392093453346364, 0.2060870315316668, 0.15456527364875008, 0.15456527364875008, 0.1030435157658334, 0.15456527364875008, 0.1030435157658334, 0.1030435157658334, 0.7191583811590149, 0.17978959528975372, 0.41610992254977264, 0.41610992254977264, 0.5896710227525551, 0.7893883006223493, 0.2631294335407831, 0.7737129667254607, 0.03726149076543471, 0.03726149076543471, 0.11178447229630413, 0.11178447229630413, 0.14904596306173884, 0.2980919261234777, 0.22356894459260826, 0.1657939864788063, 0.3315879729576126, 0.1657939864788063, 0.1657939864788063, 0.1657939864788063, 0.5077017835787833, 0.4635168155243321, 0.7171285182661216, 0.47512327986281777, 0.8370354543068034, 0.3257826986589924, 0.0814456746647481, 0.2443370239942443, 0.0814456746647481, 0.0814456746647481, 0.1628913493294962, 0.15260393983421444, 0.15260393983421444, 0.6104157593368578, 0.15260393983421444, 0.5165101154186904, 0.12872257446540158, 0.6436128723270078, 0.12872257446540158, 0.6895255995524502, 0.5695866487133154, 0.8488095128751126, 0.2379528397575518, 0.1189764198787759, 0.1189764198787759, 0.1189764198787759, 0.3569292596363277, 0.9826633468535567, 0.7028789748605743, 0.42145520623028787, 0.30203026468319216, 0.16779459149066234, 0.13423567319252985, 0.13423567319252985, 0.13423567319252985, 0.06711783659626493, 0.06711783659626493, 0.5558844558834051, 0.5872077269587576, 0.13488843022532274, 0.06744421511266137, 0.2697768604506455, 0.539553720901291, 0.06744421511266137, 0.7132988779128208, 0.6300069824778489, 0.12432608345083905, 0.12432608345083905, 0.6216304172541953, 0.12432608345083905, 0.7061774829572159, 0.6833621904572447, 0.2048922765150398, 0.2048922765150398, 0.2048922765150398, 0.4097845530300796, 0.2664182213318694, 0.7992546639956081, 0.10417806227139789, 0.20835612454279578, 0.10417806227139789, 0.31253418681419365, 0.10417806227139789, 0.9081894671586794, 0.19045448831705414, 0.3809089766341083, 0.19045448831705414, 0.6177644921620256, 0.5258084620304787, 0.18533783225102446, 0.18533783225102446, 0.18533783225102446, 0.09266891612551223, 0.09266891612551223, 0.09266891612551223, 0.2316722903137806, 0.6827164656315261, 0.5298080147869101, 0.9297706348529265, 0.21982635437813572, 0.6594790631344072, 0.7219754200308349, 0.7211422648946344, 0.8660115756401664, 0.8011978240892358, 0.7351739219432395, 0.24505797398107984, 0.6442153831193876, 0.9259791391474668, 0.7427797369992707, 0.7401061654139625, 0.37295903616537324, 0.05327986230933903, 0.05327986230933903, 0.05327986230933903, 0.15983958692801709, 0.21311944923735612, 0.05327986230933903, 0.8166146138634991, 0.1739156666570653, 0.1739156666570653, 0.5217469999711959, 0.3236041750065679, 0.10786805833552263, 0.10786805833552263, 0.10786805833552263, 0.10786805833552263, 0.21573611667104525, 0.7449275001719661, 0.7608396815302121, 0.7492346529928884, 0.6045720698679329, 0.7378831790944547, 0.5878569794987285, 0.9340424085915363, 0.8653121513701405, 0.8237987636874001, 0.6986246555905862, 0.8305689779265887, 0.2141810629309055, 0.6425431887927165, 0.4578603898224264, 0.6888842456429454, 0.7424163405654537, 0.8293427150152803, 0.5164536351410612, 0.8708181112835363, 0.49484959587481225, 0.32989973058320815, 0.175949189567657, 0.175949189567657, 0.527847568702971, 0.5110524291395683, 0.634697474279989, 0.3173487371399945, 0.5794221772746896, 0.6341562501198059, 0.15853906252995148, 0.15853906252995148, 0.7483082859341574, 0.8192930518798045, 0.5260017417676984, 0.4158091398741917, 0.8896122902607722, 0.2563475568580169, 0.6408688921450423, 0.8772860541154736, 0.8122147939811735, 0.6563287664972135, 0.3233737791608499, 0.6467475583216998, 0.5586911074944115, 0.8036766649498587, 0.14722848727492815, 0.14722848727492815, 0.5889139490997126, 0.4128921899530648, 0.8257843799061296, 0.6996119135271549, 0.6288956417955027, 0.8880322327205552, 0.7975757419629449, 0.5043333246406454, 0.2521666623203227, 0.24527099772739733, 0.24527099772739733, 0.49054199545479465, 0.22389788253021198, 0.671693647590636, 0.10430865743441883, 0.7301606020409318, 0.10430865743441883, 0.10430865743441883, 0.5613405475590333, 0.1860975707197998, 0.0930487853598999, 0.0930487853598999, 0.5582927121593994, 0.11114031375547256, 0.44456125502189026, 0.11114031375547256, 0.11114031375547256, 0.11114031375547256, 0.590326274293653, 0.16438111744875658, 0.054793705816252196, 0.16438111744875658, 0.054793705816252196, 0.10958741163250439, 0.38355594071376536, 0.16438111744875658, 0.1915808696056932, 0.1915808696056932, 0.3831617392113864, 0.1915808696056932, 0.23574718631019914, 0.1571647908734661, 0.07858239543673305, 0.1571647908734661, 0.07858239543673305, 0.07858239543673305, 0.3143295817469322, 0.5590427946462075, 0.6300820412190066, 0.10228458929538502, 0.3409486309846167, 0.017047431549230836, 0.20456917859077003, 0.11933202084461585, 0.10228458929538502, 0.11933202084461585, 0.2797890595788147, 0.8393671787364442, 0.7234071199084864, 0.7157913718454815, 0.12792285437715523, 0.12792285437715523, 0.3837685631314657, 0.3837685631314657, 0.5169675776535929, 0.7150181582882514, 0.6642240507319961, 0.13081997381526259, 0.13081997381526259, 0.13081997381526259, 0.13081997381526259, 0.26163994763052517, 0.26163994763052517, 0.6880611009680299, 0.5663204363618236, 0.2831602181809118, 1.0120558966963662, 0.6888241034890308, 0.8233449475707669, 0.20583623689269173, 0.8906820140857543, 0.1980235231127497, 0.1980235231127497, 0.3960470462254994, 0.8562657895039323, 0.6981388976130468, 1.0021206777932057, 0.623109237230217, 0.6644993549055008, 0.5442372173851903, 0.27211860869259513, 0.6880611009680299, 0.4409035220667818, 0.4815749820879065, 0.9203175432017024, 0.19585032899755822, 0.2937754934963373, 0.09792516449877911, 0.09792516449877911, 0.09792516449877911, 0.09792516449877911, 0.09792516449877911, 0.1133098706225885, 0.226619741245177, 0.226619741245177, 0.3399296118677655, 0.4271087888497969, 0.4271087888497969, 0.7359937944323277, 0.7082126254854846, 0.20356163309727307, 0.40712326619454614, 0.20356163309727307, 0.6887635048247733, 0.12853163786051722, 0.12853163786051722, 0.12853163786051722, 0.12853163786051722, 0.3855949135815517, 0.12853163786051722, 0.12853163786051722, 0.19562955421399758, 0.19562955421399758, 0.39125910842799516, 0.19562955421399758, 0.7186857849181921, 0.1796211187752972, 0.44905279693824307, 0.1796211187752972, 0.1796211187752972, 0.0898105593876486, 0.9347012044072698, 0.8160769604435806, 0.8708218081950989, 0.6355877337977377, 0.21186257793257923, 0.21186257793257923, 0.29823785950273457, 0.5964757190054691, 0.5001242528364569, 0.16947709021428267, 0.11298472680952178, 0.11298472680952178, 0.28246181702380446, 0.16947709021428267, 0.11298472680952178, 0.5625705998415477, 0.18752353328051588, 0.5474182831663774, 0.2737091415831887, 0.13685457079159435, 0.1169345033467323, 0.14616812918341537, 0.2338690066934646, 0.14616812918341537, 0.14616812918341537, 0.1169345033467323, 0.08770087751004922, 0.3996583367097544, 0.3996583367097544, 0.2523755232548038, 0.5047510465096076, 0.2523755232548038, 0.2186992475239274, 0.036449874587321233, 0.5467481188098184, 0.14579949834928493, 0.07289974917464247, 0.28033117558352316, 0.5606623511670463, 0.22843756845112556, 0.4568751369022511, 0.22843756845112556, 0.7981502778231749, 0.4871612758994265, 0.17846283992082151, 0.1070777039524929, 0.2855405438733144, 0.1070777039524929, 0.1070777039524929, 0.1070777039524929, 0.0713851359683286, 0.7006850007382732, 0.14013700014765465, 0.20876916164033157, 0.6263074849209948, 0.12083198273798887, 0.12083198273798887, 0.24166396547597774, 0.6041599136899444, 0.6071564285997143, 0.9716982222645103, 0.5047504390539442, 0.16825014635131474, 0.16825014635131474, 0.8298453624111141, 0.925102563978287, 0.5080476337619745, 0.22538320048651608, 0.6761496014595483, 0.8110931465439911, 0.98250727417306, 0.8287211134150239, 0.7143989100635345, 0.11607312637290144, 0.05803656318645072, 0.4062559423051551, 0.1741096895593522, 0.05803656318645072, 0.11607312637290144, 0.11607312637290144, 0.8667844839691616, 0.18929725023670624, 0.5678917507101188, 0.6552601732894594, 0.844436892128402, 0.8558085802800797, 0.7774429636324439, 0.25914765454414795, 0.6632747601644685, 0.13091706626931915, 0.39275119880795745, 0.13091706626931915, 0.13091706626931915, 0.13091706626931915, 0.13091706626931915, 0.7578823917463132, 0.152867330147576, 0.45860199044272804, 0.152867330147576, 0.152867330147576, 0.417988399663205, 0.15625008139593274, 0.15625008139593274, 0.15625008139593274, 0.3125001627918655, 0.15625008139593274, 0.15625008139593274, 0.15625008139593274, 0.5836779027904299, 0.14624302374566903, 0.14624302374566903, 0.14624302374566903, 0.14624302374566903, 0.14624302374566903, 0.29248604749133805, 0.8597794131605283, 0.7192102856244145, 0.5836779027904299, 0.713044336924148, 0.07720723973989528, 0.23162171921968586, 0.23162171921968586, 0.07720723973989528, 0.3088289589595811, 0.07720723973989528, 0.07720723973989528, 0.6165522806379397, 0.3082761403189698, 0.16758655077840293, 0.11172436718560196, 0.05586218359280098, 0.16758655077840293, 0.16758655077840293, 0.16758655077840293, 0.16758655077840293, 0.6456626842928147, 0.13486631774552527, 0.26973263549105053, 0.13486631774552527, 0.4045989532365758, 0.13486631774552527, 0.5982967194950347, 0.5915488251854191, 0.7141865197549884, 0.3570932598774942, 0.6211699492161773, 0.6036598904375532, 0.19731444130540207, 0.5919433239162063, 0.590326274293653, 0.8071058945546982, 0.1326951234001189, 0.1326951234001189, 0.5307804936004756, 0.2653902468002378, 0.988939423945883, 0.6464151407820469, 0.2094650767463689, 0.06982169224878963, 0.06982169224878963, 0.3491084612439482, 0.13964338449757926, 0.06982169224878963, 0.06982169224878963, 0.6535140945060469, 0.16337852362651173, 0.16337852362651173, 0.16337852362651173, 0.2818539267767745, 0.563707853553549, 0.14092696338838726, 0.14092696338838726, 0.6016831665052311, 0.2398581774463296, 0.2398581774463296, 0.4797163548926592, 0.881944395341938, 0.7628131651820395, 0.8721452036306696, 0.8656302328796677, 0.7983668244757431, 0.7921151604221144, 0.7252576655904553, 0.4425539516333309, 0.14751798387777698, 0.14751798387777698, 0.14751798387777698, 0.14751798387777698, 0.5761849897656398, 0.16728100189126088, 0.16728100189126088, 0.16728100189126088, 0.33456200378252177, 0.16728100189126088, 0.3426112287527461, 0.06852224575054922, 0.13704449150109843, 0.06852224575054922, 0.20556673725164765, 0.13704449150109843, 0.06852224575054922, 0.6427257419408071, 0.23402301214957405, 0.23402301214957405, 0.23402301214957405, 0.4680460242991481, 0.5846162203822671, 0.7030676957204474, 0.4616625944215869, 0.4616625944215869, 0.5357462791325558, 0.44895271101369644, 0.18565747245992434, 0.3713149449198487, 0.09282873622996217, 0.09282873622996217, 0.09282873622996217, 0.09282873622996217, 0.9843157800897323, 0.8288587449250292, 0.17050405292405377, 0.17050405292405377, 0.17050405292405377, 0.34100810584810753, 0.5359716116999821, 0.9008943892018202, 0.2833846722947107, 0.5667693445894214, 0.651637652916672, 0.6575554697680066, 0.2048701868152399, 0.2048701868152399, 0.2048701868152399, 0.4097403736304798, 0.8353620717709188, 0.20475983992859134, 0.614279519785774, 0.20475983992859134, 0.9841286336349198, 0.8288115282301747, 0.6664763875734006, 0.614391899467707, 0.204797299822569, 0.7182715464037064, 0.20329365223541354, 0.6098809567062407, 0.20329365223541354, 0.7897535607656093, 0.6774616767258614, 0.2513926678650452, 0.5027853357300904, 0.621681782442998, 0.1554204456107495, 0.1554204456107495, 0.1554204456107495, 0.6781915387682252, 0.16788403641099456, 0.3357680728219891, 0.16788403641099456, 0.08394201820549728, 0.04197100910274864, 0.1259130273082459, 0.08394201820549728, 0.23961813902500778, 0.47923627805001556, 0.6019696179125446, 0.5296764815559959, 0.6850570622392012, 0.6380944796214323, 0.09580044904551786, 0.09580044904551786, 0.2874013471365536, 0.19160089809103573, 0.2874013471365536, 0.13483718320607924, 0.4045115496182377, 0.13483718320607924, 0.13483718320607924, 0.13483718320607924, 0.13483718320607924, 0.7224175725323265, 0.2408058575107755, 0.8226369083774071, 0.16706834984205018, 0.5012050495261505, 0.16706834984205018, 0.33413669968410037, 0.11633513418817334, 0.11633513418817334, 0.34900540256452006, 0.11633513418817334, 0.11633513418817334, 0.11633513418817334, 0.8331158857342883, 0.23504081368923976, 0.4700816273784795, 0.4597883989092218, 0.6120622230260228, 0.3060311115130114, 0.7234564636450151, 0.4081920730742261, 0.13606402435807538, 0.13606402435807538, 0.27212804871615076, 0.13606402435807538, 0.665069395535384, 0.8678381145003005, 0.5955429276258158, 0.17660993859903898, 0.17660993859903898, 0.35321987719807796, 0.17660993859903898, 0.17660993859903898, 0.7629420261524796], \"Term\": [\"10\", \"10\", \"10\", \"160mil\", \"45\", \"50\", \"500\", \"780\", \"90\", \"95\", \"990\", \"abril\", \"abrir\", \"acabo\", \"acabo\", \"adelantar\", \"adicolor\", \"adidas\", \"adidas\", \"adidas\", \"adidas\", \"adidas\", \"adidas\", \"adidas\", \"adir\", \"adir\", \"adir\", \"adir\", \"adir\", \"adir\", \"agotar\", \"ahora\", \"ahora\", \"ahora\", \"ahora\", \"ahora\", \"ahora\", \"ahora\", \"alcampo\", \"alcampo\", \"aldub81stweeksary\", \"alexander\", \"alfajor\", \"alguien\", \"alguien\", \"alguien\", \"alianza\", \"amigo\", \"amigo\", \"amigo\", \"anticapitalismo\", \"anunciar\", \"anunciar\", \"anunciar\", \"anunciar\", \"anunciar\", \"apostar\", \"argentaria\", \"arrasar\", \"arruinaunacitacon4palabras\", \"asesor\", \"asics\", \"asociacion\", \"asorbaex\", \"atletismo\", \"ayudar\", \"ayudar\", \"ayudar\", \"balance\", \"banco\", \"banco\", \"banco\", \"banco\", \"banco\", \"bancopopular\", \"banderazo\", \"bankia\", \"bankia\", \"bankia\", \"bankia\", \"bankia\", \"bankia\", \"bankia\", \"barato\", \"barato\", \"barcelona\", \"barcelona\", \"batallar\", \"beneficio\", \"beneficio\", \"bilbao\", \"bimbo\", \"bimbo\", \"bimbo\", \"bimbo\", \"bimbo\", \"bimbo\", \"bimbo\", \"bolsa\", \"bolsa\", \"bolsa\", \"bolsa\", \"bolsa\", \"bombazo\", \"bonito\", \"borracho\", \"buena\", \"buenas\", \"bueno\", \"bueno\", \"bueno\", \"bueno\", \"bueno\", \"bueno\", \"buscar\", \"buscar\", \"buscar\", \"buscar\", \"cabr\\u00f3n\", \"caixa\", \"caixa\", \"caixa\", \"calle\", \"calor\", \"caminar\", \"camiseta\", \"camiseta\", \"camiseta\", \"camiseta\", \"camiseta\", \"captar\", \"caracas\", \"cargar\", \"carrefour\", \"carrefour\", \"carrefour\", \"carrefour\", \"carrefour\", \"carrefour\", \"carrefour\", \"carrefourarg\", \"carrera\", \"cerveza\", \"cerveza\", \"cerveza\", \"cerveza\", \"cerveza\", \"chaval\", \"chico\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocotorta\", \"ciclo\", \"clausular\", \"clausular\", \"clausular\", \"clausular\", \"click\", \"click\", \"cliente\", \"cliente\", \"cliente\", \"cliente\", \"cliente\", \"color\", \"comer\", \"comer\", \"comer\", \"comision\", \"componente\", \"comprar\", \"comprar\", \"comprar\", \"comprar\", \"comprar\", \"comprar\", \"comprar\", \"concha\", \"congelar\", \"conmigo\", \"conocer\", \"conocer\", \"conseguir\", \"control\", \"copiar\", \"corazon\", \"corona\", \"corona\", \"coronar\", \"correr\", \"corrio\", \"crudo\", \"cruzcampo\", \"cruzcampo\", \"cruzcampo\", \"cruzcampo\", \"cruzcampo\", \"cruzcampo\", \"cruzcampo\", \"cumplir\", \"decathlon\", \"decathlon\", \"decathlon\", \"decir\", \"decir\", \"decir\", \"decir\", \"decir\", \"decir\", \"declarar\", \"denominacion\", \"desarrollar\", \"desvelar\", \"devolucion\", \"diamundialcontraelcancer\", \"diciembre\", \"dieno\", \"direct\", \"directo\", \"disenadores\", \"diseno\", \"diseno\", \"disfrutar\", \"doler\", \"donitas\", \"dudar\", \"efecto\", \"electrico\", \"empezar\", \"empezar\", \"emplear\", \"emplear\", \"emplear\", \"empresas\", \"encantar\", \"encantar\", \"encargar\", \"encontrar\", \"encontrar\", \"encontrar\", \"enterate\", \"entrenamiento\", \"entrevista\", \"equipo\", \"espanola\", \"estrella\", \"estrella\", \"estrellar\", \"europeo\", \"extrane\", \"extrano\", \"extrano\", \"fallece\", \"faltar\", \"favor\", \"favor\", \"favor\", \"fibra\", \"fibra\", \"forjar\", \"forzar\", \"frias\", \"funcionar\", \"fundador\", \"fundador\", \"gala6ghvip5\", \"gala6ghvip5\", \"gala6ghvip5\", \"galicia\", \"galicia\", \"ganar\", \"ganar\", \"ganar\", \"ganar\", \"grabar\", \"gracia\", \"gracia\", \"gracia\", \"gracia\", \"gracias\", \"gracias\", \"gracias\", \"gracias\", \"gracias\", \"graduados\", \"gustar\", \"gustar\", \"gustar\", \"gustar\", \"gustar\", \"gustar\", \"gustar\", \"hacendar\", \"hacendar\", \"hacendar\", \"hacendar\", \"hacer\", \"hacer\", \"hacer\", \"hacer\", \"hacer\", \"hacer\", \"hacer\", \"hamburgo\", \"haz\", \"heineken\", \"heineken\", \"heineken\", \"heineken\", \"heineken\", \"heineken\", \"heineken\", \"helar\", \"helar\", \"hermanar\", \"hipotecario\", \"hombre\", \"hombre\", \"hombre\", \"hombre\", \"horas\", \"hostia\", \"hypervenom\", \"hyundai\", \"hyundai\", \"hyundai\", \"hyundai\", \"hyundai\", \"hyundai\", \"ibex\", \"ikea\", \"ikea\", \"imelda\", \"incorporar\", \"iniciar\", \"iniciar\", \"intercambiar\", \"jajaja\", \"jajaja\", \"jajaja\", \"jejeje\", \"kcafavglobalmusicstar\", \"kenia\", \"lado\", \"lejos\", \"leroy\", \"leroy\", \"liberbank\", \"liderar\", \"limon\", \"lindo\", \"llegar\", \"llegar\", \"llegar\", \"llegar\", \"llegar\", \"llegar\", \"llegar\", \"llevar\", \"llevar\", \"llevar\", \"llevar\", \"lorenzo\", \"lorenzo\", \"lossimsaniversario\", \"lunarlon\", \"mahou\", \"mahou\", \"mahou\", \"mallas\", \"manana\", \"manana\", \"manana\", \"manana\", \"manana\", \"manana\", \"manana\", \"mandar\", \"mandar\", \"mandar\", \"mandar\", \"mano\", \"marcar\", \"marcar\", \"marcar\", \"marcar\", \"marcar\", \"marcos\", \"mcflurry\", \"mecanico\", \"medalla\", \"medalla\", \"medalla\", \"medio\", \"medio\", \"mego\", \"mejor\", \"mejor\", \"mejor\", \"mejor\", \"mejor\", \"mejor\", \"mejorar\", \"mejorar\", \"menos\", \"menos\", \"menos\", \"mercadona\", \"mercadona\", \"mercadona\", \"mercadona\", \"mercadona\", \"mercadona\", \"mercadona\", \"mexicano\", \"mexicano\", \"mientras\", \"mientras\", \"mientras\", \"milka\", \"milka\", \"milka\", \"milka\", \"milka\", \"modelar\", \"modelar\", \"momento\", \"momento\", \"momento\", \"montar\", \"morir\", \"movistar\", \"movistar\", \"movistar\", \"movistar\", \"movistar\", \"movistar\", \"movistar\", \"mueble\", \"mueble\", \"mujer\", \"mujer\", \"mundo\", \"mundo\", \"mundo\", \"mundo\", \"name\", \"napaacc\", \"necesitar\", \"necesitar\", \"necesitar\", \"necesito\", \"negociaci\\u00f3n\", \"negociar\", \"negro\", \"negro\", \"nikefootball\", \"nikeplus\", \"nikes\", \"novio\", \"nuevo\", \"nuevo\", \"nuevo\", \"nuevo\", \"nuevo\", \"nuevo\", \"nuevo\", \"ofrecer\", \"online\", \"online\", \"ordinario\", \"oreo\", \"organizar\", \"osito\", \"osito\", \"pabelloneuropa\", \"pagar\", \"pagar\", \"pagar\", \"pagar\", \"pagar\", \"pagar\", \"panadero\", \"panga\", \"panga\", \"panga\", \"panga\", \"pantalon\", \"parecer\", \"parecer\", \"parecer\", \"parecer\", \"parecer\", \"parecer\", \"parecer\", \"parra\", \"pasar\", \"pasar\", \"pasar\", \"pasar\", \"pasar\", \"pasar\", \"pasate\", \"patata\", \"patta\", \"pbbpadaluckmayward\", \"peugeot\", \"peugeot\", \"peugeot\", \"peugeot\", \"peugeot\", \"peugeot\", \"peugeot\", \"pillar\", \"pillar\", \"poder\", \"poder\", \"poder\", \"poder\", \"poder\", \"poder\", \"poder\", \"podrir\", \"poner\", \"poner\", \"poner\", \"poner\", \"poner\", \"posible\", \"potencial\", \"premiar\", \"premiar\", \"presionan\", \"presto\", \"probar\", \"probar\", \"programa\", \"puleva\", \"quedar\", \"quedar\", \"quedar\", \"quedar\", \"queja\", \"quejandote\", \"querer\", \"querer\", \"querer\", \"querer\", \"querer\", \"querer\", \"querer\", \"quien\", \"quien\", \"quien\", \"quien\", \"quiero\", \"quiero\", \"quiero\", \"quiero\", \"rebook\", \"reclamar\", \"reclamar\", \"reclamar\", \"refugiar\", \"relleno\", \"reparacion\", \"ritmar\", \"romeo\", \"ropita\", \"roscar\", \"sabadell\", \"sabadell\", \"sabadell\", \"sabadell\", \"sabadell\", \"saldo\", \"salir\", \"salir\", \"salir\", \"salir\", \"salir\", \"santander\", \"santander\", \"santander\", \"santander\", \"santander\", \"santander\", \"santander\", \"sed\\u00e1n\", \"seguro\", \"seguro\", \"seguro\", \"seguro\", \"sergio\", \"seriar\", \"servitje\", \"servitje\", \"sevilla\", \"shoes\", \"siempre\", \"siempre\", \"siempre\", \"siempre\", \"siempre\", \"siempre\", \"siglo\", \"siguemeytesigo\", \"soler\", \"soler\", \"soler\", \"soler\", \"solucionar\", \"sportage\", \"sucursal\", \"sucursal\", \"sudaderilla\", \"suede\", \"super\", \"super\", \"super\", \"super\", \"supermercado\", \"superstar\", \"superstar\", \"superstar\", \"suzuki\", \"taller\", \"teatro\", \"tecnologia\", \"tecnologia\", \"telcel\", \"tengo\", \"tengo\", \"tengo\", \"tenis\", \"terelu\", \"tiempo\", \"tiempo\", \"tomar\", \"tomar\", \"tomar\", \"tomar\", \"tortilla\", \"toyota\", \"toyota\", \"toyota\", \"toyota\", \"toyota\", \"toyota\", \"toyota\", \"traer\", \"traer\", \"training\", \"traves\", \"turquia\", \"valle\", \"vender\", \"vender\", \"vender\", \"vender\", \"vender\", \"venir\", \"venir\", \"venir\", \"venir\", \"venir\", \"venir\", \"verdad\", \"verdad\", \"versiones\", \"vestir\", \"vestir\", \"vestir\", \"vestir\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"videos\", \"viernes\", \"viernes\", \"visitar\", \"vivienda\", \"vivienda\", \"vizcaya\", \"vodafone\", \"vodafone\", \"vodafone\", \"vodafone\", \"vodafone\", \"willem\", \"yeezy\", \"zapar\", \"zapatilla\", \"zapatilla\", \"zapatilla\", \"zapatilla\", \"zapatilla\", \"zapatillas\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 7, 1, 4, 5, 3, 6]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el571401108779422248386181531\", ldavis_el571401108779422248386181531_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el571401108779422248386181531\", ldavis_el571401108779422248386181531_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el571401108779422248386181531\", ldavis_el571401108779422248386181531_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para más informacións sobre la librería `pyLDAvis`, se recomienda la lectura [del papaer original](http://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf) el cual fué presentado en la conferencia [*ACL Workshop on Interactive Language Learning, Visualization, and Interfaces*](http://nlp.stanford.edu/events/illvi2014/) en Baltimore el June 27, 2014."
      ],
      "metadata": {
        "id": "XZ8bz63cwLrn"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Topic Modeling.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "bea38c2984299ac640e8421861d34b2e05ee614f6236d2975c05eeb77366835f"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}