{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "NLP (nlp-py37)",
      "language": "python",
      "name": "nlp-py37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Topic Modeling.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Irja1O_J9X",
        "colab_type": "text"
      },
      "source": [
        "# Introducción a Métodos basados en frecuencias y Topic Modeling\n",
        "\n",
        "Topic modeling es una técnica de aprendizaje automático no supervisado donde intentados descubrir tópicos que son abstractos al texto pero que pueden describir una colección de documentos. Es importante marcar que estos \"tópicos\" no son necesariamente equivalentes a la interpretación coloquial de tópicos, sino que responden a un patrón que emerge de las palabras que están en los documentos.\n",
        "\n",
        "La suposición básica para Topic Modeling es que cada documento está representado por una mescla de tópicos, y cada tópico consite en una conlección de palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE_O7bEjLebd",
        "colab_type": "text"
      },
      "source": [
        "## Sobre el set de datos con el que vamos a trabajar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8lcRTa_Li4e",
        "colab_type": "text"
      },
      "source": [
        "Utilizaremos como ejemplo un set de datos en español que contiene tweets que diferentes usuarios han publicado en relación a diferentes marcas de productos u empresas en el rubro de alimentación, construcción, automoviles, etc. Estos tweets, a su vez, están asociados a una de las diferentes fases en el proceso de ventas (también conocido como Marketing Funel) y por eso están tagueados con las fases de:\n",
        " - Awareness – el cliente es conciente de la existencia de un producto o servicio\n",
        " - Interest – activamente expresa el interes de un producto o servicio\n",
        " - Evaluation – aspira una marca o producto en particular\n",
        " - Purchase – toma el siguiente paso necesario para comprar el producto o servicio\n",
        " - Postpurchase - realización del proceso de compra. El cliente compara la diferencia entre lo que deseaba y lo que obtuvo\n",
        "\n",
        "Origen: Spanish Corpus of Tweets for Marketing [http://ceur-ws.org/Vol-2111/paper1.pdf]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPpqVNrwSdhL",
        "colab_type": "text"
      },
      "source": [
        "Primero importaremos algunas librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfF_O0U_J9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2TJjaoMSh-w",
        "colab_type": "text"
      },
      "source": [
        "Preparé una versión pre-procesada de este dataset que pueden descargar desde:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RSsdeZTGw3Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7487967f-72bb-4cd6-ffe6-5f6a80d94432"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Datasets/mascorpus/tweets_marketing.csv --directory-prefix ./Datasets/mascorpus/"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-28 13:40:33--  https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Datasets/mascorpus/tweets_marketing.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 512573 (501K) [text/plain]\n",
            "Saving to: ‘./Datasets/mascorpus/tweets_marketing.csv.1’\n",
            "\n",
            "tweets_marketing.cs 100%[===================>] 500.56K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-08-28 13:40:34 (7.24 MB/s) - ‘./Datasets/mascorpus/tweets_marketing.csv.1’ saved [512573/512573]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc44Q7do_J9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = pd.read_csv('Datasets/mascorpus/tweets_marketing.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INJwReUXSs4K",
        "colab_type": "text"
      },
      "source": [
        "Inspeccionamos el set de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd6EocPdG5A0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "83728500-7b18-4bdd-c3fc-150aec7773f3"
      },
      "source": [
        "tweets.head(5)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXTO</th>\n",
              "      <th>SECTOR</th>\n",
              "      <th>MARCA</th>\n",
              "      <th>CANAL</th>\n",
              "      <th>AWARENESS</th>\n",
              "      <th>EVALUATION</th>\n",
              "      <th>PURCHASE</th>\n",
              "      <th>POSTPURCHASE</th>\n",
              "      <th>NC2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#tablondeanuncios Funda nordica ikea #madrid h...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>IKEA</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#tr Me ofrezco para montar muebles de Ikea - H...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>IKEA</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#VozPópuli Vozpópuli @voz_populi - #LoMásLeido...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>ALCAMPO</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#ZonaTecno Destacado: Todo lo que hay que sabe...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>CARREFOUR</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>$Carrefour retira pez #Panga. OCU y grupos x #...</td>\n",
              "      <td>RETAIL</td>\n",
              "      <td>CARREFOUR</td>\n",
              "      <td>Microblog</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TEXTO  SECTOR  ... POSTPURCHASE  NC2\n",
              "0  #tablondeanuncios Funda nordica ikea #madrid h...  RETAIL  ...            0  1.0\n",
              "1  #tr Me ofrezco para montar muebles de Ikea - H...  RETAIL  ...            0  1.0\n",
              "2  #VozPópuli Vozpópuli @voz_populi - #LoMásLeido...  RETAIL  ...            0  1.0\n",
              "3  #ZonaTecno Destacado: Todo lo que hay que sabe...  RETAIL  ...            0  1.0\n",
              "4  $Carrefour retira pez #Panga. OCU y grupos x #...  RETAIL  ...            0  1.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXwJS2Og_J9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "af206431-f16a-4a96-a6c5-76fb751040e5"
      },
      "source": [
        "tweets.groupby('SECTOR').head(1)[['TEXTO', 'SECTOR']]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXTO</th>\n",
              "      <th>SECTOR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#tablondeanuncios Funda nordica ikea #madrid h...</td>\n",
              "      <td>RETAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>\"Ilcinsisti lis MB dispiniblis\" te odeeeeeo Mo...</td>\n",
              "      <td>TELCO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>#CarlosSlim y Bimbo lanzarán un vehículo eléct...</td>\n",
              "      <td>ALIMENTACION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>‼🏎Toyota #Day, 4ruedas ,1/4 milla, 1 #pasión, ...</td>\n",
              "      <td>AUTOMOCION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1748</th>\n",
              "      <td>\"- Tú qué.\\n- Yo na.\"\\nConversaciones banco sa...</td>\n",
              "      <td>BANCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2348</th>\n",
              "      <td>- Cariño, te juro que sólo tenían Cruzcampo en...</td>\n",
              "      <td>BEBIDAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3023</th>\n",
              "      <td>#adidas #hockey Amenabar 2080 CABA https://t.c...</td>\n",
              "      <td>DEPORTES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  TEXTO        SECTOR\n",
              "0     #tablondeanuncios Funda nordica ikea #madrid h...        RETAIL\n",
              "725   \"Ilcinsisti lis MB dispiniblis\" te odeeeeeo Mo...         TELCO\n",
              "964   #CarlosSlim y Bimbo lanzarán un vehículo eléct...  ALIMENTACION\n",
              "1298  ‼🏎Toyota #Day, 4ruedas ,1/4 milla, 1 #pasión, ...    AUTOMOCION\n",
              "1748  \"- Tú qué.\\n- Yo na.\"\\nConversaciones banco sa...         BANCA\n",
              "2348  - Cariño, te juro que sólo tenían Cruzcampo en...       BEBIDAS\n",
              "3023  #adidas #hockey Amenabar 2080 CABA https://t.c...      DEPORTES"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9FcIehJ_J9q",
        "colab_type": "text"
      },
      "source": [
        "## Preprosesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VlfbDQc_J9q",
        "colab_type": "text"
      },
      "source": [
        "### Stop words\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcaReFCnS5lf",
        "colab_type": "text"
      },
      "source": [
        "Algunas palabras que son extremadamente frecuentes, \"a-priori\" (revisaremos este concepto luego) no son de mucha utilidad para resolver una tarea de clasificación de texto específica. Estas palabras se las conoce como Stop words y, dado que son de poca utilidad, son eliminadas del texto.\n",
        "\n",
        "**Spoiler Alert:**\n",
        "Mencionamos 'a priori', porque la tendencia general en los ultimos tiempos ha sido ir desde grandes listas de stop words en el order de 200-300 a listas muy pequeñas (10-15 - si es que las hay). Los buscadores, por ejemplo, hoy en día no eliminan estas palabras. Cuando veamos modelos de lenguaje, en realidad las vamos a necesitar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja75kpIe_J9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKPDo8b6_J9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6bce75b1-7494-4ca1-b65b-aceda0977314"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQlTlxvA_J90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spa_stopwords = stopwords.words('spanish')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZIgUnkM_J93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c87e436c-c9a5-45fd-815d-9f664e2674af"
      },
      "source": [
        "spa_stopwords[:10]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi58DXii_J97",
        "colab_type": "text"
      },
      "source": [
        "### Tokenización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBTU9Ak6_J98",
        "colab_type": "text"
      },
      "source": [
        "Se refiere al proceso de generación de tokens basado en un texto. Un token se diferencia de una palabra en el hecho de que una palabra es una instancia de un token. Existen varias técnicas para separar una oración o texto en general en palabras discretas.\n",
        "\n",
        "Lectura recomendada: Diferentes tokenizers:\n",
        " - http://www.nltk.org/api/nltk.tokenize.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BiCyQ7yTON5",
        "colab_type": "text"
      },
      "source": [
        "Tomemos un tweet de ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzRujM1t_J98",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "22a36c17-c872-462e-ce28-3984f69e7d84"
      },
      "source": [
        "tweet = tweets['TEXTO'][5]\n",
        "print(tweet)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ". @PoliciadeBurgos @PCivilBurgos @Aytoburgos Mismo peligro c/ Rio Viejo junto Mercadona Villimar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXXh8by-_J9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5glHPgt0Ir6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0337c4f6-410b-44b1-a656-32c9e76dfb4b"
      },
      "source": [
        "tokenizer.tokenize(tweet)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.',\n",
              " '@',\n",
              " 'PoliciadeBurgos',\n",
              " '@',\n",
              " 'PCivilBurgos',\n",
              " '@',\n",
              " 'Aytoburgos',\n",
              " 'Mismo',\n",
              " 'peligro',\n",
              " 'c/',\n",
              " 'Rio',\n",
              " 'Viejo',\n",
              " 'junto',\n",
              " 'Mercadona',\n",
              " 'Villimar']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_IERd4u_J-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize.casual import TweetTokenizer\n",
        "\n",
        "tokenizer = TweetTokenizer()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6AHmFOgI-DT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5ec5c704-3308-4a42-9cfa-b89a1a77f60b"
      },
      "source": [
        "tokenizer.tokenize(tweet)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.',\n",
              " '@PoliciadeBurgos',\n",
              " '@PCivilBurgos',\n",
              " '@Aytoburgos',\n",
              " 'Mismo',\n",
              " 'peligro',\n",
              " 'c',\n",
              " '/',\n",
              " 'Rio',\n",
              " 'Viejo',\n",
              " 'junto',\n",
              " 'Mercadona',\n",
              " 'Villimar']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlP2oXmn_J-F",
        "colab_type": "text"
      },
      "source": [
        "### Stemming and Lemmatization\n",
        "\n",
        "Existen palabras cuyo significado no cambia ya que estan atados a una palabra raiz que les da el significado:\n",
        "\n",
        "<i>Organizan, organiza, organizando, organizaron</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uvHJjdPTewA",
        "colab_type": "text"
      },
      "source": [
        "**Stemming y Lemmatization** son dos técnicas que generan la palabra raiz dada una palabra. La diferencia que hay entre estas técnicas es que **Lemmatization** utiliza reglas del lenguaje para extraer las palabras raiz y por lo tanto, el resultado son palabras que existen en el vocabulario. Por el contrario, **Stemming** utiliza heuristicas que truncan la palabra hasta su raiz invariable. El resultado son \"psudopalabras\" o mejor conocidos como tokens que no forman una palabra del lenguaje propiamente dicho. Esta técnica, como se puede intuir, es más rápida computacionalmente. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WATarE2OTlRI",
        "colab_type": "text"
      },
      "source": [
        "Utilizaremos la libreria nltk para stemming y spaCy para lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSGONgWJ_J-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import stem\n",
        "\n",
        "import spacy\n",
        "from spacy.lemmatizer import Lemmatizer"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBRNgDd_JkJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3c3c3987-1c43-40ae-9f87-b08708533d88"
      },
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: es_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz#egg=es_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (49.6.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHsY1CO9_J-I",
        "colab_type": "text"
      },
      "source": [
        "**Sobre la libreria spaCy:** Spacy es una libreria para NLP muy polupar actualmente ya que, al contrario de nltk, ofrece formas muy eficientes de hacer solo algunos tipos de operaciones. NLTK es una herramienta más general. Para instalar spaCy en español necesitaran ejecutar:\n",
        "\n",
        "```\n",
        "conda install -c spacy spacy\n",
        "python -m spacy download es_core_news_sm\n",
        "```\n",
        "\n",
        "Si bien NLTK ofrece la opción de hacer Lemmatization, su soporte mayoritariamente es para ingles. La versión en español no es demasiado buena. Si les interesa probarla puede hacerlo a traves del metodo.\n",
        "\n",
        "```\n",
        "nltk.wordnet.lemas(\"palabra\", lang='spa')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWqTzFm0Tydy",
        "colab_type": "text"
      },
      "source": [
        "Cargamos el modelo en español e instanciamos el parser:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVeCzmo5_J-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import es_core_news_sm as spa\n",
        "parser = spa.load()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLWW840SUEcS",
        "colab_type": "text"
      },
      "source": [
        "Creamos 2 funciones que nos ayuden a simplificar el uso de estos métodos: una para cada una de las técnicas mencionadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--OMLZ2k_J-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = lambda word : \" \".join([token.lemma_ for token in parser(word)])\n",
        "stemmer = stem.SnowballStemmer(language='spanish')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqLoIHHd_J-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = ['amigos', 'amigo', 'amiga', 'amistad' ]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_4-B8Me_J-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e56bb232-f674-440d-8bd4-3f0d0a359338"
      },
      "source": [
        "[stemmer.stem(word) for word in words]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['amig', 'amig', 'amig', 'amist']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zffzVC3_J-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b3d500c6-3d6f-431b-89fd-c5d95af7d4ce"
      },
      "source": [
        "[lemmatizer(word) for word in words]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['amigo', 'amigar', 'amigo', 'amistar']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5wt-YMf_J-e",
        "colab_type": "text"
      },
      "source": [
        "Nota: La precisión de Lemmatization depende de la implementación. La de español no es demasiado buena. Noten también lo que sucede con la palabra \"amigo\": ¿Es el verbo amigar o el sustantivo amigo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0VT-fzN_J-f",
        "colab_type": "text"
      },
      "source": [
        "### Otra estrategia\n",
        "\n",
        "El problema de reducir las palabras a sus formatos raiz radica en que en general cada palabra (separada por espacios, puntos, etc) conforma un elemento en nuestro vocabulario y no queremos diferentes elementos de nuestro vocabulario que mapeen al mismo elemento o concepto. Si por el contrario utilizaramos otra estrategia para determinar nuestro vocabulario (o mejor dicho, cada elemento de nuestro vocabulario) entonces este problema quizás no existiría (o se volvería peor).\n",
        "\n",
        "Este tipo de técnicas por lo general intentan representar el vocabulario con \"sub-palabras\" o partes de las palabras como unidad. Un ejemplo de esto es SentencePiece."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZISG0Cs_J-g",
        "colab_type": "text"
      },
      "source": [
        "### Creando una rutina de preprosesamiento de texto\n",
        "\n",
        "Adicionalmente de utilizar Lemmatization y eliminar stop words, necesitamos hacer algunas tareas extras:\n",
        " - Eliminar caracteres especiales: Acentos y caracteres especiales podrían complejizar el la representación de palabras, por lo que los eliminaremos.\n",
        " - Eliminaremos URLs y handles que son típicos en tweeter. Esto es especifico en este set de datos ya que una URL no representa información en este contexto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_DPo-_PM_Xv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60baa7a5-8ee1-4974-a209-ec6e600819e0"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eJxv1LA_J-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unidecode\n",
        "import spacy\n",
        "import es_core_news_sm as spa\n",
        "import re\n",
        "from nltk import stem\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize.casual import TweetTokenizer\n",
        "\n",
        "parser = spa.load() # Cargamos el parser en español\n",
        "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True) # Creamos un tokenizer\n",
        "stemmer = stem.SnowballStemmer(language='spanish') # Creamos un steammer\n",
        "lemmatizer = lambda word : \" \".join([token.lemma_ for token in parser(word)]) # Creamos un lemmatizer\n",
        "stopwords = set(stopwords.words('spanish')) # Instanciamos las stopwords en español\n",
        "urls_regex = re.compile('http\\S+') # Usamos una expresion regular para encontrar las URLs\n",
        "\n",
        "def process_text(text):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token for token in tokens if not re.match(urls_regex, token)]\n",
        "    tokens = [token for token in tokens if len(token) > 4]\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    tokens = [unidecode.unidecode(token) for token in tokens] # Quitamos acentos\n",
        "    tokens = [lemmatizer(token) for token in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4uXheye_J-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "621a27f6-8945-40cd-a9fb-bf91280bf8a9"
      },
      "source": [
        "doc_list = []\n",
        "\n",
        "for doc in tqdm(tweets['TEXTO']):\n",
        "    tokens = process_text(doc)\n",
        "    doc_list.append(' '.join(tokens))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3763/3763 [02:07<00:00, 29.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtykSqbA_J-l",
        "colab_type": "text"
      },
      "source": [
        "Revisemos algunos resultados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQgWOejW_J-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ff886cf-ae6b-435e-eea2-9db13c894ea4"
      },
      "source": [
        "tweets['TEXTO'][2]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#VozPópuli Vozpópuli @voz_populi - #LoMásLeidoHoy Mercadona, DIA o Alcampo guardan silencio ante la ola europea... https://t.co/aJTuA4J9UV'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huZ2Cu2Q_J-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4754ea7a-af58-4782-f475-f69fb5b9b1d1"
      },
      "source": [
        "doc_list[2]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#vozpopuli vozpopuli #lomasleidohoy mercadon alcamp guard silenci europe'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WSbMjTnRYXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf5e8bcd-aeba-47b9-d8d8-81217f17f64f"
      },
      "source": [
        "len(doc_list)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3763"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PXVzn24_J-p",
        "colab_type": "text"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLwWu__sX4Rq",
        "colab_type": "text"
      },
      "source": [
        "Una vez que nuesto texto fue preprocesado para mantener solo aquellas palabras que nos son relevantes, pasamos al proceso de generar vectores a partir de las palabras que componen nuestro vocabulario. Nuestros modelos no pueden operar sobre palabras, y por lo tanto necesitamos una representación númerica de las mismas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjAlqTArYGkD",
        "colab_type": "text"
      },
      "source": [
        "### One-hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KNGM__EYKHX",
        "colab_type": "text"
      },
      "source": [
        "Quizás una de las técnicas más sencillas, one-hot encoding utiliza la misma lógica que cuando se utiliza para codificar variables categoricas. Utilizando un vector de longitud igual al tamaño del vocabulario, asigna un 1 a la posición de cada palabra en el diccionario. Así si la palabra \"hola\" es la primera palabra del diccionario, su vector será [1 0 0 0 0 0 ... 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLXvkGy8Y889",
        "colab_type": "text"
      },
      "source": [
        "### Frecuencia de la palabra (TF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBcSI27AZDYJ",
        "colab_type": "text"
      },
      "source": [
        "Una forma más interesante de representar una palabra podría ser tratando de capturar la frecuencia con la que aparece, haciendo sentido de que si una palabra aparece muy frecuentemente en un texto, entonces tendría mas relevancia. Esto lo podemos lograr con CountVectorizer el cual calcula:\n",
        "\n",
        "$$TF = \\frac {freq(w_i)} {len(doc)} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1nMf7TY_J-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWk8TAKN_J-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OP1XPee_J-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors = vectorizer.fit_transform(doc_list).todense()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqr6FFqe_J-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4fb3ce96-09f7-4a7e-d5c5-4f1f8376efdf"
      },
      "source": [
        "vectors.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3763, 6729)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBHCllSp_J-2",
        "colab_type": "text"
      },
      "source": [
        "¿Que representa 6729?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcWd57oJ_J-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = np.array(vectorizer.get_feature_names())"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30nO-ORD_J-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8db26cfb-d730-4a8a-bbed-7c175cca6c4b"
      },
      "source": [
        "vocab[3020:3050]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['gastar', 'gasto', 'gazelle', 'gedauto', 'gemeliers', 'generacion',\n",
              "       'general', 'generar', 'generation', 'generico', 'genesis',\n",
              "       'genetica', 'genial', 'genialidad', 'genil', 'genio', 'gente',\n",
              "       'george', 'geosimbolicamente', 'gerencia', 'gerente', 'gestion',\n",
              "       'gestionar', 'gestor', 'ghost', 'ghvip', 'ghvipdirecto', 'gibaja',\n",
              "       'gibraltar', 'giga'], dtype='<U29')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UanHET-FaAZN",
        "colab_type": "text"
      },
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSf9hs5Z_J--",
        "colab_type": "text"
      },
      "source": [
        "Un problema que hay con las frecuencias de las palabras es que palabras muy comunes en el lenguage, como \"el\", dominarian el proceso de vectorización. TF-IDF es una forma de normalizar los vectores de frecuencias al tomar en consideración la frecuencia en la que aparece la palabra en el documento, la longitud del documento y que tan comun o raro es la palabra en todo el corpus.\n",
        "\n",
        "$$TF = \\frac {freq(w_i)} {len(doc)} $$\n",
        "\n",
        "\n",
        "$$IDF = log(\\frac {len(corpus)} {freq(w_i, corpus)}) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmlzH04aXc7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_tnL2Bsanm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors = vectorizer.fit_transform(doc_list).todense()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cAm8AT_ap1e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "93064772-ef77-4984-c731-8cf5bd9cac7e"
      },
      "source": [
        "vectors.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3763, 6729)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiCNkuiFatKU",
        "colab_type": "text"
      },
      "source": [
        "Noten que cambiar la forma de vectorización en estos casos no cambia la longitud de nuestros vectores (que siempre está dada por la dimensionalidad del vocabulario, en este caso 6729). Solo cambia los valores numericos que se asignan en los vectores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5YtJxjQXgxH",
        "colab_type": "text"
      },
      "source": [
        "## Reducción de dimensionalidad: Featurization\n",
        "Una vez que tenemos nuestros palabras representadas como vectores, nos aparece el problema de que !aún son demasiado grandes! En el ejemplo anterior, estamos trabajando con vectores en un espacio de 6K+. Necesitamos reducir esta dimensionalidad. Para esto, utilizaremos métodos de reducción de dimensionalidad con el objetivo de generar features que nos sean más utiles. Estas features las generaremos de forma \"no supervisada\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI4HLD1tkTBT",
        "colab_type": "text"
      },
      "source": [
        "### Métodos básados en SVD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8tC0kyK_J-6",
        "colab_type": "text"
      },
      "source": [
        "Los modelos basados en factorización de matrices intentan reducir la dimensionalidad de la matriz al aproximarla usando dos matrices más pequeñas con <i>k</i> factores latentes. Este método es bastante popular no solo en NLP sino que también en sistemas de recomendación, método que fué ganador del Netflix Prize (Funk SVD).\n",
        "\n",
        "El concepto de decomposición de matrices es muy similar al de PCA en el sentido de que el número de factores latentes determina la cantidad de concepto abstractos que queremos mapear en un espacio dimensional menor. A medida que agregamos factores latentes, aumentaremos la especificación de los mismos hasta que llegue un momento donde los factores serán demasiados y el modelo comience a saturarse (over-fitting).\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/700/1*Z0EUVs7QElEqRqXtqut_FQ.png\" />\n",
        "\n",
        "\n",
        "U y V(trapuesta) son ortogonales. Esto es de esperar porrque si determinadas propiedades determinan un determinado factor latente, entonces esas propiedades serán poco relevantes en los restantes factores (pues sino, no haría sentido que conformen un factor distinto en un primer lugar).\n",
        "\n",
        "SVC es un metodo de decomposición exacto, lo que singnifica que las matrices U y V son lo suficientemente grandes para mapear exactamente la matriz A. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh1u5cZzkKbO",
        "colab_type": "text"
      },
      "source": [
        "### LSI - Latent Semantic Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1pbwdPv_J-7",
        "colab_type": "text"
      },
      "source": [
        "Cuando SVD es utilizado para procesar tópicos en texto y en donde los valores de la matriz A corresponden a frecuencias de palabras (ya sea por su frecuencia de aparición o con el método TF-IDF), este método se lo denomina Latent Semantic Analysis (sin embargo, en NLP no se lo suele nombrar como LSI).\n",
        "\n",
        "Dado que SVC es un método de decomposición exacto, tiende a producir matrices de poca densidad (sparse). Para evitar este problema, se utiliza una versión modificada de SVC conocida como Truncated SVD que solamente computa los k componentes mas grandes en la descomposición. Esto ayuda a que LSI combata efectivamente el problema de matrices sparse que tienden a generarse cuando se tienen cuerpos de texto con sinónimos y palabras que significan varias cosas dependiendo del contexto. Truncated SVD evíta ser un método de decomposición exacto al aproximar la matriz A utilizando los k tópicos más relevantes.\n",
        "\n",
        "<img src='https://github.com/fastai/course-nlp/raw/aabfeddf61fea29b18c72f841d057b56a216b7eb/images/svd_fb.png' />\n",
        "\n",
        "Facebook Research: Fast Randomized SVD [https://research.fb.com/fast-randomized-svd/])\n",
        "\n",
        "En esta configuración entonces:\n",
        " - A es una matriz de m x n donde m es la cantidad de documentos ú observaciones, y n es la cantidad de palabras en el vocabulario.\n",
        " - Los valores de A corresponden a la frecuencia de la cada palabra del vocabulario en cada observación ú documento.\n",
        "\n",
        "Referencia: Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions [https://arxiv.org/abs/0909.4061]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUldeeN6_J-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=True, sublinear_tf=True, norm='l2')\n",
        "vectors = vectorizer.fit_transform(doc_list).todense()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1iGWgQZca0C",
        "colab_type": "text"
      },
      "source": [
        "El principal parametro en LSI es el numero de factores que queremos generar (el parametro K). No existe una regla para especificar este parametro ya que depende del escenario. Valores muy pequeños pueden forzar a los documentos a ser colisionar en los tópicos que son asignados, mientras que valores muy grandes pueden hacer que palabras poco frecuentes y raras terminen determinando su propio \"topico\". Este valor lo especificaremos en n_components. El parametro algorithm hace referencia al método que utilizaremos para generar la descomposición:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ2uzF82_J--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=7, algorithm='randomized')\n",
        "USigma = svd.fit_transform(vectors)\n",
        "Sigma = svd.singular_values_\n",
        "VT = svd.components_"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bFhXZc6eHQL",
        "colab_type": "text"
      },
      "source": [
        "Si bien en el codigo anterior estamos viendo las 3 matrices, solo nos interesa la matriz VT. ¿Porque? Recuerden que nuestro \"input\" es un conjunto de palabras que luego vectorizamos utilizando TF-IDF. Cada documento está representado por este conjunto de palabras. Nuestro objetivo es disponer una forma donde podamos convertir este set de palabras a \"tópicos\" que sean más informativos que las palabras propiamente dichas. **En consecuencia, lo único que nos interesa aqui es la matriz VT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvvt3kpu_J_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "aa3a5255-b2ae-405c-9308-9260e65b0a26"
      },
      "source": [
        "VT.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 6729)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwu_KCg__J_C",
        "colab_type": "text"
      },
      "source": [
        "Internamente, TrucatedSVC es un wrapper de la clase randomized_svd donde la matríz Q que vimos anteriormente se genera a través de un método de sampling aleatorio. Las siguientes lineas son equivalentes a lo que vimos anteriormente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kigl-Xl_J_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils.extmath import randomized_svd\n",
        "\n",
        "U, Sigma, VT = randomized_svd(vectors, \n",
        "                              n_components=7,\n",
        "                              n_iter=5)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV9fOGLB_J_F",
        "colab_type": "text"
      },
      "source": [
        "Podemos validar que U es una matriz ortogonal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLYEo9Gm_J_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3957c27e-443e-4a69-9791-892cd0587a51"
      },
      "source": [
        "np.allclose(U.T @ U, np.eye(U.shape[1]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSv1wUgK_J_I",
        "colab_type": "text"
      },
      "source": [
        "Lo siguiente es solo a titulo informativo, pero si vemos los valores de la matriz Sigma, veremos la importancia relativa de los documentos con respecto a los tópicos que encontramos. Si los gráficamos vemos que sus valores comienzan a decrecer relativamente rápido, sosteniendo la supoción de que Truncated SVD genera los K más relevantes tópicos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVI80HRw_J_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d554eb62-26eb-47d2-d29b-98e16016e582"
      },
      "source": [
        "plt.plot(Sigma)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f349cd3dcf8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR8CpAYe_J_K",
        "colab_type": "text"
      },
      "source": [
        "#### Interpretando los tópicos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra5f0S7FfKjG",
        "colab_type": "text"
      },
      "source": [
        "La siguiente función solo toma la matriz de VT y obtiene las 8 palabras más importantes en este topico. Si quieren pueden variar este parametro para ver más palabras e inspeccionar los tópicos. Esto es importante porque SVD es un método no supervisado, por lo tanto no sabemos a priori cuando un tópico es bueno o malo. El sentido debemos darselo nosotros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBNIN0xE_J_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_topics(a):\n",
        "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[-8:-1]]\n",
        "    topic_words = ([top_words(t) for t in a])\n",
        "    return [' '.join(t) for t in topic_words]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDhDFVY9_J_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c334104a-1591-429f-c014-68f2872acfaf"
      },
      "source": [
        "show_topics(VT)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['medalla querer ganar gustar comprar cerveza cruzcampo',\n",
              " 'olimpia nikes siempre nuevo zapatilla camiseta adidas',\n",
              " 'nuevo conocer comprar gustar aldub81stweeksary superstar cruzcampo',\n",
              " 'bueno querer invitar beber arruinaunacitacon4palabras cerveza gustar',\n",
              " '10 terminar carrera milka ritmar correr acabo',\n",
              " 'bimbo alfajor ganar comprar carrefour mercadona chocolate',\n",
              " 'panga vender movistar mejor bimbo comprar carrefour']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKCo8UOd_J_Q",
        "colab_type": "text"
      },
      "source": [
        "Limitaciones en SVD:\n",
        " - SVD sufre de un problema llamado \"Indeterminación del signo\", que básicamente significa que el signo en la matríz VT y USigma dependen del algorimo que se utilizó para generarlos y de las condiciones iniciales (initial random state). En este contexto, que significa que un tópico esté relacionado con una palabra en un valor negativo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no6V6rtO_J_Q",
        "colab_type": "text"
      },
      "source": [
        "### NMF: Non-negative Matrix Factorization\n",
        "\n",
        "Motivación: En lugar de construir nuestros factores imponiendo la restricción de que sean ortogonales, la idea es de construirlos de tal forma que sean no-negativos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQwyjnN8_J_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nmf = NMF(n_components=7, random_state = 1234)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdTfBg2n_J_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = nmf.fit_transform(vectors)\n",
        "H1 = nmf.components_"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIYwacxIfxqQ",
        "colab_type": "text"
      },
      "source": [
        "En este caso, la matriz que nos interesa es H1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S39Zrr06_J_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0fb721b9-d453-4085-9d42-2501ed31d0a7"
      },
      "source": [
        "H1.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 6729)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkEBkOc-fqtT",
        "colab_type": "text"
      },
      "source": [
        "#### Interpretando los tópicos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8qfO_Dx_J_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "184ae210-b37e-4012-d21e-4ff1e0259810"
      },
      "source": [
        "show_topics(H1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['novio comprar querer corona medalla cerveza ganar',\n",
              " 'olimpia color nikes siempre nuevo zapatilla camiseta',\n",
              " 'tenis napaacc cliente nuevo conocer aldub81stweeksary superstar',\n",
              " 'mahou invitar querer beber arruinaunacitacon4palabras cerveza gustar',\n",
              " '50 10 terminar carrera ritmar correr acabo',\n",
              " 'mcflurry necesito quiero querer alfajor ganar chocolate',\n",
              " 'panga vender movistar mejor comprar bimbo carrefour']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbMNkPv7_J_i",
        "colab_type": "text"
      },
      "source": [
        "### LDA: Latent Dirichlet Allocation\n",
        "\n",
        "LDA es un método Bayesiano basado en la distribución de Dirichlet, la cual es una distribución sobre probabilidades en K categorias. LDA supone que los documentos que tenemos pertenecen a K categorias distintas cuya distribución es desconocida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bct-Ck5f6fs",
        "colab_type": "text"
      },
      "source": [
        "La distribución Dirichlet es una generalización de la distribución Beta en un espacio multidimensional. Así como la distribución beta es la distribución previa de la binomial, la distribución de Dirichlet es la distribución previa de la multinomial. \n",
        "\n",
        "$$ P(w\\mid d) = P(d)\\sum_c P(k\\mid d)P(w\\mid k) $$\n",
        "\n",
        "*¿Notan alguna similitud con SVD*\n",
        "\n",
        "David Blei, Andrew Ng, Michael Jordan:  Latent Dirichlet Allocation [https://jmlr.org/papers/volume3/blei03a/blei03a.pdf]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN1vPUB3_J_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=7)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1dC1tN6_J_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3f38a83d-62d0-4672-fa8f-e7c1b19e5ebc"
      },
      "source": [
        "lda.fit(vectors)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
              "                          evaluate_every=-1, learning_decay=0.7,\n",
              "                          learning_method='batch', learning_offset=10.0,\n",
              "                          max_doc_update_iter=100, max_iter=10,\n",
              "                          mean_change_tol=0.001, n_components=7, n_jobs=None,\n",
              "                          perp_tol=0.1, random_state=None,\n",
              "                          topic_word_prior=None, total_samples=1000000.0,\n",
              "                          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF-MpBfDgk2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fff73cf3-0cbd-4a5c-8152-e8d0698a9968"
      },
      "source": [
        "for idx, topic in enumerate(lda.components_):\n",
        "    print (\"Topic \", idx, \" \".join(vocab[i] for i in topic.argsort()[:-10 - 1:-1]))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic  0 carrefour bimbo nunca digital movistar lorenzo servitje diseno bankinter decathlon\n",
            "Topic  1 adir carrefour gracia mercadona heineken querer soler bankia hacer comprar\n",
            "Topic  2 bimbo movistar siempre mueble banco marcar toyota santander adir adidas\n",
            "Topic  3 heineken adidas nikeplus acabo correr toyota milka ritmar ganar medalla\n",
            "Topic  4 mercadona heineken mejor taller mecanico movistar banco peugeot reparacion poder\n",
            "Topic  5 cruzcampo gustar heineken mercadona cerveza carrefour movistar adir comprar arruinaunacitacon4palabras\n",
            "Topic  6 milka heineken chocolate mercadona adidas barato comprar alcampo necesito probar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwFoS39i_J_r",
        "colab_type": "text"
      },
      "source": [
        "## Creando un pipeline de preprocesamiento de texto\n",
        "\n",
        "A pesar de que los métodos anteriores son no supervisados, son de utilidad para el modelado de de problemas no supervisados como supervisados. Para llevar estos métodos a un entorno práctico normalmente se construyen flujos de procesamiento como el que se muestra más abajo. Estos flujos se los llama Pipeline:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLSZG2Gy_J_r",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/santiagxf/M72109/blob/master/NLP/Docs/atap_0406.png?raw=1' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdw5EvPI_J_s",
        "colab_type": "text"
      },
      "source": [
        "A modo de ejemplo, vamos a utilizar la API de Scikit-Learn para generar cada uno de estos pasos y así construir un modelo que resuelva un problema de negocio de punta a punta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONzBUk9yhH9k",
        "colab_type": "text"
      },
      "source": [
        "**¿Que es lo que vamos a hacer?**\n",
        "Intentaremos construir un pipeline de machine learning donde como entrada recibamos texto, ejecutemos todos los pasos que vimos en este notebook incluyendo:\n",
        " - Eliminación de stopwords\n",
        " - Tokenización\n",
        " - Stemming y Lemmatization\n",
        " - Procesamiento especico del tema\n",
        " - Creación de features utilizando algun metodo de reducción de dimensionalidad, SVD, LSI, LDA\n",
        "\n",
        ", para luego utilizar estas features para entrenar un modelo que nos permita predecir alguna propiedad interesante del set de datos. En este caso en particular, donde estamos viendo tweets, algunos casos interesantes podrían ser:\n",
        " - Predecir el sector al que pertenece el tweet: Alimentación, Bebidas, etc.\n",
        " - Predecir el paso en el Marketing Funel al que pertece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-TetBhbiGMz",
        "colab_type": "text"
      },
      "source": [
        "### Creando un paso de Pipeline para procesamiento de texto\n",
        "\n",
        "El paso más complejo que tenemos para crear es quizas el preprocesamiento del texto. Esto lo podemos encapsular en un modulo de Scikit-Learn. Esta libreria tiene 2 tipos de modulos:\n",
        " - Transformers\n",
        " - Estimators\n",
        "\n",
        "Los transformers toman un set de features y devuelven otro set de features, por eso es que reciben el nombre de \"trasformers\", porque basicamente transforman vectores. Los estimators, por el contrario, reciben un set de features y producen un podelo que aproxima, o estima, una variable target. Por este motivo, estos modulos reciben el nombre de \"estimators\".\n",
        "\n",
        "¿Qué modulo les parece que va a implementar nuestro proceso de \"preprocesamiento\" de texto?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WWuoi17_J_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unidecode\n",
        "import spacy\n",
        "import es_core_news_sm as spa\n",
        "import re\n",
        "import sklearn\n",
        "from nltk import stem\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize.casual import TweetTokenizer\n",
        "\n",
        "class TextNormalizer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
        "    def __init__(self, language='spanish'):\n",
        "        self.parser = spa.load() # Cargamos el parser en español\n",
        "        self.tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True) # Creamos un tokenizer\n",
        "        self.stemmer = stem.SnowballStemmer(language=language) # Creamos un steammer\n",
        "        self.lemmatizer = lambda word : \" \".join([token.lemma_ for token in self.parser(word)]) # Creamos un lemmatizer\n",
        "        self.stopwords = set(stopwords.words(language)) # Instanciamos las stopwords en español\n",
        "        self.urls_regex = re.compile('http\\S+') # Usamos una expresion regular para encontrar las URLs\n",
        "    \n",
        "    def process_text(self, text):\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        tokens = [token for token in tokens if not re.match(urls_regex, token)]\n",
        "        tokens = [token for token in tokens if len(token) > 4]\n",
        "        tokens = [token for token in tokens if token not in self.stopwords]\n",
        "        tokens = [unidecode.unidecode(token) for token in tokens] # Quitamos acentos\n",
        "        tokens = [self.lemmatizer(token) for token in tokens]\n",
        "        return tokens\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        for doc in X:\n",
        "          yield ' '.join(self.process_text(text=doc))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeSpeGyC_J_0",
        "colab_type": "text"
      },
      "source": [
        "Instanciamos nuestro preprocesamiento de texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir3pP6II_J_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalizer = TextNormalizer()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8YY0A5wkPa0",
        "colab_type": "text"
      },
      "source": [
        "Podemos ver como funciona nuestro modulo de preprocesamiento de texto al llamarlo con la función transform:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N89kgK3tkYUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cf34099-91d4-4d2c-ed1f-7f54adb9c0f2"
      },
      "source": [
        "tweet = tweets['TEXTO'][5]\n",
        "print(tweet)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ". @PoliciadeBurgos @PCivilBurgos @Aytoburgos Mismo peligro c/ Rio Viejo junto Mercadona Villimar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIZm5SWMkgvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cd794e5-7cbb-4b79-aba0-29517e6569a4"
      },
      "source": [
        "list(normalizer.transform([tweet]))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mismo peligrar Viejo juntar Mercadona Villimar']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKl5iLwpl1Jm",
        "colab_type": "text"
      },
      "source": [
        "*Nota: Usamso list() solamente porque transform es una operación de tipo lazy. Esto significa que no se ejecuta hasta que enumeramos los resultados*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDuoM0BRmESe",
        "colab_type": "text"
      },
      "source": [
        "### Construyendo nuestro pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwhSKt53_J_w",
        "colab_type": "text"
      },
      "source": [
        "Importamos algunas librerias que necesitaremos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bx5kQr6_J_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU4ykD8z_J_3",
        "colab_type": "text"
      },
      "source": [
        "Instanciamos nuestro vectorizador, en este caso usando el método TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVIdgSc9_J_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(use_idf=True, sublinear_tf=True, norm='l2')"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSnMG5la_J_5",
        "colab_type": "text"
      },
      "source": [
        "Instanciamos nuestro generador de features, que en este caso son los tópicos que LDA genere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o18xNsj_J_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featurizer = LatentDirichletAllocation(n_components=7)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FumqlRDO_J__",
        "colab_type": "text"
      },
      "source": [
        "Instanciamos nuestro clasificador que utilizará las features generadas hasta este momento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mpzmpo__KAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimator = LogisticRegression(max_iter=10000, multiclass=True)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xkn_cWu_KAE",
        "colab_type": "text"
      },
      "source": [
        "Creamos un pipeline que ejecute todos los pasos en secuencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAccQHAG_KAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = Pipeline(steps=[('normalizer', normalizer), \n",
        "                           ('vectorizer', vectorizer),\n",
        "                           ('featurizer', featurizer),\n",
        "                           ('estimator', estimator)])"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6pY5hsJmRzH",
        "colab_type": "text"
      },
      "source": [
        "### Entrenando nuestro pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wHgLnnYmZH0",
        "colab_type": "text"
      },
      "source": [
        "En este caso intentaremos predecir el sector al que pertenece un tweet en particular. Para ello, como en todo proceso de machine learning separaremos nuestros datos en training y testing, para poder evaluar los resultados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yAc9s1WmjlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tweets['TEXTO'], tweets['SECTOR'], test_size=0.33, stratify=tweets['SECTOR'])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtWhdGYQn4Ey",
        "colab_type": "text"
      },
      "source": [
        "El método fit intrenará nuestro modelo de punta a punta. Tomará unos minutos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp-fZa4E_KAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = pipeline.fit(X=X_train, y=y_train)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOLZErx-oGIB",
        "colab_type": "text"
      },
      "source": [
        "Es hora de ver que tan bien le fué a nuestro modelo en esta tarea"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiQLKHrr_KAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbDgBh5M_KAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "2ab98170-b142-470a-cb88-554a43fb30e8"
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "ALIMENTACION       0.00      0.00      0.00       110\n",
            "  AUTOMOCION       0.00      0.00      0.00       148\n",
            "       BANCA       0.00      0.00      0.00       198\n",
            "     BEBIDAS       0.36      0.56      0.44       223\n",
            "    DEPORTES       0.28      0.12      0.16       216\n",
            "      RETAIL       0.24      0.73      0.36       268\n",
            "       TELCO       0.00      0.00      0.00        79\n",
            "\n",
            "    accuracy                           0.28      1242\n",
            "   macro avg       0.13      0.20      0.14      1242\n",
            "weighted avg       0.17      0.28      0.19      1242\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "089VY2OupEVK",
        "colab_type": "text"
      },
      "source": [
        "¿Les parece que estás métricas son buenas? ¿Se les ocurre como mejorarlo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XfLkgKApJpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}